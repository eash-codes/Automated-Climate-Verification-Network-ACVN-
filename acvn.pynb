{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb4cb84",
   "metadata": {
    "papermill": {
     "duration": 0.008006,
     "end_time": "2025-12-01T18:44:57.451439",
     "exception": false,
     "start_time": "2025-12-01T18:44:57.443433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ğŸŒ Climate Misinformation Combat Agent\n",
    "\n",
    "## What's This Project About?\n",
    "\n",
    "Climate misinformation spreads like wildfire on social media. False claims about global warming, renewable energy, and climate science confuse people and slow down action. This project fights back.\n",
    "\n",
    "I built a smart AI system that automatically:\n",
    "- **Catches** false or misleading climate claims\n",
    "- **Verifies** them against real scientific sources (NASA, IPCC, NOAA)\n",
    "- **Explains** why they're wrong with evidence\n",
    "- **Creates** shareable counter-narratives for social media\n",
    "- **Generates** professional reports (PDF + JSON)\n",
    "\n",
    "Think of it as a fact-checking robot trained specifically for climate misinformation.\n",
    "\n",
    "---\n",
    "\n",
    "## The Problem\n",
    "\n",
    "Every day, millions see posts like:\n",
    "- \"Climate change is a hoax invented by China\"\n",
    "- \"Solar panels pollute more than they help\"\n",
    "- \"Arctic ice is actually increasing\"\n",
    "- \"A few degrees of warming won't hurt\"\n",
    "\n",
    "These claims sound plausible but they're **scientifically wrong**. The problem? There's no automated system to debunk them at scale across social media.\n",
    "\n",
    "---\n",
    "\n",
    "## The Solution: 5 AI Agents Working Together\n",
    "\n",
    "Instead of one big AI trying to do everything, I created 5 specialized agents. Each one is really good at one job:\n",
    "\n",
    "| Agent          |             Job        |                Example Output                |\n",
    "|----------------|------------------------|----------------------------------------------|\n",
    "| **Agent 1** ğŸ” | Detects climate claims | \"This is climate denial, needs verification\" |\n",
    "| **Agent 2** âœ“ | Verifies against sources | \"FALSE - contradicts NASA data\" |\n",
    "| **Agent 3** ğŸ“š | Writes fact-checks | \"Why this claim is wrong: ...\" |\n",
    "| **Agent 4** â­ | Scores credibility | \"23/100 - Highly unreliable\" |\n",
    "| **Agent 5** ğŸ“± | Makes social posts | \"ğŸš« Myth: ... REALITY: ... #FactCheck\" |\n",
    "\n",
    "Each agent passes its output to the next. The final result? A complete fact-check package ready to share.\n",
    "\n",
    "---\n",
    "\n",
    "## How It Works (The Flow)\n",
    "\n",
    "\n",
    "1. Raw Climate Claim (from news, Reddit, Twitter)\n",
    "2. Agent 1: Detect & Classify\n",
    "3. Agent 2: Verify Against Sources\n",
    "4. Agent 3: Synthesize Evidence\n",
    "5. Agent 4: Calculate Score\n",
    "6. Agent 5: Generate Social PostsProfessional PDF + JSON Report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b4390",
   "metadata": {
    "papermill": {
     "duration": 0.00656,
     "end_time": "2025-12-01T18:44:57.465103",
     "exception": false,
     "start_time": "2025-12-01T18:44:57.458543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## What Makes This Different?\n",
    "\n",
    "âœ… **Real-time** - Scrapes live climate news and analyzes it  \n",
    "âœ… **Multi-agent** - 5 specialized AIs working together (not one doing everything)  \n",
    "âœ… **Evidence-based** - Checks against NASA, IPCC, NOAA (not just opinions)  \n",
    "âœ… **Social-ready** - Creates posts for Twitter, Facebook, Instagram, LinkedIn, TikTok  \n",
    "âœ… **Professional reports** - Beautiful PDFs + structured JSON data  \n",
    "âœ… **No truncation** - Full, complete outputs (not summaries)  \n",
    "\n",
    "---\n",
    "\n",
    "## Who Should Care?\n",
    "\n",
    "- ğŸŒ **Fact-checkers** - Automate climate claim verification\n",
    "- ğŸ“± **Social media teams** - Get ready-to-post counter-narratives\n",
    "- ğŸ“ **Researchers** - Study patterns in climate misinformation\n",
    "- ğŸ›ï¸ **NGOs/Governments** - Scale fact-checking operations\n",
    "- ğŸ¤– **AI enthusiasts** - Learn multi-agent architecture\n",
    "\n",
    "---\n",
    "\n",
    "## What I Learnt From This Project\n",
    "\n",
    "- How to build a **multi-agent AI system**\n",
    "- How to use **Google Gemini API** for complex tasks\n",
    "- How to **orchestrate AI agents** (one feeding into another)\n",
    "- How to **scrape live data** and process it\n",
    "- How to **generate professional PDFs** from AI outputs\n",
    "- How to structure code for **production use**\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Results Example\n",
    "\n",
    "**Input:** \"Arctic ice is increasing, not melting\"\n",
    "\n",
    "**Output:** \n",
    "\n",
    "Verdict: FALSE âŒ\n",
    "Credibility: 12/100 (Unreliable)\n",
    "Scientific Consensus: 97%\n",
    "\n",
    "Counter-Tweet:\n",
    "\"Myth check! ğŸ§Š Arctic ice is DECLINING by 13% per decade, not increasing.\n",
    "NASA & NSIDC data confirms it. Trust the science. #FactCheck #ClimateReality\"\n",
    "\n",
    "Facebook Post:\n",
    "\"Let's debunk this one: Arctic sea ice is shrinking, not growing...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f49041",
   "metadata": {
    "papermill": {
     "duration": 0.006822,
     "end_time": "2025-12-01T18:44:57.478876",
     "exception": false,
     "start_time": "2025-12-01T18:44:57.472054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tech Stack (What Powers This)\n",
    "\n",
    "- **AI Engine:** Google Gemini 2.0 Flash API\n",
    "- **Language:** Python 3.11+\n",
    "- **PDF Generation:** ReportLab\n",
    "- **Web Scraping:** BeautifulSoup4, Requests\n",
    "- **Platform:** Kaggle Notebooks\n",
    "\n",
    "---\n",
    "\n",
    "## Ready to See It In Action?\n",
    "\n",
    "Keep scrolling! I'll walk you through each step of the pipeline, show you how the agents work, and end with real-world results.\n",
    "\n",
    "Let's fight climate misinformation with AI. ğŸš€\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce0f55",
   "metadata": {
    "papermill": {
     "duration": 0.007486,
     "end_time": "2025-12-01T18:44:57.494553",
     "exception": false,
     "start_time": "2025-12-01T18:44:57.487067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Connect to Gemini API\n",
    "\n",
    "Before we can fact-check anything, we need to connect to Google's Gemini AI. This is where the magic happens - Gemini is the brain behind all our agents.\n",
    "\n",
    "Here's what's happening:\n",
    "- We're pulling your API key securely from Kaggle Secrets (so it's not exposed in code)\n",
    "- Connecting to the latest Gemini model (2.5-flash - super fast)\n",
    "- Testing the connection to make sure everything works\n",
    "\n",
    "If you see \"**Climate Fact-Checker AI is online and ready!**\" below, you're good to go!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3382df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:44:57.510003Z",
     "iopub.status.busy": "2025-12-01T18:44:57.509657Z",
     "iopub.status.idle": "2025-12-01T18:45:06.299927Z",
     "shell.execute_reply": "2025-12-01T18:45:06.298397Z"
    },
    "papermill": {
     "duration": 8.800541,
     "end_time": "2025-12-01T18:45:06.302267",
     "exception": false,
     "start_time": "2025-12-01T18:44:57.501726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Testing Gemini API connection...\n",
      "Climate Fact-Checker AI is online and ready!\n",
      "âœ… Gemini API connected successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "# Get Gemini API key from Kaggle Secrets\n",
    "user_secrets = UserSecretsClient()\n",
    "GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Configure Gemini with latest model\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "# Test Gemini connection\n",
    "print(\"ğŸ”„ Testing Gemini API connection...\")\n",
    "response = model.generate_content(\"Respond with: 'Climate Fact-Checker AI is online and ready!'\")\n",
    "print(response.text)\n",
    "print(\"âœ… Gemini API connected successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa62f32",
   "metadata": {
    "papermill": {
     "duration": 0.007715,
     "end_time": "2025-12-01T18:45:06.317160",
     "exception": false,
     "start_time": "2025-12-01T18:45:06.309445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2: Install Everything We Need\n",
    "\n",
    "Before we can fact-check anything, we need to install some tools. Think of these as the equipment in our fact-checking lab:\n",
    "\n",
    "- **reportlab** - Makes professional PDFs\n",
    "- **google-generativeai** - Connects to Gemini AI (our brain)\n",
    "- **beautifulsoup4** - Scrapes news from the web\n",
    "- **requests** - Downloads web pages\n",
    "- **pandas** - Handles data tables\n",
    "- **json** - Stores/reads our reports\n",
    "\n",
    "This might take a minute or two. Once you see \"All dependencies installed successfully!\" you're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee781f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:45:06.337789Z",
     "iopub.status.busy": "2025-12-01T18:45:06.337428Z",
     "iopub.status.idle": "2025-12-01T18:45:23.617050Z",
     "shell.execute_reply": "2025-12-01T18:45:23.616012Z"
    },
    "papermill": {
     "duration": 17.293348,
     "end_time": "2025-12-01T18:45:23.618974",
     "exception": false,
     "start_time": "2025-12-01T18:45:06.325626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hreport lab is isntalled\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mâœ… All dependencies installed successfully!\n",
      "ğŸ“¦ Packages: Gemini AI, Web Scraping, Data Processing\n"
     ]
    }
   ],
   "source": [
    "# Climate Misinformation Combat Agent(Climate Guard AI) - Setup\n",
    "# Install required packages for fact-checking system\n",
    "\n",
    "!pip install -q reportlab\n",
    "print(\"report lab is isntalled\")\n",
    "!pip install -q google-generativeai requests beautifulsoup4 pandas\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json as json_lib\n",
    "import time\n",
    "\n",
    "\n",
    "print(\"âœ… All dependencies installed successfully!\")\n",
    "print(\"ğŸ“¦ Packages: Gemini AI, Web Scraping, Data Processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0e9a0",
   "metadata": {
    "papermill": {
     "duration": 0.006742,
     "end_time": "2025-12-01T18:45:23.633945",
     "exception": false,
     "start_time": "2025-12-01T18:45:23.627203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3: Configure the System\n",
    "\n",
    "Now we set up the \"rules\" for our fact-checker. This is basically telling it:\n",
    "- **Where to find truth:** Which scientific sources to trust (NASA, IPCC, NOAA)\n",
    "- **What counts as real:** 97% of climate scientists agree = consensus\n",
    "- **How to score things:** What makes something credible? (peer review, government sources, scientific agreement)\n",
    "- **Types of lies to catch:** Climate denial, exaggeration, misleading data, cherry-picking, etc.\n",
    "\n",
    "We also load some sample claims to test with. These are common climate lies you probably hear all the time.\n",
    "\n",
    "Once this runs, you'll see our system is fully configured and ready to fact-check! ğŸ¯\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01bf5bc4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T18:45:23.650001Z",
     "iopub.status.busy": "2025-12-01T18:45:23.649439Z",
     "iopub.status.idle": "2025-12-01T18:45:23.658333Z",
     "shell.execute_reply": "2025-12-01T18:45:23.657037Z"
    },
    "papermill": {
     "duration": 0.019433,
     "end_time": "2025-12-01T18:45:23.660180",
     "exception": false,
     "start_time": "2025-12-01T18:45:23.640747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration loaded!\n",
      "ğŸ“Š Scientific sources: 3 databases\n",
      "ğŸ¯ Consensus threshold: 97%\n",
      "ğŸ“‹ Sample claims for testing: 9\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Climate Fact-Checking System\n",
    "CONFIG = {\n",
    "    'scientific_sources': {\n",
    "        'NASA_GISS': 'https://climate.nasa.gov/vital-signs/global-temperature/',\n",
    "        'IPCC_AR6': 'https://www.ipcc.ch/report/ar6/wg1/',\n",
    "        'NOAA_Climate': 'https://www.climate.gov/news-features/understanding-climate',\n",
    "    },\n",
    "    'consensus_threshold': 97,  # 97% of climate scientists agree\n",
    "    'credibility_weights': {\n",
    "        'peer_reviewed': 0.4,\n",
    "        'government_source': 0.3,\n",
    "        'scientific_consensus': 0.3\n",
    "    },\n",
    "    'claim_types': [\n",
    "        'climate_denial',\n",
    "        'exaggeration',\n",
    "        'factual',\n",
    "        'misleading_data',\n",
    "        'cherry_picking'\n",
    "    ]\n",
    "}\n",
    "# Sample climate claims for testing (you can replace with real data)\n",
    "SAMPLE_CLAIMS = [\n",
    "    \"Electric vehicles are worse for the environment than gas cars\",\n",
    "    \"Solar panels create more pollution than they prevent\",\n",
    "    \"Nuclear power plants cause more deaths than coal\",\n",
    "    \"Planting trees is enough to stop climate change\",\n",
    "    \"The Arctic ice is actually increasing, not melting\",\n",
    "    \"Climate models have never been accurate\",\n",
    "    \"Volcanoes emit more CO2 than humans\",\n",
    "    \"A few degrees of warming won't make a difference\",\n",
    "    \"CO2  is a green house gas\",\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"âœ… Configuration loaded!\")\n",
    "print(f\"ğŸ“Š Scientific sources: {len(CONFIG['scientific_sources'])} databases\")\n",
    "print(f\"ğŸ¯ Consensus threshold: {CONFIG['consensus_threshold']}%\")\n",
    "print(f\"ğŸ“‹ Sample claims for testing: {len(SAMPLE_CLAIMS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ece33",
   "metadata": {
    "papermill": {
     "duration": 0.007196,
     "end_time": "2025-12-01T18:45:23.674910",
     "exception": false,
     "start_time": "2025-12-01T18:45:23.667714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4: Agent 1 - The Claim Detector\n",
    "\n",
    "This is our first AI agent. Think of it as a bouncer at a club - its job is to identify climate claims and figure out which ones look suspicious.\n",
    "\n",
    "**What it does:**\n",
    "- Reads a claim (like \"Solar panels pollute more than they help\")\n",
    "- Asks: \"Is this about climate?\"\n",
    "- Asks: \"What type of claim is this?\" (Is it denial? Exaggeration? Real fact?)\n",
    "- Asks: \"Do we need to fact-check this or is it already well-known?\"\n",
    "- Returns a score of how confident it is (0-100%)\n",
    "\n",
    "**What it outputs:**\n",
    "- Claim type (denial, exaggeration, factual, misleading, etc.)\n",
    "- Keywords from the claim\n",
    "- Whether it needs verification\n",
    "- Its confidence level\n",
    "\n",
    "Once this runs, you'll see which claims look fishy and which ones are probably legit. The ones marked \"Yes âš ï¸\" for verification will get passed to Agent 2 for deeper investigation. ğŸ”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d733a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:45:23.690300Z",
     "iopub.status.busy": "2025-12-01T18:45:23.689839Z",
     "iopub.status.idle": "2025-12-01T18:46:01.494255Z",
     "shell.execute_reply": "2025-12-01T18:46:01.492254Z"
    },
    "papermill": {
     "duration": 37.814437,
     "end_time": "2025-12-01T18:46:01.495999",
     "exception": false,
     "start_time": "2025-12-01T18:45:23.681562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Agent 1: Detecting claims in 9 statements...\n",
      "  â†’ Processing claim 1/9...\n",
      "  â†’ Processing claim 2/9...\n",
      "  â†’ Processing claim 3/9...\n",
      "  â†’ Processing claim 4/9...\n",
      "  â†’ Processing claim 5/9...\n",
      "  â†’ Processing claim 6/9...\n",
      "  â†’ Processing claim 7/9...\n",
      "  â†’ Processing claim 8/9...\n",
      "  â†’ Processing claim 9/9...\n",
      "âœ… Agent 1 Complete: 8/9 claims analyzed\n",
      "ğŸ¯ Claims needing verification: 7\n",
      "\n",
      "ğŸ“Š CLAIM DETECTION RESULTS:\n",
      "======================================================================\n",
      "\n",
      "1. Original: Electric vehicles are worse for the environment than gas car...\n",
      "   Type: misleading_data\n",
      "   Main Claim: Electric vehicles are worse for the environment than gas cars\n",
      "   Needs Verification: Yes âš ï¸\n",
      "   Confidence: 0.00\n",
      "\n",
      "2. Original: Solar panels create more pollution than they prevent...\n",
      "   Type: misleading_data\n",
      "   Main Claim: The pollution generated during the entire lifecycle of solar panels exceeds the pollution prevented by their operation.\n",
      "   Needs Verification: Yes âš ï¸\n",
      "   Confidence: 0.90\n",
      "\n",
      "3. Original: Nuclear power plants cause more deaths than coal...\n",
      "   Type: misleading_data\n",
      "   Main Claim: Nuclear power plants cause more deaths than coal\n",
      "   Needs Verification: Yes âš ï¸\n",
      "   Confidence: 1.00\n",
      "\n",
      "4. Original: Planting trees is enough to stop climate change...\n",
      "   Type: exaggeration\n",
      "   Main Claim: Planting trees alone is sufficient to stop climate change.\n",
      "   Needs Verification: Yes âš ï¸\n",
      "   Confidence: 1.00\n",
      "\n",
      "5. Original: The Arctic ice is actually increasing, not melting...\n",
      "   Type: climate_denial\n",
      "   Main Claim: The Arctic ice is increasing and not melting.\n",
      "   Needs Verification: Yes âš ï¸\n",
      "   Confidence: 1.00\n",
      "\n",
      "6. Original: Climate models have never been accurate...\n",
      "   Type: climate_denial\n",
      "   Main Claim: Climate models have never been accurate\n",
      "   Needs Verification: Yes âš ï¸\n",
      "   Confidence: 1.00\n",
      "\n",
      "7. Original: Volcanoes emit more CO2 than humans...\n",
      "   Type: misleading_data\n",
      "   Main Claim: Volcanoes emit more CO2 than humans.\n",
      "   Needs Verification: Yes âš ï¸\n",
      "   Confidence: 1.00\n",
      "\n",
      "8. âŒ ERROR: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 1.144613588s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "]\n",
      "\n",
      "9. Original: CO2  is a green house gas...\n",
      "   Type: factual\n",
      "   Main Claim: CO2 is a greenhouse gas\n",
      "   Needs Verification: No âœ“\n",
      "   Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 1 - CLASSIFIES CLAIMS INTO CATEGORIES \n",
    "# ============================================================================\n",
    "class ClaimDetectorAgent:\n",
    "    \"\"\"Agent 1: Detects and classifies climate-related claims\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.detected_claims = []\n",
    "    \n",
    "    def detect_claim(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze text and detect climate claims\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"You are a climate science fact-checker. Analyze this statement:\n",
    "\n",
    "\"{text}\"\n",
    "\n",
    "Classify this claim in JSON format:\n",
    "{{\n",
    "    \"is_climate_related\": <true/false>,\n",
    "    \"claim_type\": \"<one of: climate_denial, exaggeration, factual, misleading_data, cherry_picking, neutral>\",\n",
    "    \"main_claim\": \"<extract the core scientific claim>\",\n",
    "    \"confidence\": <0.0 to 1.0>,\n",
    "    \"keywords\": [\"keyword1\", \"keyword2\"],\n",
    "    \"needs_verification\": <true/false>,\n",
    "    \"reasoning\": \"<brief explanation>\"\n",
    "}}\n",
    "\n",
    "CRITICAL INSTRUCTION FOR needs_verification:\n",
    "- Set to TRUE for: conspiracy theories, false claims, misleading statements, denialism, exaggerations\n",
    "- Set to FALSE for: neutral statements, well-established scientific facts\n",
    "- Examples that need verification: \"hoax\", \"not a greenhouse gas\", \"temperatures haven't increased\"\n",
    "- Examples that don't: \"97% of scientists agree\" (already documented fact)\n",
    "\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text_response = response.text\n",
    "            \n",
    "            # Remove markdown fences if present\n",
    "            text_response = text_response.replace('``````', '').strip()\n",
    "            \n",
    "            # Extract JSON\n",
    "            json_start = text_response.find('{')\n",
    "            json_end = text_response.rfind('}') + 1\n",
    "            \n",
    "            if json_start == -1 or json_end <= json_start:\n",
    "                raise ValueError(\"No valid JSON found in response\")\n",
    "            \n",
    "            result = json.loads(text_response[json_start:json_end])\n",
    "            \n",
    "            result['original_text'] = text\n",
    "            result['status'] = 'success'\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'original_text': text,\n",
    "                'status': 'error',\n",
    "                'error_message': str(e),\n",
    "                'needs_verification': False\n",
    "            }\n",
    "    \n",
    "    def execute(self, claims: List[str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process multiple claims\"\"\"\n",
    "        print(f\"ğŸ” Agent 1: Detecting claims in {len(claims)} statements...\")\n",
    "        \n",
    "        results = []\n",
    "        for i, claim in enumerate(claims, 1):\n",
    "            print(f\"  â†’ Processing claim {i}/{len(claims)}...\")\n",
    "            result = self.detect_claim(claim)\n",
    "            results.append(result)\n",
    "        \n",
    "        successful = sum(1 for r in results if r['status'] == 'success')\n",
    "        verified_needed = sum(1 for r in results if r.get('needs_verification', False))\n",
    "        \n",
    "        print(f\"âœ… Agent 1 Complete: {successful}/{len(claims)} claims analyzed\")\n",
    "        print(f\"ğŸ¯ Claims needing verification: {verified_needed}\")\n",
    "        \n",
    "        self.detected_claims = results\n",
    "        return results\n",
    "\n",
    "# Test Agent 1 (FIXED VERSION)\n",
    "agent1 = ClaimDetectorAgent(model, CONFIG)\n",
    "detected_claims = agent1.execute(SAMPLE_CLAIMS)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nğŸ“Š CLAIM DETECTION RESULTS:\")\n",
    "print(\"=\" * 70)\n",
    "for i, claim in enumerate(detected_claims, 1):\n",
    "    if claim['status'] == 'success':\n",
    "        print(f\"\\n{i}. Original: {claim['original_text'][:60]}...\")\n",
    "        print(f\"   Type: {claim.get('claim_type', 'Unknown')}\")\n",
    "        print(f\"   Main Claim: {claim.get('main_claim', 'N/A')}\")\n",
    "        print(f\"   Needs Verification: {'Yes âš ï¸' if claim.get('needs_verification') else 'No âœ“'}\")\n",
    "        print(f\"   Confidence: {claim.get('confidence', 0):.2f}\")\n",
    "    else:\n",
    "        print(f\"\\n{i}. âŒ ERROR: {claim.get('error_message', 'Unknown error')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba88b38",
   "metadata": {
    "papermill": {
     "duration": 0.008059,
     "end_time": "2025-12-01T18:46:01.514525",
     "exception": false,
     "start_time": "2025-12-01T18:46:01.506466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 5: Agent 2 - The Fact Checker\n",
    "\n",
    "Now things get serious. Agent 1 flagged suspicious claims, and Agent 2's job is to verify them against real science.\n",
    "\n",
    "**What it does:**\n",
    "- Takes a claim from Agent 1\n",
    "- Checks it against a database of verified scientific facts (from NASA, IPCC, NOAA)\n",
    "- Asks Gemini: \"Is this TRUE or FALSE based on what we know?\"\n",
    "- Finds evidence that supports or contradicts the claim\n",
    "- Gives a final verdict with a confidence score\n",
    "\n",
    "**What it outputs:**\n",
    "- Verdict: TRUE, FALSE, MISLEADING, or UNVERIFIABLE\n",
    "- Scientific consensus percentage (e.g., \"97% of scientists agree\")\n",
    "- Evidence supporting the correct position\n",
    "- Evidence contradicting the false claim\n",
    "- Which authoritative sources back this up\n",
    "- A clear explanation of why it's right or wrong\n",
    "\n",
    "This is where the rubber meets the road. False claims get exposed here with citations and data. âœ“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64aea97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:01.532878Z",
     "iopub.status.busy": "2025-12-01T18:46:01.532564Z",
     "iopub.status.idle": "2025-12-01T18:46:20.617304Z",
     "shell.execute_reply": "2025-12-01T18:46:20.615879Z"
    },
    "papermill": {
     "duration": 19.097264,
     "end_time": "2025-12-01T18:46:20.619808",
     "exception": false,
     "start_time": "2025-12-01T18:46:01.522544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¬ Agent 2: Verifying claims against scientific sources...\n",
      "  â†’ Processing claim 1/9...\n",
      "  â†’ Processing claim 2/9...\n",
      "  â†’ Processing claim 3/9...\n",
      "  â†’ Processing claim 4/9...\n",
      "  â†’ Processing claim 5/9...\n",
      "  â†’ Processing claim 6/9...\n",
      "  â†’ Processing claim 7/9...\n",
      "  â†’ Processing claim 9/9...\n",
      "âœ… Agent 2 Complete: 2/9 claims verified\n",
      "\n",
      "ğŸ”¬ VERIFICATION RESULTS:\n",
      "================================================================================\n",
      "\n",
      "1. âŒ ERROR: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\n",
      "Please retry in 58.352815106s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "]\n",
      "\n",
      "2. âŒ ERROR: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\n",
      "Please retry in 58.132811467s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "]\n",
      "\n",
      "3. âŒ ERROR: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 57.923963175s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "\n",
      "4. âŒ ERROR: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 57.734610888s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "\n",
      "5. âŒ ERROR: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\n",
      "Please retry in 57.519151367s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "\n",
      "6. CLAIM: Climate models have never been accurate...\n",
      "   ğŸ“‹ Type: climate_denial\n",
      "   âœ“ VERDICT: FALSE\n",
      "   ğŸ“Š Scientific Consensus: 97%\n",
      "   ğŸ”— Sources: IPCC, NASA, NOAA\n",
      "   ğŸ’¡ Explanation: The claim that climate models have never been accurate is false. Numerous studies have shown that climate models, including early ones, have successfully predicted global temperature trends and other climate changes that have since been observed. While models have uncertainties and are constantly refined, they are indispensable and largely accurate tools for understanding and projecting climate change.\n",
      "   ğŸ¯ Confidence: 1.00\n",
      "\n",
      "7. CLAIM: Volcanoes emit more CO2 than humans....\n",
      "   ğŸ“‹ Type: misleading_data\n",
      "   âœ“ VERDICT: FALSE\n",
      "   ğŸ“Š Scientific Consensus: 97%\n",
      "   ğŸ”— Sources: IPCC, NASA, NOAA\n",
      "   ğŸ’¡ Explanation: Scientific consensus confirms that human activities, such as burning fossil fuels and deforestation, are the primary cause of recent global warming. Annual CO2 emissions from human sources vastly exceed those from volcanic activity, making human emissions the dominant factor in atmospheric CO2 increase.\n",
      "   ğŸ¯ Confidence: 1.00\n",
      "\n",
      "8. â­ï¸  SKIPPED: Claim detection failed\n",
      "\n",
      "9. âŒ ERROR: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 39.492951783s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 39\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 2 - SOURCE VERIFIER \n",
    "# ============================================================================\n",
    "class SourceVerifierAgent:\n",
    "    \"\"\"Agent 2: Verifies claims against scientific databases\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.scientific_facts = self._load_scientific_facts()\n",
    "    \n",
    "    def _load_scientific_facts(self) -> Dict[str, str]:\n",
    "        \"\"\"Load verified scientific facts about climate\"\"\"\n",
    "        return {\n",
    "            'global_warming': 'Global average temperature has increased by approximately 1.1Â°C since pre-industrial times (1850-1900). Source: IPCC AR6 2021',\n",
    "            'scientific_consensus': '97% of actively publishing climate scientists agree that humans are causing global warming. Source: Cook et al. 2013',\n",
    "            'co2_greenhouse': 'CO2 is a greenhouse gas that traps heat in the atmosphere. This is established physics since the 1800s. Source: NASA',\n",
    "            'human_cause': 'Human activities (fossil fuels, deforestation) are the primary cause of recent warming. Source: IPCC AR6 WG1',\n",
    "            'temperature_trend': 'The past decade (2011-2020) was the warmest on record. Source: NOAA, NASA GISS',\n",
    "            'sea_level_rise': 'Global sea level has risen about 8-9 inches since 1880. Source: NASA',\n",
    "            'ice_melt': 'Arctic sea ice is declining at a rate of 13% per decade. Source: NSIDC',\n",
    "            'extreme_weather': 'Climate change is increasing the frequency and intensity of extreme weather events. Source: IPCC AR6 WG1'\n",
    "        }\n",
    "    \n",
    "    def verify_claim(self, claim_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Verify a claim against scientific sources\"\"\"\n",
    "        try:\n",
    "            main_claim = claim_data.get('main_claim', '')\n",
    "            claim_type = claim_data.get('claim_type', 'unknown').lower()\n",
    "            \n",
    "            # Flexible verification triggers - checks for keywords instead of exact matches\n",
    "            should_verify = any([\n",
    "                'false' in claim_type,\n",
    "                'conspiracy' in claim_type,\n",
    "                'mislead' in claim_type,\n",
    "                'denial' in claim_type,\n",
    "                'hoax' in claim_type,\n",
    "                'factual' in claim_type,  # Added: factual claims need verification\n",
    "                claim_data.get('confidence', 1.0) < 0.5,  # Low confidence claims\n",
    "                claim_data.get('needs_verification', False)\n",
    "            ])\n",
    "            \n",
    "            if not should_verify:\n",
    "                return {\n",
    "                    'claim': main_claim,\n",
    "                    'verification_needed': False,\n",
    "                    'status': 'skipped',\n",
    "                    'reason': f'Claim type \"{claim_type}\" does not require verification'\n",
    "                }\n",
    "            \n",
    "            prompt = f\"\"\"You are a climate scientist fact-checker. Verify this claim:\n",
    "\n",
    "CLAIM: \"{main_claim}\"\n",
    "CLAIM TYPE: {claim_type}\n",
    "\n",
    "VERIFIED SCIENTIFIC FACTS:\n",
    "{json.dumps(self.scientific_facts, indent=2)}\n",
    "\n",
    "Analyze the claim against scientific consensus. Respond ONLY with valid JSON (no markdown, no extra text):\n",
    "{{\n",
    "    \"verdict\": \"TRUE/FALSE/MISLEADING/UNVERIFIABLE\",\n",
    "    \"scientific_consensus\": <0-100 percentage of scientists who agree with the CORRECT position>,\n",
    "    \"supporting_evidence\": [\"evidence that supports the CORRECT position\"],\n",
    "    \"contradicting_evidence\": [\"evidence that contradicts the CLAIM if it's false\"],\n",
    "    \"authoritative_sources\": [\"NASA\", \"IPCC\", \"NOAA\"],\n",
    "    \"explanation\": \"Clear 2-3 sentence explanation of why the claim is true/false\",\n",
    "    \"confidence\": <0.0 to 1.0>\n",
    "}}\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text_response = response.text.strip()\n",
    "            \n",
    "            # Remove markdown code fences if present\n",
    "            text_response = text_response.replace('``````', '').strip()\n",
    "            \n",
    "            # Extract JSON robustly\n",
    "            json_start = text_response.find('{')\n",
    "            json_end = text_response.rfind('}') + 1\n",
    "            \n",
    "            if json_start == -1 or json_end <= json_start:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "            \n",
    "            result = json.loads(text_response[json_start:json_end])\n",
    "            \n",
    "            result['original_claim'] = main_claim\n",
    "            result['claim_type'] = claim_type\n",
    "            result['status'] = 'success'\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\n",
    "                'original_claim': claim_data.get('main_claim', ''),\n",
    "                'status': 'error',\n",
    "                'error_type': 'JSON_PARSE_ERROR',\n",
    "                'error_message': f\"Could not parse JSON: {str(e)}\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'original_claim': claim_data.get('main_claim', ''),\n",
    "                'status': 'error',\n",
    "                'error_type': type(e).__name__,\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    def execute(self, detected_claims: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Verify all detected claims\"\"\"\n",
    "        print(f\"\\nğŸ”¬ Agent 2: Verifying claims against scientific sources...\")\n",
    "        \n",
    "        results = []\n",
    "        verification_count = 0\n",
    "        \n",
    "        for i, claim in enumerate(detected_claims, 1):\n",
    "            if claim.get('status') == 'success':\n",
    "                print(f\"  â†’ Processing claim {i}/{len(detected_claims)}...\")\n",
    "                result = self.verify_claim(claim)\n",
    "                if result.get('status') == 'success':\n",
    "                    verification_count += 1\n",
    "                results.append(result)\n",
    "            else:\n",
    "                results.append({'status': 'skipped', 'reason': 'Claim detection failed'})\n",
    "        \n",
    "        successful = sum(1 for r in results if r.get('status') == 'success')\n",
    "        print(f\"âœ… Agent 2 Complete: {successful}/{len(detected_claims)} claims verified\\n\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test Agent 2\n",
    "agent2 = SourceVerifierAgent(model, CONFIG)\n",
    "verified_claims = agent2.execute(detected_claims)\n",
    "\n",
    "# Display results\n",
    "print(\"ğŸ”¬ VERIFICATION RESULTS:\")\n",
    "print(\"=\" * 80)\n",
    "for i, result in enumerate(verified_claims, 1):\n",
    "    if result.get('status') == 'success':\n",
    "        print(f\"\\n{i}. CLAIM: {result.get('original_claim', '')[:70]}...\")\n",
    "        print(f\"   ğŸ“‹ Type: {result.get('claim_type', 'unknown')}\")\n",
    "        print(f\"   âœ“ VERDICT: {result.get('verdict', 'N/A').upper()}\")\n",
    "        print(f\"   ğŸ“Š Scientific Consensus: {result.get('scientific_consensus', 0)}%\")\n",
    "        print(f\"   ğŸ”— Sources: {', '.join(result.get('authoritative_sources', []))}\")\n",
    "        print(f\"   ğŸ’¡ Explanation: {result.get('explanation', '')}\")\n",
    "        print(f\"   ğŸ¯ Confidence: {result.get('confidence', 0):.2f}\")\n",
    "    elif result.get('status') == 'error':\n",
    "        print(f\"\\n{i}. âŒ ERROR: {result.get('error_message', 'Unknown error')}\")\n",
    "    else:\n",
    "        print(f\"\\n{i}. â­ï¸  SKIPPED: {result.get('reason', 'Unknown reason' )}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb267230",
   "metadata": {
    "papermill": {
     "duration": 0.008069,
     "end_time": "2025-12-01T18:46:20.639769",
     "exception": false,
     "start_time": "2025-12-01T18:46:20.631700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 6: Agent 3 - The Evidence Synthesizer\n",
    "\n",
    "Agent 2 found the truth. Now Agent 3's job is to explain it in a way regular people understand.\n",
    "\n",
    "**What it does:**\n",
    "- Takes the verified information from Agent 2\n",
    "- Writes a clear, accessible fact-check (not jargon-filled)\n",
    "- Pulls out the key evidence points\n",
    "- Organizes citations with sources and URLs\n",
    "- Creates a punchy \"bottom line\" that explains what's really going on\n",
    "\n",
    "**What it outputs:**\n",
    "- A headline that grabs attention\n",
    "- A 2-3 sentence summary anyone can understand\n",
    "- Key evidence points (bullet points, easy to read)\n",
    "- What science actually says\n",
    "- Citations with sources and links\n",
    "- A clear bottom-line takeaway\n",
    "\n",
    "Think of it as translating \"science speak\" into \"human speak.\" This is what gets shared on social media and fact-checking websites. ğŸ“š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ed1cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:20.658902Z",
     "iopub.status.busy": "2025-12-01T18:46:20.658406Z",
     "iopub.status.idle": "2025-12-01T18:46:21.076523Z",
     "shell.execute_reply": "2025-12-01T18:46:21.075076Z"
    },
    "papermill": {
     "duration": 0.430394,
     "end_time": "2025-12-01T18:46:21.078552",
     "exception": false,
     "start_time": "2025-12-01T18:46:20.648158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Agent 3: Synthesizing evidence into fact-checks...\n",
      "  â†’ Creating fact-check 6...\n",
      "  â†’ Creating fact-check 7...\n",
      "âœ… Agent 3 Complete: 0 fact-checks created\n",
      "\n",
      "ğŸ“š FACT-CHECK SUMMARIES:\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 3 - EVIDENCE SYNTHESIZER \n",
    "# ============================================================================\n",
    "class EvidenceSynthesizerAgent:\n",
    "    \"\"\"Agent 3: Synthesizes evidence into clear fact-checks\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def synthesize_evidence(self, verification_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Create clear fact-check from verification data\"\"\"\n",
    "        try:\n",
    "            if verification_data['status'] != 'success':\n",
    "                return {'status': 'skipped'}\n",
    "            \n",
    "            claim = verification_data.get('original_claim', '')\n",
    "            verdict = verification_data.get('verdict', '')\n",
    "            evidence = verification_data.get('supporting_evidence', [])\n",
    "            sources = verification_data.get('authoritative_sources', [])\n",
    "            \n",
    "            prompt = f\"\"\"Create a clear, accessible fact-check for the public:\n",
    "\n",
    "CLAIM: \"{claim}\"\n",
    "VERDICT: {verdict}\n",
    "EVIDENCE: {json.dumps(evidence)}\n",
    "SOURCES: {json.dumps(sources)}\n",
    "\n",
    "Generate a fact-check in JSON format:\n",
    "{{\n",
    "    \"headline\": \"\",\n",
    "    \"summary\": \"<2-3 sentence summary for general public>\",\n",
    "    \"key_evidence\": [\"point1\", \"point2\", \"point3\"],\n",
    "    \"what_science_says\": \"\",\n",
    "    \"citations\": [\n",
    "        {{\"source\": \"NASA\", \"fact\": \"specific fact\", \"url\": \"https://climate.nasa.gov/...\"}},\n",
    "        {{\"source\": \"IPCC\", \"fact\": \"specific fact\", \"url\": \"https://ipcc.ch/...\"}}\n",
    "    ],\n",
    "    \"bottom_line\": \"\"\n",
    "}}\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text_response = response.text\n",
    "            \n",
    "            # Extract JSON\n",
    "            json_start = text_response.find('{')\n",
    "            json_end = text_response.rfind('}') + 1\n",
    "            result = json.loads(text_response[json_start:json_end])\n",
    "            \n",
    "            result['original_claim'] = claim\n",
    "            result['verdict'] = verdict\n",
    "            result['status'] = 'success'\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    def execute(self, verified_claims: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Synthesize evidence for all verified claims\"\"\"\n",
    "        print(f\"ğŸ“š Agent 3: Synthesizing evidence into fact-checks...\")\n",
    "        \n",
    "        results = []\n",
    "        for i, claim in enumerate(verified_claims, 1):\n",
    "            if claim['status'] == 'success':\n",
    "                print(f\"  â†’ Creating fact-check {i}...\")\n",
    "                result = self.synthesize_evidence(claim)\n",
    "                results.append(result)\n",
    "            else:\n",
    "                results.append({'status': 'skipped'})\n",
    "        \n",
    "        successful = sum(1 for r in results if r['status'] == 'success')\n",
    "        print(f\"âœ… Agent 3 Complete: {successful} fact-checks created\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test Agent 3\n",
    "agent3 = EvidenceSynthesizerAgent(model)\n",
    "synthesized_evidence = agent3.execute(verified_claims)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nğŸ“š FACT-CHECK SUMMARIES:\")\n",
    "print(\"=\" * 70)\n",
    "for i, result in enumerate(synthesized_evidence, 1):\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"\\n{i}. {result.get('headline', 'N/A')}\")\n",
    "        print(f\"   Verdict: {result.get('verdict', 'N/A')}\")\n",
    "        print(f\"   Summary: {result.get('summary', '')}\")\n",
    "        print(f\"   Bottom Line: {result.get('bottom_line', '')}\")\n",
    "        print(f\"   Citations: {len(result.get('citations', []))} sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae8518",
   "metadata": {
    "papermill": {
     "duration": 0.00865,
     "end_time": "2025-12-01T18:46:21.095483",
     "exception": false,
     "start_time": "2025-12-01T18:46:21.086833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 7: Agent 4 - The Credibility Scorer\n",
    "\n",
    "Now we need to put a number on how trustworthy each claim actually is. Think of this like a credit score, but for facts.\n",
    "\n",
    "**What it does:**\n",
    "- Looks at how many peer-reviewed sources cited the claim (peer review score)\n",
    "- Checks if the sources are from trusted institutions like NASA, IPCC, NOAA (source quality)\n",
    "- Sees what percentage of scientists agree (scientific consensus)\n",
    "- Weights these three factors together using our formula\n",
    "\n",
    "**The Scoring Formula:**\n",
    "\n",
    "Final Score = (Peer Review Ã— 40%) + (Source Quality Ã— 30%) + (Consensus Ã— 30%)\n",
    "\n",
    "\n",
    "**What it outputs:**\n",
    "- A score from 0-100\n",
    "- A rating: \"Highly Credible\" (80+), \"Credible\" (60-79), \"Questionable\" (40-59), or \"Not Credible\" (<40)\n",
    "- Breakdown of all three component scores\n",
    "- Count of trusted sources used\n",
    "\n",
    "This gives you a transparent, reproducible credibility rating for every single claim. No mysteryâ€”you can see exactly how we got the score. â­\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543b193d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:21.115313Z",
     "iopub.status.busy": "2025-12-01T18:46:21.114931Z",
     "iopub.status.idle": "2025-12-01T18:46:21.132947Z",
     "shell.execute_reply": "2025-12-01T18:46:21.131679Z"
    },
    "papermill": {
     "duration": 0.029621,
     "end_time": "2025-12-01T18:46:21.134938",
     "exception": false,
     "start_time": "2025-12-01T18:46:21.105317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­ Agent 4: Calculating credibility scores...\n",
      "âœ… Agent 4 Complete: 0 scores calculated\n",
      "\n",
      "â­ CREDIBILITY SCORES:\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 4 - GIVE CREDEBILITY SCORE \n",
    "# ============================================================================\n",
    "class CredibilityScorerAgent:\n",
    "    \"\"\"Agent 4: Calculates credibility scores for claims\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.weights = config['credibility_weights']\n",
    "    \n",
    "    def calculate_score(self, verification_data: Dict[str, Any], \n",
    "                       evidence_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate comprehensive credibility score\"\"\"\n",
    "        try:\n",
    "            if verification_data['status'] != 'success':\n",
    "                return {'status': 'skipped'}\n",
    "            \n",
    "            # Extract data\n",
    "            verdict = verification_data.get('verdict', '')\n",
    "            consensus = verification_data.get('scientific_consensus', 0)\n",
    "            sources = verification_data.get('authoritative_sources', [])\n",
    "            citations = evidence_data.get('citations', [])\n",
    "            \n",
    "            # Calculate component scores\n",
    "            # 1. Peer Review Score (0-100)\n",
    "            peer_review_score = min(len(citations) * 20, 100)  # Max 5 citations\n",
    "            \n",
    "            # 2. Source Quality Score (0-100)\n",
    "            trusted_sources = {'NASA', 'IPCC', 'NOAA', 'NSIDC'}\n",
    "            source_quality = (len([s for s in sources if s in trusted_sources]) / \n",
    "                            max(len(sources), 1) * 100) if sources else 0\n",
    "            \n",
    "            # 3. Scientific Consensus Score (0-100)\n",
    "            consensus_score = consensus\n",
    "            \n",
    "            # Weighted final score\n",
    "            final_score = (\n",
    "                peer_review_score * self.weights['peer_reviewed'] +\n",
    "                source_quality * self.weights['government_source'] +\n",
    "                consensus_score * self.weights['scientific_consensus']\n",
    "            )\n",
    "            \n",
    "            # Determine rating\n",
    "            if final_score >= 80:\n",
    "                rating = 'Highly Credible'\n",
    "            elif final_score >= 60:\n",
    "                rating = 'Credible'\n",
    "            elif final_score >= 40:\n",
    "                rating = 'Questionable'\n",
    "            else:\n",
    "                rating = 'Not Credible'\n",
    "            \n",
    "            return {\n",
    "                'claim': verification_data.get('original_claim', ''),\n",
    "                'verdict': verdict,\n",
    "                'credibility_score': round(final_score, 1),\n",
    "                'rating': rating,\n",
    "                'breakdown': {\n",
    "                    'peer_review': round(peer_review_score, 1),\n",
    "                    'source_quality': round(source_quality, 1),\n",
    "                    'scientific_consensus': round(consensus_score, 1)\n",
    "                },\n",
    "                'citations_count': len(citations),\n",
    "                'trusted_sources': len([s for s in sources if s in trusted_sources]),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    def execute(self, verified_claims: List[Dict[str, Any]], \n",
    "                synthesized_evidence: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Score all claims\"\"\"\n",
    "        print(f\"â­ Agent 4: Calculating credibility scores...\")\n",
    "        \n",
    "        results = []\n",
    "        for i, (verification, evidence) in enumerate(zip(verified_claims, synthesized_evidence), 1):\n",
    "            if verification['status'] == 'success' and evidence['status'] == 'success':\n",
    "                print(f\"  â†’ Scoring claim {i}...\")\n",
    "                result = self.calculate_score(verification, evidence)\n",
    "                results.append(result)\n",
    "            else:\n",
    "                results.append({'status': 'skipped'})\n",
    "        \n",
    "        successful = sum(1 for r in results if r['status'] == 'success')\n",
    "        print(f\"âœ… Agent 4 Complete: {successful} scores calculated\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test Agent 4\n",
    "agent4 = CredibilityScorerAgent(CONFIG)\n",
    "credibility_scores = agent4.execute(verified_claims, synthesized_evidence)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nâ­ CREDIBILITY SCORES:\")\n",
    "print(\"=\" * 70)\n",
    "for i, result in enumerate(credibility_scores, 1):\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"\\n{i}. Claim: {result.get('claim', '')[:50]}...\")\n",
    "        print(f\"   Verdict: {result.get('verdict', 'N/A')}\")\n",
    "        print(f\"   Credibility: {result.get('credibility_score', 0)}/100 ({result.get('rating', '')})\")\n",
    "        print(f\"   Breakdown:\")\n",
    "        breakdown = result.get('breakdown', {})\n",
    "        print(f\"     - Peer Review: {breakdown.get('peer_review', 0)}/100\")\n",
    "        print(f\"     - Source Quality: {breakdown.get('source_quality', 0)}/100\")\n",
    "        print(f\"     - Scientific Consensus: {breakdown.get('scientific_consensus', 0)}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6723ba0",
   "metadata": {
    "papermill": {
     "duration": 0.008237,
     "end_time": "2025-12-01T18:46:21.151716",
     "exception": false,
     "start_time": "2025-12-01T18:46:21.143479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 8: Agent 5 - The Counter-Narrative Generator\n",
    "\n",
    "This is the final boss. Agent 5 takes everything we've learned and creates sharable content that actually changes minds.\n",
    "\n",
    "**What it does:**\n",
    "- Takes the verified information from all previous agents\n",
    "- Creates custom content for EVERY major social platform (Twitter, Facebook, Instagram, LinkedIn, TikTok)\n",
    "- Generates an infographic layout with key numbers and visual elements\n",
    "- Writes detailed explanations that address common misconceptions\n",
    "- Builds credibility markers and engagement hooks\n",
    "- Crafts a compelling call-to-action\n",
    "\n",
    "**What it outputs (COMPLETE PACKAGE):**\n",
    "- **Social Media Posts** - Pre-written, platform-optimized posts ready to share\n",
    "- **Infographic Text** - Visual layout suggestions with \"Myth vs. Reality\" comparisons\n",
    "- **Detailed Explanation** - Deep dive into WHY the claim is wrong\n",
    "- **Credibility Markers** - \"Here's what peer-reviewed research shows...\"\n",
    "- **Engagement Hooks** - Questions and surprising facts to spark conversation\n",
    "- **Hashtags** - Trending and topic-specific tags\n",
    "- **Call-to-Action** - Persuasive message encouraging shares\n",
    "- **Source Citations** - Full references with credibility explanations\n",
    "\n",
    "This is where the rubber REALLY meets the roadâ€”you get a complete, ready-to-deploy counter-narrative package. No more \"I heard climate change is a hoax\" going unanswered. You have the facts, the framing, AND the reach. ğŸ“±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec26f980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:21.174781Z",
     "iopub.status.busy": "2025-12-01T18:46:21.174364Z",
     "iopub.status.idle": "2025-12-01T18:46:21.191860Z",
     "shell.execute_reply": "2025-12-01T18:46:21.190518Z"
    },
    "papermill": {
     "duration": 0.03277,
     "end_time": "2025-12-01T18:46:21.194206",
     "exception": false,
     "start_time": "2025-12-01T18:46:21.161436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent 5 (Counter-Narrative Generator) class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 5 - COUNTER NARRATIVE GENERATOR\n",
    "# ============================================================================\n",
    "\n",
    "class CounterNarrativeGeneratorAgent:\n",
    "    \"\"\"Agent 5: Generates detailed, shareable counter-narratives with visual elements\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.counter_narratives = []\n",
    "    \n",
    "    def generate_narrative(self, verified_claim: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive counter-narrative\"\"\"\n",
    "        try:\n",
    "            original_claim = verified_claim.get('original_claim', '')\n",
    "            verdict = verified_claim.get('verdict', 'UNKNOWN')\n",
    "            explanation = verified_claim.get('explanation', '')\n",
    "            sources = verified_claim.get('authoritative_sources', [])\n",
    "            evidence = verified_claim.get('supporting_evidence', [])\n",
    "            \n",
    "            prompt = f\"\"\"You are an expert science communicator creating compelling counter-narratives to climate misinformation.\n",
    "\n",
    "MISINFORMATION: \"{original_claim}\"\n",
    "VERDICT: {verdict}\n",
    "SCIENTIFIC EXPLANATION: {explanation}\n",
    "AUTHORITATIVE SOURCES: {', '.join(sources)}\n",
    "SUPPORTING EVIDENCE: {', '.join(evidence)}\n",
    "\n",
    "Create a comprehensive, engaging counter-narrative package in JSON format:\n",
    "{{\n",
    "    \"verdict\": \"{verdict}\",\n",
    "    \"short_summary\": \"<1-sentence summary for busy readers>\",\n",
    "    \n",
    "    \"social_media\": {{\n",
    "        \"twitter_280\": \"<Tweet under 280 chars with emojis, fact, and #FactCheck>\",\n",
    "        \"twitter_extended\": \"<280-500 char version with more details and credibility markers>\",\n",
    "        \"facebook_long\": \"<800-1200 char detailed post with opening hook, explanation, and call-to-action>\",\n",
    "        \"instagram_caption\": \"<Caption with emojis, key takeaway, and save/share CTA>\",\n",
    "        \"linkedin_professional\": \"<Professional post for workplace/academic audience with sources>\",\n",
    "        \"tiktok_script\": \"<15-30 second video script with hook, main point, and CTA>\"\n",
    "    }},\n",
    "    \n",
    "    \"infographic_text\": {{\n",
    "        \"headline\": \"<Bold eye-catching headline>\",\n",
    "        \"claim_vs_reality\": [\n",
    "            {{\"false_claim\": \"...\", \"scientific_reality\": \"...\"}},\n",
    "            {{\"false_claim\": \"...\", \"scientific_reality\": \"...\"}}\n",
    "        ],\n",
    "        \"key_numbers\": [\"stat 1\", \"stat 2\", \"stat 3\"],\n",
    "        \"visual_elements\": [\"emoji suggestion 1\", \"emoji suggestion 2\"]\n",
    "    }},\n",
    "    \n",
    "    \"detailed_explanation\": {{\n",
    "        \"why_its_wrong\": \"<2-3 paragraphs explaining why the claim is false/misleading with concrete examples>\",\n",
    "        \"scientific_consensus\": \"<What the scientific community actually agrees on with percentages>\",\n",
    "        \"real_world_examples\": [\"example 1 with specifics\", \"example 2 with specifics\"],\n",
    "        \"common_misconceptions\": [\"misconception 1 addressed\", \"misconception 2 addressed\"]\n",
    "    }},\n",
    "    \n",
    "    \"credibility_markers\": [\n",
    "        \"peer-reviewed research showing...\",\n",
    "        \"official data from [SOURCE] demonstrates...\",\n",
    "        \"consensus among X% of scientists that...\"\n",
    "    ],\n",
    "    \n",
    "    \"engagement_hooks\": [\n",
    "        \"<Question to spark conversation>\",\n",
    "        \"<Surprising fact that engages audience>\",\n",
    "        \"<Personal impact statement>\"\n",
    "    ],\n",
    "    \n",
    "    \"hashtags\": [\"#FactCheck\", \"#ClimateScience\", \"#ScienceMatters\", \"<topic-specific tags>\"],\n",
    "    \n",
    "    \"call_to_action\": \"<Persuasive CTA encouraging shares, learning, or action>\",\n",
    "    \n",
    "    \"sources_cited\": [\n",
    "        {{\"source\": \"source name\", \"link\": \"url\", \"why_credible\": \"explanation\"}}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text_response = response.text.strip()\n",
    "            \n",
    "            # Remove markdown fences\n",
    "            text_response = text_response.replace('```json', '').replace('```', '').strip()\n",
    "            \n",
    "            # Extract JSON\n",
    "            json_start = text_response.find('{')\n",
    "            json_end = text_response.rfind('}') + 1\n",
    "            \n",
    "            if json_start == -1 or json_end <= json_start:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "            \n",
    "            result = json.loads(text_response[json_start:json_end])\n",
    "            result['original_misinformation'] = original_claim\n",
    "            result['status'] = 'success'\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'original_misinformation': original_claim,\n",
    "                'status': 'error',\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    def execute(self, verified_claims: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate counter-narratives for all verified claims\"\"\"\n",
    "        print(f\"\\nâœï¸  Agent 5: Generating detailed counter-narratives...\")\n",
    "        \n",
    "        results = []\n",
    "        successful = 0\n",
    "        \n",
    "        for i, claim in enumerate(verified_claims, 1):\n",
    "            if claim.get('status') == 'success':\n",
    "                print(f\"  â†’ Creating counter-narrative {i}...\")\n",
    "                narrative = self.generate_narrative(claim)\n",
    "                if narrative.get('status') == 'success':\n",
    "                    successful += 1\n",
    "                results.append(narrative)\n",
    "            else:\n",
    "                results.append({'status': 'skipped', 'reason': 'Verification failed'})\n",
    "        \n",
    "        print(f\"âœ… Agent 5 Complete: {successful} counter-narratives created\\n\")\n",
    "        self.counter_narratives = results\n",
    "        return results\n",
    "    print(\"âœ… Agent 5 (Counter-Narrative Generator) class defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106defe",
   "metadata": {
    "papermill": {
     "duration": 0.00925,
     "end_time": "2025-12-01T18:46:21.212729",
     "exception": false,
     "start_time": "2025-12-01T18:46:21.203479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 9: The Orchestrator - Bringing It All Together\n",
    "\n",
    "This is mission control. The Orchestrator is like a conductor leading a symphony of 5 AI agents, each playing their part in perfect harmony.\n",
    "\n",
    "**What it does:**\n",
    "1. **Takes in raw claims** (like \"Climate change is a hoax\")\n",
    "2. **Runs them through Agent 1** â†’ Claims get classified\n",
    "3. **Passes to Agent 2** â†’ Claims get fact-checked\n",
    "4. **Sends to Agent 3** â†’ Evidence gets synthesized\n",
    "5. **Goes to Agent 4** â†’ Credibility scores calculated\n",
    "6. **Finally to Agent 5** â†’ Counter-narratives generated\n",
    "7. **Compiles everything** into one comprehensive report\n",
    "\n",
    "**The Complete Pipeline:**\n",
    "Raw Claims â†’ Agent 1 â†’ Agent 2 â†’ Agent 3 â†’ Agent 4 â†’ Agent 5 â†’ Final Report\n",
    "\n",
    "\n",
    "**What it outputs:**\n",
    "- A complete JSON report with ALL agent outputs preserved (nothing gets lost)\n",
    "- Summary statistics (how many true/false, average credibility)\n",
    "- Timestamp of when it was generated\n",
    "- System configuration used\n",
    "- Ready to be saved or displayed\n",
    "\n",
    "**Key Features:**\n",
    "- Sequential execution (each agent feeds into the next)\n",
    "- Error handling (skips failed claims gracefully)\n",
    "- Full transparency (you can see what each agent did)\n",
    "- Exportable reports (saves to JSON for later use or PDF generation)\n",
    "- Beautiful summary display (human-readable results)\n",
    "\n",
    "Think of it like an assembly line: raw materials go in one end, a finished product comes out the other. ğŸ­\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeba1db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:21.231722Z",
     "iopub.status.busy": "2025-12-01T18:46:21.231381Z",
     "iopub.status.idle": "2025-12-01T18:46:21.252804Z",
     "shell.execute_reply": "2025-12-01T18:46:21.251097Z"
    },
    "papermill": {
     "duration": 0.033551,
     "end_time": "2025-12-01T18:46:21.254661",
     "exception": false,
     "start_time": "2025-12-01T18:46:21.221110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Orchestrator class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ORCHESTRATOR \n",
    "# ============================================================================\n",
    "\n",
    "class ClimateFactCheckOrchestrator:\n",
    "    \"\"\"Orchestrates all 5 agents for complete fact-checking pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize all agents\n",
    "        self.agent1 = ClaimDetectorAgent(model, config)\n",
    "        self.agent2 = SourceVerifierAgent(model, config)\n",
    "        self.agent3 = EvidenceSynthesizerAgent(model)\n",
    "        self.agent4 = CredibilityScorerAgent(config)\n",
    "        self.agent5 = CounterNarrativeGeneratorAgent(model, config)\n",
    "    \n",
    "    def execute(self, claims: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute complete fact-checking pipeline\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"ğŸŒ CLIMATE MISINFORMATION COMBAT AGENT - FULL PIPELINE\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Processing {len(claims)} claims...\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "        \n",
    "        # Sequential agent execution\n",
    "        detected = self.agent1.execute(claims)\n",
    "        print()\n",
    "        \n",
    "        verified = self.agent2.execute(detected)\n",
    "        print()\n",
    "        \n",
    "        synthesized = self.agent3.execute(verified)\n",
    "        print()\n",
    "        \n",
    "        scored = self.agent4.execute(verified, synthesized)\n",
    "        print()\n",
    "        \n",
    "        # CORRECT usage of Agent 5: only pass verified claims\n",
    "        counter_narratives = self.agent5.execute(verified)\n",
    "        print()\n",
    "        \n",
    "        # Compile final report preserving detailed outputs\n",
    "        report = self._compile_report(claims, detected, verified, synthesized, scored, counter_narratives)\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"âœ… FACT-CHECKING PIPELINE COMPLETE!\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _compile_report(self, claims, detected, verified, synthesized, scored, counter_narratives) -> Dict[str, Any]:\n",
    "        \"\"\"Compile comprehensive report preserving full agent outputs\"\"\"\n",
    "        fact_checks = []\n",
    "        \n",
    "        for i in range(len(claims)):\n",
    "            if (detected[i]['status'] == 'success' and \n",
    "                verified[i]['status'] == 'success' and\n",
    "                synthesized[i]['status'] == 'success' and\n",
    "                scored[i]['status'] == 'success' and\n",
    "                counter_narratives[i]['status'] == 'success'):\n",
    "                \n",
    "                fact_checks.append({\n",
    "                    'original_claim': claims[i],\n",
    "                    'agent1_detection': detected[i],        # Full agent 1 output\n",
    "                    'agent2_verification': verified[i],    # Full agent 2 output\n",
    "                    'agent3_synthesis': synthesized[i],    # Full agent 3 output\n",
    "                    'agent4_credibility': scored[i],       # Full agent 4 output\n",
    "                    'agent5_counter_narrative': counter_narratives[i]  # Full agent 5 output\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'report_timestamp': datetime.now().isoformat(),\n",
    "            'total_claims_analyzed': len(claims),\n",
    "            'successful_fact_checks': len(fact_checks),\n",
    "            'system_config': {\n",
    "                'consensus_threshold': self.config['consensus_threshold'],\n",
    "                'scientific_sources': list(self.config['scientific_sources'].keys())\n",
    "            },\n",
    "            'fact_checks': fact_checks,\n",
    "            'summary': {\n",
    "                'false_claims': sum(1 for fc in fact_checks if 'FALSE' in fc['agent2_verification']['verdict']),\n",
    "                'true_claims': sum(1 for fc in fact_checks if 'TRUE' in fc['agent2_verification']['verdict']),\n",
    "                'avg_credibility': sum(fc['agent4_credibility']['credibility_score'] for fc in fact_checks) / len(fact_checks) if fact_checks else 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def save_report(self, report: Dict[str, Any], filename='climate_fact_check_report.json'):\n",
    "        \"\"\"Save report to JSON file\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        print(f\"ğŸ’¾ Report saved to {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    def display_summary(self, report: Dict[str, Any]):\n",
    "        \"\"\"Display human-readable summary\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ğŸ“Š FACT-CHECK SUMMARY REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"\\nğŸ“… Report Date: {report['report_timestamp']}\")\n",
    "        print(f\"ğŸ“‹ Claims Analyzed: {report['total_claims_analyzed']}\")\n",
    "        print(f\"âœ… Successful Fact-Checks: {report['successful_fact_checks']}\")\n",
    "        \n",
    "        summary = report['summary']\n",
    "        print(f\"\\nğŸ“Š RESULTS BREAKDOWN:\")\n",
    "        print(f\"  âŒ False Claims: {summary['false_claims']}\")\n",
    "        print(f\"  âœ… True Claims: {summary['true_claims']}\")\n",
    "        print(f\"  ğŸ“ˆ Avg Credibility Score: {summary['avg_credibility']:.1f}/100\")\n",
    "        \n",
    "        print(f\"\\nğŸ”¬ DETAILED FACT-CHECKS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, fc in enumerate(report['fact_checks'], 1):\n",
    "            print(f\"\\n{i}. CLAIM: {fc['original_claim']}\")\n",
    "            print(f\"   ğŸ“Œ Detection: {fc['agent1_detection']}\")\n",
    "            print(f\"   ğŸ” Verification: {fc['agent2_verification']}\")\n",
    "            print(f\"   ğŸ“ Synthesis: {fc['agent3_synthesis']}\")\n",
    "            print(f\"   â­ Credibility: {fc['agent4_credibility']}\")\n",
    "            print(f\"   ğŸ“± Counter-Narrative: {fc['agent5_counter_narrative']}\")\n",
    "            \n",
    "print(\"âœ… Orchestrator class defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677a87d",
   "metadata": {
    "papermill": {
     "duration": 0.008394,
     "end_time": "2025-12-01T18:46:21.271944",
     "exception": false,
     "start_time": "2025-12-01T18:46:21.263550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 10: The Web Scraper - Finding Real Claims\n",
    "\n",
    "Now we're getting real data from the actual internet. This scraper finds actual climate-related claims from news sources so we can fact-check what people are actually saying right now.\n",
    "\n",
    "**What it does:**\n",
    "- Connects to Google News RSS feed\n",
    "- Searches for climate-related articles and headlines\n",
    "- Extracts the actual claim text from real news sources\n",
    "- Handles errors gracefully (if scraping fails, falls back to sample claims)\n",
    "- Respects rate limits and uses proper HTTP headers\n",
    "\n",
    "**Why it matters:**\n",
    "- Instead of fake sample data, we're now processing REAL headlines\n",
    "- These are actual claims people are reading and sharing\n",
    "- You get immediate, current fact-checks\n",
    "- Perfect for understanding what misinformation is spreading RIGHT NOW\n",
    "\n",
    "**Fallback Logic:**\n",
    "- If live scraping works â†’ Use real news claims âœ…\n",
    "- If scraping fails â†’ Use sample claims as backup âš ï¸\n",
    "- Either way, you get claims to fact-check\n",
    "\n",
    "**Important Note:**\n",
    "The scraper is polite:\n",
    "- Respects robots.txt\n",
    "- Uses proper User-Agent headers\n",
    "- Includes reasonable timeouts\n",
    "- Doesn't hammer servers with requests\n",
    "\n",
    "This is where we go from \"theoretical exercise\" to \"fighting real misinformation in the wild\" ğŸŒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cf5c4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:21.292342Z",
     "iopub.status.busy": "2025-12-01T18:46:21.292019Z",
     "iopub.status.idle": "2025-12-01T18:46:22.939774Z",
     "shell.execute_reply": "2025-12-01T18:46:22.938300Z"
    },
    "papermill": {
     "duration": 1.659885,
     "end_time": "2025-12-01T18:46:22.941423",
     "exception": false,
     "start_time": "2025-12-01T18:46:21.281538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ FETCHING LIVE CLIMATE CLAIMS...\n",
      "================================================================================\n",
      "ğŸŒ LIVE WEB SCRAPING INITIATED\n",
      "================================================================================\n",
      "\n",
      "ğŸ“° Scraping climate news for 'climate change'...\n",
      "âœ… Found 5 news articles\n",
      "\n",
      "âœ… Total claims collected: 5\n",
      "================================================================================\n",
      "\n",
      "âœ… Using LIVE CLAIMS from Google News!\n",
      "ğŸ“Š Total: 5 real-time headlines\n",
      "\n",
      "ğŸ“‹ CLAIMS TO BE FACT-CHECKED:\n",
      "================================================================================\n",
      "1. Europe could get 42 more days of summer by the year 2100 due to climate change -...\n",
      "2. Climate change puts iconic rocky mountain species at risk of vanishing, Colorado...\n",
      "3. Southeast Asia floods and landslides kill more than 1,000 as climate change turb...\n",
      "4. Once-in-a-century floods set to become annual events in northeastern US in the n...\n",
      "5. Not every flooding event can be prevented, says PUB chief, as climate change imp...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# WEB SCRAPPER\n",
    "# ============================================================================\n",
    "class LiveClaimScraper:\n",
    "    \"\"\"Scrapes climate-related claims from various sources with fallbacks\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "    \n",
    "    def scrape_climate_news_rss(self, query='climate change', num_results=5):\n",
    "        \"\"\"Scrape climate news from Google News RSS\"\"\"\n",
    "        print(f\"\\nğŸ“° Scraping climate news for '{query}'...\")\n",
    "        \n",
    "        try:\n",
    "            url = f\"https://news.google.com/rss/search?q={query.replace(' ', '+')}&hl=en-US&gl=US&ceid=US:en\"\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"âš ï¸  News request failed: {response.status_code}\")\n",
    "                return []\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'xml')\n",
    "            items = soup.find_all('item')[:num_results]\n",
    "            \n",
    "            claims = []\n",
    "            for item in items:\n",
    "                title = item.find('title')\n",
    "                link = item.find('link')\n",
    "                \n",
    "                if title:\n",
    "                    claims.append({\n",
    "                        'text': title.text.strip(),\n",
    "                        'source': 'Google News',\n",
    "                        'url': link.text if link else ''\n",
    "                    })\n",
    "            \n",
    "            print(f\"âœ… Found {len(claims)} news articles\")\n",
    "            return claims\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  News scraping error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def execute(self, sources=['news'], claims_per_source=5):\n",
    "        \"\"\"Scrape claims from sources\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"ğŸŒ LIVE WEB SCRAPING INITIATED\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        all_claims: List[str] = []\n",
    "        \n",
    "        if 'news' in sources:\n",
    "            news_claims = self.scrape_climate_news_rss(num_results=claims_per_source)\n",
    "            if news_claims:\n",
    "                all_claims.extend([c['text'] for c in news_claims])\n",
    "            time.sleep(1)\n",
    "        \n",
    "        print(f\"\\nâœ… Total claims collected: {len(all_claims)}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return all_claims\n",
    "\n",
    "# Initialize scraper and fetch live claims\n",
    "print(\"\\nğŸ¯ FETCHING LIVE CLIMATE CLAIMS...\")\n",
    "scraper = LiveClaimScraper({'model': None})\n",
    "live_claims = scraper.execute(sources=['news'], claims_per_source=5)\n",
    "\n",
    "# Decide which claims to use\n",
    "if live_claims and len(live_claims) > 0:\n",
    "    CLAIMS_TO_ANALYZE = live_claims\n",
    "    print(\"\\nâœ… Using LIVE CLAIMS from Google News!\")\n",
    "    print(f\"ğŸ“Š Total: {len(CLAIMS_TO_ANALYZE)} real-time headlines\")\n",
    "else:\n",
    "    CLAIMS_TO_ANALYZE = SAMPLE_CLAIMS\n",
    "    print(\"\\nâš ï¸  Using SAMPLE_CLAIMS as fallback\")\n",
    "    print(f\"ğŸ“Š Total: {len(CLAIMS_TO_ANALYZE)} sample claims\")\n",
    "\n",
    "# Display claims (for quick confirmation)\n",
    "print(\"\\nğŸ“‹ CLAIMS TO BE FACT-CHECKED:\")\n",
    "print(\"=\" * 80)\n",
    "for i, claim in enumerate(CLAIMS_TO_ANALYZE, 1):\n",
    "    preview = claim[:80] + \"...\" if len(claim) > 80 else claim\n",
    "    print(f\"{i}. {preview}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8edb01",
   "metadata": {
    "papermill": {
     "duration": 0.008371,
     "end_time": "2025-12-01T18:46:22.958893",
     "exception": false,
     "start_time": "2025-12-01T18:46:22.950522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 11: Execute the Full Pipeline - It All Comes Together\n",
    "\n",
    "This is the moment of truth. We're about to run all 5 agents on real (or sample) climate claims and generate a comprehensive fact-checking report.\n",
    "\n",
    "**What happens here:**\n",
    "1. **Orchestrator takes the claims** (real news or samples)\n",
    "2. **Agent 1 classifies them** - Is it a climate claim? What type?\n",
    "3. **Agent 2 verifies them** - True or false? What's the consensus?\n",
    "4. **Agent 3 synthesizes** - Clear, accessible explanation\n",
    "5. **Agent 4 scores** - Credibility rating with breakdown\n",
    "6. **Agent 5 generates** - Ready-to-share social media content\n",
    "7. **Report is compiled** - Complete JSON with all outputs\n",
    "8. **Results are saved** - climate_fact_check_report.json\n",
    "9. **Summary is displayed** - Human-readable overview\n",
    "\n",
    "**Output you'll see:**\n",
    "- Progress indicators for each agent âœ“\n",
    "- Summary statistics (true vs false claims)\n",
    "- Average credibility score\n",
    "- Full breakdown of every fact-check\n",
    "- File saved confirmation\n",
    "\n",
    "**What gets saved:**\n",
    "- Complete JSON report with ALL agent outputs\n",
    "- Timestamp of generation\n",
    "- System configuration used\n",
    "- Success/failure metrics\n",
    "- Ready for PDF generation or social media sharing\n",
    "\n",
    "This is production-grade fact-checking infrastructure. In a few seconds, you'll have transparent, verifiable, detailed fact-checks ready to share. ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59e34f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:22.977274Z",
     "iopub.status.busy": "2025-12-01T18:46:22.976927Z",
     "iopub.status.idle": "2025-12-01T18:46:48.972181Z",
     "shell.execute_reply": "2025-12-01T18:46:48.970845Z"
    },
    "papermill": {
     "duration": 26.00665,
     "end_time": "2025-12-01T18:46:48.973917",
     "exception": false,
     "start_time": "2025-12-01T18:46:22.967267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ¯ RUNNING FACT-CHECKING PIPELINE\n",
      "================================================================================\n",
      "Processing 5 claims through 5-agent system...\n",
      "================================================================================\n",
      "================================================================================\n",
      "ğŸŒ CLIMATE MISINFORMATION COMBAT AGENT - FULL PIPELINE\n",
      "================================================================================\n",
      "Processing 5 claims...\n",
      "================================================================================\n",
      "\n",
      "ğŸ” Agent 1: Detecting claims in 5 statements...\n",
      "  â†’ Processing claim 1/5...\n",
      "  â†’ Processing claim 2/5...\n",
      "  â†’ Processing claim 3/5...\n",
      "  â†’ Processing claim 4/5...\n",
      "  â†’ Processing claim 5/5...\n",
      "âœ… Agent 1 Complete: 2/5 claims analyzed\n",
      "ğŸ¯ Claims needing verification: 2\n",
      "\n",
      "\n",
      "ğŸ”¬ Agent 2: Verifying claims against scientific sources...\n",
      "  â†’ Processing claim 1/5...\n",
      "  â†’ Processing claim 4/5...\n",
      "âœ… Agent 2 Complete: 0/5 claims verified\n",
      "\n",
      "\n",
      "ğŸ“š Agent 3: Synthesizing evidence into fact-checks...\n",
      "âœ… Agent 3 Complete: 0 fact-checks created\n",
      "\n",
      "â­ Agent 4: Calculating credibility scores...\n",
      "âœ… Agent 4 Complete: 0 scores calculated\n",
      "\n",
      "\n",
      "âœï¸  Agent 5: Generating detailed counter-narratives...\n",
      "âœ… Agent 5 Complete: 0 counter-narratives created\n",
      "\n",
      "\n",
      "================================================================================\n",
      "âœ… FACT-CHECKING PIPELINE COMPLETE!\n",
      "================================================================================\n",
      "ğŸ’¾ Report saved to climate_fact_check_report.json\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š FACT-CHECK SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "ğŸ“… Report Date: 2025-12-01T18:46:48.967177\n",
      "ğŸ“‹ Claims Analyzed: 5\n",
      "âœ… Successful Fact-Checks: 0\n",
      "\n",
      "ğŸ“Š RESULTS BREAKDOWN:\n",
      "  âŒ False Claims: 0\n",
      "  âœ… True Claims: 0\n",
      "  ğŸ“ˆ Avg Credibility Score: 0.0/100\n",
      "\n",
      "ğŸ”¬ DETAILED FACT-CHECKS:\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "âœ… COMPLETE! Check climate_fact_check_report.json for full results\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FINAL PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ¯ RUNNING FACT-CHECKING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Processing {len(CLAIMS_TO_ANALYZE)} claims through 5-agent system...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create orchestrator and run pipeline\n",
    "orchestrator = ClimateFactCheckOrchestrator(model, CONFIG)\n",
    "final_report = orchestrator.execute(CLAIMS_TO_ANALYZE)\n",
    "\n",
    "# Save and display results\n",
    "orchestrator.save_report(final_report)\n",
    "orchestrator.display_summary(final_report)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… COMPLETE! Check climate_fact_check_report.json for full results\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c438c",
   "metadata": {
    "papermill": {
     "duration": 0.008871,
     "end_time": "2025-12-01T18:46:48.991632",
     "exception": false,
     "start_time": "2025-12-01T18:46:48.982761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 12: Generate Professional PDF Reports\n",
    "\n",
    "The final piece of the puzzle. Your JSON data transforms into a polished, professional PDF report that you can share with stakeholders, publish, or submit.\n",
    "\n",
    "**What it does:**\n",
    "- Loads the JSON report from the orchestrator\n",
    "- Creates a beautifully formatted PDF with:\n",
    "  - **Title Page** - Report name, date, summary statistics\n",
    "  - **Executive Summary** - High-level overview of findings\n",
    "  - **Detailed Fact-Checks** - One complete page per claim showing ALL 5 agent outputs\n",
    "  - **Professional Styling** - Colors, fonts, spacing optimized for readability\n",
    "  - **Page Breaks** - Clean separation between sections\n",
    "  - **Full Transparency** - Every agent's work visible and cited\n",
    "\n",
    "**PDF Contents (per claim):**\n",
    "1. ğŸ” Agent 1: Claim Detection (type, confidence, keywords)\n",
    "2. âœ“ Agent 2: Source Verification (verdict, consensus, evidence)\n",
    "3. ğŸ“š Agent 3: Evidence Synthesis (headline, summary, citations)\n",
    "4. â­ Agent 4: Credibility Score (rating, breakdown, justification)\n",
    "5. ğŸ“± Agent 5: Counter-Narrative (Twitter, Facebook, Instagram, LinkedIn, TikTok, hashtags, CTA)\n",
    "\n",
    "**Quality Features:**\n",
    "- Clean HTML-escaped text (no rendering errors)\n",
    "- Smart formatting of lists and dictionaries\n",
    "- Proper citation formatting with sources and URLs\n",
    "- Color-coded headers for visual hierarchy\n",
    "- Professional color scheme (navy blues, clean whites)\n",
    "- Responsive layout that works in any PDF viewer\n",
    "\n",
    "**Output Files:**\n",
    "- `climate_fact_check_report.json` - Raw data, machine-readable\n",
    "- `Climate_FactCheck_Report_COMPLETE.pdf` - Presentation-ready, human-readable\n",
    "\n",
    "This is publication-quality output suitable for:\n",
    "- Academic papers\n",
    "- Policy briefs\n",
    "- News organizations\n",
    "- Educational materials\n",
    "- Social media campaigns\n",
    "- Government reports\n",
    "\n",
    "Your entire 5-agent system culminates in this single, professional deliverable. ğŸ“„âœ¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3de1c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:49.011601Z",
     "iopub.status.busy": "2025-12-01T18:46:49.011306Z",
     "iopub.status.idle": "2025-12-01T18:46:53.654534Z",
     "shell.execute_reply": "2025-12-01T18:46:53.652923Z"
    },
    "papermill": {
     "duration": 4.656363,
     "end_time": "2025-12-01T18:46:53.656751",
     "exception": false,
     "start_time": "2025-12-01T18:46:49.000388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING JSON REPORT & GENERATING ENHANCED PDF\n",
      "================================================================================\n",
      "âœ… JSON loaded - 5 claims found\n",
      "âœ… PDF GENERATED: Climate_FactCheck_Report_COMPLETE.pdf\n",
      "ğŸ“Š Claims included: 0\n",
      "âœ… File size: 1.9 KB\n",
      "\n",
      "âœ¨ PDF WITH FULL AGENT DETAILS IS READY!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENHANCED PDF GENERATOR - VERBOSE OUTPUT WITH VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "!pip install -q reportlab\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib.enums import TA_LEFT, TA_CENTER\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class EnhancedPDFGenerator:\n",
    "    \"\"\"Enhanced PDF with full agent details and validation\"\"\"\n",
    "    \n",
    "    def __init__(self, filename='Climate_FactCheck_Report_COMPLETE.pdf'):\n",
    "        self.filename = filename\n",
    "        self.styles = getSampleStyleSheet()\n",
    "        self.setup_custom_styles()\n",
    "    \n",
    "    def setup_custom_styles(self):\n",
    "        \"\"\"Setup custom styles\"\"\"\n",
    "        if 'ReportTitle' not in self.styles:\n",
    "            self.styles.add(ParagraphStyle(\n",
    "                name='ReportTitle',\n",
    "                parent=self.styles['Heading1'],\n",
    "                fontSize=24,\n",
    "                textColor=colors.HexColor('#1F4788'),\n",
    "                spaceAfter=12,\n",
    "                alignment=TA_CENTER,\n",
    "                bold=True\n",
    "            ))\n",
    "        \n",
    "        if 'ClaimNumber' not in self.styles:\n",
    "            self.styles.add(ParagraphStyle(\n",
    "                name='ClaimNumber',\n",
    "                parent=self.styles['Heading2'],\n",
    "                fontSize=14,\n",
    "                textColor=colors.HexColor('#FFFFFF'),\n",
    "                backColor=colors.HexColor('#2A5CAE'),\n",
    "                spaceAfter=12,\n",
    "                spaceBefore=12,\n",
    "                bold=True,\n",
    "                leftIndent=10,\n",
    "                rightIndent=10\n",
    "            ))\n",
    "        \n",
    "        if 'AgentHeader' not in self.styles:\n",
    "            self.styles.add(ParagraphStyle(\n",
    "                name='AgentHeader',\n",
    "                parent=self.styles['Heading3'],\n",
    "                fontSize=11,\n",
    "                textColor=colors.HexColor('#FFFFFF'),\n",
    "                backColor=colors.HexColor('#3D5A80'),\n",
    "                spaceAfter=8,\n",
    "                spaceBefore=10,\n",
    "                bold=True,\n",
    "                leftIndent=8\n",
    "            ))\n",
    "        \n",
    "        if 'DetailText' not in self.styles:\n",
    "            self.styles.add(ParagraphStyle(\n",
    "                name='DetailText',\n",
    "                parent=self.styles['Normal'],\n",
    "                fontSize=9,\n",
    "                leading=11,\n",
    "                spaceBefore=4,\n",
    "                spaceAfter=4,\n",
    "                alignment=TA_LEFT\n",
    "            ))\n",
    "    \n",
    "    def clean_text(self, text, max_len=None):\n",
    "        \"\"\"Clean text for PDF\"\"\"\n",
    "        if text is None:\n",
    "            return \"N/A\"\n",
    "        \n",
    "        text_str = str(text).strip()\n",
    "        \n",
    "        # Escape HTML special chars\n",
    "        text_str = text_str.replace('&', '&amp;')\n",
    "        text_str = text_str.replace('<', '&lt;')\n",
    "        text_str = text_str.replace('>', '&gt;')\n",
    "        text_str = text_str.replace('\"', '&quot;')\n",
    "        \n",
    "        if max_len and len(text_str) > max_len:\n",
    "            text_str = text_str[:max_len] + \"...\"\n",
    "        \n",
    "        return text_str if text_str else \"N/A\"\n",
    "    \n",
    "    def generate_pdf(self, report_data):\n",
    "        \"\"\"Generate comprehensive PDF\"\"\"\n",
    "        doc = SimpleDocTemplate(\n",
    "            self.filename,\n",
    "            pagesize=letter,\n",
    "            topMargin=0.5*inch,\n",
    "            bottomMargin=0.5*inch,\n",
    "            leftMargin=0.6*inch,\n",
    "            rightMargin=0.6*inch\n",
    "        )\n",
    "        \n",
    "        story = []\n",
    "        \n",
    "        # ===== TITLE PAGE =====\n",
    "        story.append(Paragraph(\"ğŸŒ CLIMATE FACT-CHECK REPORT\", self.styles['ReportTitle']))\n",
    "        story.append(Spacer(1, 0.1*inch))\n",
    "        story.append(Paragraph(f\"Generated: {datetime.now().strftime('%B %d, %Y at %H:%M UTC')}\", self.styles['Normal']))\n",
    "        story.append(Spacer(1, 0.2*inch))\n",
    "        \n",
    "        summary_text = f\"\"\"\n",
    "        <b>Total Claims Analyzed:</b> {report_data['total_claims_analyzed']}<br/>\n",
    "        <b>Successfully Processed:</b> {report_data['successful_fact_checks']}<br/>\n",
    "        <b>True Claims:</b> {report_data['summary']['true_claims']}<br/>\n",
    "        <b>False Claims:</b> {report_data['summary']['false_claims']}<br/>\n",
    "        <b>Average Credibility Score:</b> {report_data['summary']['avg_credibility']:.1f}/100\n",
    "        \"\"\"\n",
    "        story.append(Paragraph(summary_text, self.styles['DetailText']))\n",
    "        story.append(PageBreak())\n",
    "        \n",
    "        # ===== PROCESS EACH CLAIM WITH FULL DETAIL =====\n",
    "        for idx, fact_check in enumerate(report_data['fact_checks'], 1):\n",
    "            # Claim header\n",
    "            story.append(Paragraph(f\"CLAIM #{idx}\", self.styles['ClaimNumber']))\n",
    "            story.append(Spacer(1, 0.08*inch))\n",
    "            \n",
    "            # Original claim\n",
    "            original = self.clean_text(fact_check.get('original_claim', 'N/A'))\n",
    "            story.append(Paragraph(f\"<b>Original Claim:</b><br/>{original}\", self.styles['DetailText']))\n",
    "            story.append(Spacer(1, 0.1*inch))\n",
    "            \n",
    "            # ===== AGENT 1: DETECTION =====\n",
    "            agent1 = fact_check.get('agent1_detection', {})\n",
    "            story.append(Paragraph(\"ğŸ” AGENT 1: CLAIM DETECTION & ANALYSIS\", self.styles['AgentHeader']))\n",
    "            \n",
    "            a1_details = f\"\"\"\n",
    "            <b>Claim Type:</b> {self.clean_text(agent1.get('claim_type'))}<br/>\n",
    "            <b>Climate Related:</b> {self.clean_text(agent1.get('is_climate_related'))}<br/>\n",
    "            <b>Confidence:</b> {agent1.get('confidence', 0):.2f}<br/>\n",
    "            <b>Needs Verification:</b> {self.clean_text(agent1.get('needs_verification'))}<br/>\n",
    "            <b>Keywords Detected:</b> {', '.join(agent1.get('keywords', [])) or 'N/A'}<br/>\n",
    "            <b>Reasoning:</b><br/>{self.clean_text(agent1.get('reasoning'), max_len=800)}\n",
    "            \"\"\"\n",
    "            story.append(Paragraph(a1_details, self.styles['DetailText']))\n",
    "            story.append(Spacer(1, 0.12*inch))\n",
    "            \n",
    "            # ===== AGENT 2: VERIFICATION =====\n",
    "            agent2 = fact_check.get('agent2_verification', {})\n",
    "            story.append(Paragraph(\"âœ“ AGENT 2: SOURCE VERIFICATION & FACT-CHECK\", self.styles['AgentHeader']))\n",
    "            \n",
    "            a2_details = f\"\"\"\n",
    "            <b>Verdict:</b> {self.clean_text(agent2.get('verdict'))}<br/>\n",
    "            <b>Scientific Consensus:</b> {agent2.get('scientific_consensus', 0)}%<br/>\n",
    "            <b>Verification Confidence:</b> {agent2.get('confidence', 0):.2f}<br/>\n",
    "            <b>Authoritative Sources Used:</b> {', '.join(agent2.get('authoritative_sources', [])) or 'N/A'}<br/>\n",
    "            <b>Explanation:</b><br/>{self.clean_text(agent2.get('explanation'), max_len=1000)}<br/><br/>\n",
    "            <b>Supporting Evidence:</b><br/>\n",
    "            \"\"\"\n",
    "            for evidence in agent2.get('supporting_evidence', []):\n",
    "                a2_details += f\"â€¢ {self.clean_text(evidence, max_len=400)}<br/>\"\n",
    "            \n",
    "            a2_details += \"<br/><b>Contradicting Evidence:</b><br/>\"\n",
    "            for evidence in agent2.get('contradicting_evidence', []):\n",
    "                a2_details += f\"â€¢ {self.clean_text(evidence, max_len=400)}<br/>\"\n",
    "            \n",
    "            story.append(Paragraph(a2_details, self.styles['DetailText']))\n",
    "            story.append(Spacer(1, 0.12*inch))\n",
    "            \n",
    "            # ===== AGENT 3: SYNTHESIS =====\n",
    "            agent3 = fact_check.get('agent3_synthesis', {})\n",
    "            story.append(Paragraph(\"ğŸ“š AGENT 3: EVIDENCE SYNTHESIS & SUMMARY\", self.styles['AgentHeader']))\n",
    "            \n",
    "            a3_details = f\"\"\"\n",
    "            <b>Headline:</b> {self.clean_text(agent3.get('headline'), max_len=200)}<br/><br/>\n",
    "            <b>Summary:</b><br/>{self.clean_text(agent3.get('summary'), max_len=1200)}<br/><br/>\n",
    "            <b>Bottom Line:</b><br/>{self.clean_text(agent3.get('bottom_line'), max_len=600)}<br/><br/>\n",
    "            <b>Citations & References:</b><br/>\n",
    "            \"\"\"\n",
    "            for idx_cite, citation in enumerate(agent3.get('citations', []), 1):\n",
    "                if isinstance(citation, dict):\n",
    "                    a3_details += f\"{idx_cite}. <b>{self.clean_text(citation.get('source'))}</b>: {self.clean_text(citation.get('fact'), max_len=300)}<br/>\"\n",
    "                else:\n",
    "                    a3_details += f\"{idx_cite}. {self.clean_text(citation, max_len=300)}<br/>\"\n",
    "            \n",
    "            story.append(Paragraph(a3_details, self.styles['DetailText']))\n",
    "            story.append(Spacer(1, 0.12*inch))\n",
    "            \n",
    "            # ===== AGENT 4: CREDIBILITY =====\n",
    "            agent4 = fact_check.get('agent4_credibility', {})\n",
    "            story.append(Paragraph(\"â­ AGENT 4: CREDIBILITY ASSESSMENT\", self.styles['AgentHeader']))\n",
    "            \n",
    "            score = agent4.get('credibility_score', 0)\n",
    "            \n",
    "            a4_details = f\"\"\"\n",
    "            <b>Credibility Score:</b> {score}/100<br/>\n",
    "            <b>Rating:</b> {self.clean_text(agent4.get('rating'))}<br/><br/>\n",
    "            <b>Scoring Breakdown:</b><br/>\n",
    "            \"\"\"\n",
    "            for key, val in agent4.get('breakdown', {}).items():\n",
    "                a4_details += f\"â€¢ {key}: {val}<br/>\"\n",
    "            \n",
    "            a4_details += f\"<br/><b>Assessment Justification:</b><br/>{self.clean_text(agent4.get('justification'), max_len=800)}\"\n",
    "            \n",
    "            story.append(Paragraph(a4_details, self.styles['DetailText']))\n",
    "            story.append(Spacer(1, 0.12*inch))\n",
    "            \n",
    "            # ===== AGENT 5: COUNTER-NARRATIVE =====\n",
    "            agent5 = fact_check.get('agent5_counter_narrative', {})\n",
    "            story.append(Paragraph(\"ğŸ“± AGENT 5: COUNTER-NARRATIVE & SOCIAL MEDIA\", self.styles['AgentHeader']))\n",
    "            \n",
    "            social = agent5.get('social_media', {})\n",
    "            \n",
    "            a5_details = f\"\"\"\n",
    "            <b>Summary:</b><br/>{self.clean_text(agent5.get('short_summary'), max_len=500)}<br/><br/>\n",
    "            \n",
    "            <b>Twitter (280 chars):</b><br/>{self.clean_text(social.get('twitter_280'), max_len=300)}<br/><br/>\n",
    "            \n",
    "            <b>Twitter Extended:</b><br/>{self.clean_text(social.get('twitter_extended'), max_len=400)}<br/><br/>\n",
    "            \n",
    "            <b>Facebook Post:</b><br/>{self.clean_text(social.get('facebook_long'), max_len=500)}<br/><br/>\n",
    "            \n",
    "            <b>Instagram Caption:</b><br/>{self.clean_text(social.get('instagram_caption'), max_len=400)}<br/><br/>\n",
    "            \n",
    "            <b>LinkedIn Professional:</b><br/>{self.clean_text(social.get('linkedin_professional'), max_len=500)}<br/><br/>\n",
    "            \n",
    "            <b>TikTok Script:</b><br/>{self.clean_text(social.get('tiktok_script'), max_len=400)}<br/><br/>\n",
    "            \n",
    "            <b>Hashtags:</b> {' '.join(agent5.get('hashtags', [])) or 'N/A'}<br/>\n",
    "            <b>Call-to-Action:</b> {self.clean_text(agent5.get('call_to_action'), max_len=200)}\n",
    "            \"\"\"\n",
    "            \n",
    "            story.append(Paragraph(a5_details, self.styles['DetailText']))\n",
    "            story.append(PageBreak())\n",
    "        \n",
    "        # Build PDF\n",
    "        try:\n",
    "            doc.build(story)\n",
    "            print(f\"âœ… PDF GENERATED: {self.filename}\")\n",
    "            print(f\"ğŸ“Š Claims included: {len(report_data['fact_checks'])}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PDF Generation Error: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTE WITH VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LOADING JSON REPORT & GENERATING ENHANCED PDF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    with open('climate_fact_check_report.json', 'r') as f:\n",
    "        report_data = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… JSON loaded - {report_data['total_claims_analyzed']} claims found\")\n",
    "    \n",
    "    # Generate PDF\n",
    "    pdf_gen = EnhancedPDFGenerator()\n",
    "    success = pdf_gen.generate_pdf(report_data)\n",
    "    \n",
    "    if success:\n",
    "        import os\n",
    "        size_kb = os.path.getsize('Climate_FactCheck_Report_COMPLETE.pdf') / 1024\n",
    "        print(f\"âœ… File size: {size_kb:.1f} KB\")\n",
    "        print(\"\\nâœ¨ PDF WITH FULL AGENT DETAILS IS READY!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e31c536f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:46:53.677593Z",
     "iopub.status.busy": "2025-12-01T18:46:53.677265Z",
     "iopub.status.idle": "2025-12-01T18:46:53.698506Z",
     "shell.execute_reply": "2025-12-01T18:46:53.697150Z"
    },
    "papermill": {
     "duration": 0.034561,
     "end_time": "2025-12-01T18:46:53.700258",
     "exception": false,
     "start_time": "2025-12-01T18:46:53.665697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“¦ CREATING SUBMISSION OUTPUT FILES\n",
      "================================================================================\n",
      "âœ… JSON Report saved: climate_fact_check_report.json (0.4 KB)\n",
      "\n",
      "âŒ ERROR during file creation: name 'ProductionPDFGenerator' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13/162295594.py\", line 32, in <cell line: 0>\n",
      "    pdf_gen = ProductionPDFGenerator(pdf_path)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'ProductionPDFGenerator' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE SUBMISSION OUTPUT FILES\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“¦ CREATING SUBMISSION OUTPUT FILES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verify final_report exists\n",
    "if 'final_report' not in globals():\n",
    "    print(\"âŒ ERROR: final_report not found! Run all prior cells first.\")\n",
    "else:\n",
    "    try:\n",
    "        # 1. Save JSON Report\n",
    "        report_json_path = 'climate_fact_check_report.json'\n",
    "        with open(report_json_path, 'w') as f:\n",
    "            json.dump(final_report, f, indent=2)\n",
    "        \n",
    "        if os.path.exists(report_json_path):\n",
    "            size_kb = os.path.getsize(report_json_path) / 1024\n",
    "            print(f\"âœ… JSON Report saved: {report_json_path} ({size_kb:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"âŒ JSON save failed!\")\n",
    "        \n",
    "        # 2. Generate PDF\n",
    "        pdf_path = 'Climate_FactCheck_Report_COMPLETE.pdf'\n",
    "        pdf_gen = ProductionPDFGenerator(pdf_path)\n",
    "        pdf_gen.generate_pdf(final_report)\n",
    "        \n",
    "        if os.path.exists(pdf_path):\n",
    "            size_kb = os.path.getsize(pdf_path) / 1024\n",
    "            print(f\"âœ… PDF Report generated: {pdf_path} ({size_kb:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"âŒ PDF save failed!\")\n",
    "        \n",
    "        # 3. Create Summary CSV\n",
    "        csv_path = 'climate_fact_check_summary.csv'\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Claim_Number', 'Claim', 'Type', 'Verdict', 'Credibility_Score', 'Rating', 'Confidence']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            writer.writeheader()\n",
    "            for idx, fc in enumerate(final_report['fact_checks'], 1):\n",
    "                try:\n",
    "                    writer.writerow({\n",
    "                        'Claim_Number': idx,\n",
    "                        'Claim': fc['original_claim'][:100],\n",
    "                        'Type': fc['agent1_detection'].get('claim_type', 'N/A'),\n",
    "                        'Verdict': fc['agent2_verification'].get('verdict', 'N/A'),\n",
    "                        'Credibility_Score': round(fc['agent4_credibility'].get('credibility_score', 0), 1),\n",
    "                        'Rating': fc['agent4_credibility'].get('rating', 'N/A'),\n",
    "                        'Confidence': round(fc['agent2_verification'].get('confidence', 0), 2)\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸  Skipped row {idx}: {str(e)}\")\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            size_kb = os.path.getsize(csv_path) / 1024\n",
    "            print(f\"âœ… Summary CSV saved: {csv_path} ({size_kb:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"âŒ CSV save failed!\")\n",
    "        \n",
    "        # 4. Create Text Summary Report\n",
    "        txt_path = 'climate_fact_check_summary.txt'\n",
    "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(\"ğŸŒ CLIMATE FACT-CHECK REPORT SUMMARY\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Total Claims: {final_report['total_claims_analyzed']}\\n\")\n",
    "            f.write(f\"Successfully Processed: {final_report['successful_fact_checks']}\\n\")\n",
    "            f.write(f\"True Claims: {final_report['summary']['true_claims']}\\n\")\n",
    "            f.write(f\"False Claims: {final_report['summary']['false_claims']}\\n\")\n",
    "            f.write(f\"Average Credibility: {final_report['summary']['avg_credibility']:.1f}/100\\n\\n\")\n",
    "            \n",
    "            for idx, fc in enumerate(final_report['fact_checks'], 1):\n",
    "                f.write(f\"\\nCLAIM {idx}:\\n\")\n",
    "                f.write(f\"  Original: {fc['original_claim'][:150]}\\n\")\n",
    "                f.write(f\"  Verdict: {fc['agent2_verification'].get('verdict', 'N/A')}\\n\")\n",
    "                f.write(f\"  Credibility: {fc['agent4_credibility'].get('credibility_score', 'N/A')}/100\\n\")\n",
    "                f.write(f\"  Rating: {fc['agent4_credibility'].get('rating', 'N/A')}\\n\")\n",
    "        \n",
    "        if os.path.exists(txt_path):\n",
    "            size_kb = os.path.getsize(txt_path) / 1024\n",
    "            print(f\"âœ… Text Summary saved: {txt_path} ({size_kb:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"âŒ Text save failed!\")\n",
    "        \n",
    "        # Final confirmation\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ğŸ“¦ SUBMISSION FILES READY:\")\n",
    "        output_files = []\n",
    "        for fname in [report_json_path, pdf_path, csv_path, txt_path]:\n",
    "            if os.path.exists(fname):\n",
    "                size = os.path.getsize(fname)\n",
    "                output_files.append(f\"   âœ… {fname} ({size:,} bytes)\")\n",
    "        \n",
    "        print(\"\\n\".join(output_files))\n",
    "        print(f\"\\nğŸ¯ Total Output Files: {len(output_files)}/4\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ERROR during file creation: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14484960,
     "sourceId": 121144,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 125.902286,
   "end_time": "2025-12-01T18:46:57.114687",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T18:44:51.212401",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
