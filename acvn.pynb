{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7421e6b7",
   "metadata": {
    "papermill": {
     "duration": 0.006953,
     "end_time": "2025-12-01T18:26:28.014576",
     "exception": false,
     "start_time": "2025-12-01T18:26:28.007623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üåç Climate Misinformation Combat Agent\n",
    "\n",
    "## What's This Project About?\n",
    "\n",
    "Climate misinformation spreads like wildfire on social media. False claims about global warming, renewable energy, and climate science confuse people and slow down action. This project fights back.\n",
    "\n",
    "I built a smart AI system that automatically:\n",
    "- **Catches** false or misleading climate claims\n",
    "- **Verifies** them against real scientific sources (NASA, IPCC, NOAA)\n",
    "- **Explains** why they're wrong with evidence\n",
    "- **Creates** shareable counter-narratives for social media\n",
    "- **Generates** professional reports (PDF + JSON)\n",
    "\n",
    "Think of it as a fact-checking robot trained specifically for climate misinformation.\n",
    "\n",
    "---\n",
    "\n",
    "## The Problem\n",
    "\n",
    "Every day, millions see posts like:\n",
    "- \"Climate change is a hoax invented by China\"\n",
    "- \"Solar panels pollute more than they help\"\n",
    "- \"Arctic ice is actually increasing\"\n",
    "- \"A few degrees of warming won't hurt\"\n",
    "\n",
    "These claims sound plausible but they're **scientifically wrong**. The problem? There's no automated system to debunk them at scale across social media.\n",
    "\n",
    "---\n",
    "\n",
    "## The Solution: 5 AI Agents Working Together\n",
    "\n",
    "Instead of one big AI trying to do everything, I created 5 specialized agents. Each one is really good at one job:\n",
    "\n",
    "| Agent          |             Job        |                Example Output                |\n",
    "|----------------|------------------------|----------------------------------------------|\n",
    "| **Agent 1** üîç | Detects climate claims | \"This is climate denial, needs verification\" |\n",
    "| **Agent 2** ‚úì | Verifies against sources | \"FALSE - contradicts NASA data\" |\n",
    "| **Agent 3** üìö | Writes fact-checks | \"Why this claim is wrong: ...\" |\n",
    "| **Agent 4** ‚≠ê | Scores credibility | \"23/100 - Highly unreliable\" |\n",
    "| **Agent 5** üì± | Makes social posts | \"üö´ Myth: ... REALITY: ... #FactCheck\" |\n",
    "\n",
    "Each agent passes its output to the next. The final result? A complete fact-check package ready to share.\n",
    "\n",
    "---\n",
    "\n",
    "## How It Works (The Flow)\n",
    "\n",
    "\n",
    "1. Raw Climate Claim (from news, Reddit, Twitter)\n",
    "2. Agent 1: Detect & Classify\n",
    "3. Agent 2: Verify Against Sources\n",
    "4. Agent 3: Synthesize Evidence\n",
    "5. Agent 4: Calculate Score\n",
    "6. Agent 5: Generate Social PostsProfessional PDF + JSON Report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301d9a4",
   "metadata": {
    "papermill": {
     "duration": 0.005422,
     "end_time": "2025-12-01T18:26:28.025363",
     "exception": false,
     "start_time": "2025-12-01T18:26:28.019941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## What Makes This Different?\n",
    "\n",
    "‚úÖ **Real-time** - Scrapes live climate news and analyzes it  \n",
    "‚úÖ **Multi-agent** - 5 specialized AIs working together (not one doing everything)  \n",
    "‚úÖ **Evidence-based** - Checks against NASA, IPCC, NOAA (not just opinions)  \n",
    "‚úÖ **Social-ready** - Creates posts for Twitter, Facebook, Instagram, LinkedIn, TikTok  \n",
    "‚úÖ **Professional reports** - Beautiful PDFs + structured JSON data  \n",
    "‚úÖ **No truncation** - Full, complete outputs (not summaries)  \n",
    "\n",
    "---\n",
    "\n",
    "## Who Should Care?\n",
    "\n",
    "- üåç **Fact-checkers** - Automate climate claim verification\n",
    "- üì± **Social media teams** - Get ready-to-post counter-narratives\n",
    "- üéì **Researchers** - Study patterns in climate misinformation\n",
    "- üèõÔ∏è **NGOs/Governments** - Scale fact-checking operations\n",
    "- ü§ñ **AI enthusiasts** - Learn multi-agent architecture\n",
    "\n",
    "---\n",
    "\n",
    "## What I Learnt From This Project\n",
    "\n",
    "- How to build a **multi-agent AI system**\n",
    "- How to use **Google Gemini API** for complex tasks\n",
    "- How to **orchestrate AI agents** (one feeding into another)\n",
    "- How to **scrape live data** and process it\n",
    "- How to **generate professional PDFs** from AI outputs\n",
    "- How to structure code for **production use**\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Results Example\n",
    "\n",
    "**Input:** \"Arctic ice is increasing, not melting\"\n",
    "\n",
    "**Output:** \n",
    "\n",
    "Verdict: FALSE ‚ùå\n",
    "Credibility: 12/100 (Unreliable)\n",
    "Scientific Consensus: 97%\n",
    "\n",
    "Counter-Tweet:\n",
    "\"Myth check! üßä Arctic ice is DECLINING by 13% per decade, not increasing.\n",
    "NASA & NSIDC data confirms it. Trust the science. #FactCheck #ClimateReality\"\n",
    "\n",
    "Facebook Post:\n",
    "\"Let's debunk this one: Arctic sea ice is shrinking, not growing...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51a887",
   "metadata": {
    "papermill": {
     "duration": 0.005316,
     "end_time": "2025-12-01T18:26:28.035983",
     "exception": false,
     "start_time": "2025-12-01T18:26:28.030667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tech Stack (What Powers This)\n",
    "\n",
    "- **AI Engine:** Google Gemini 2.0 Flash API\n",
    "- **Language:** Python 3.11+\n",
    "- **PDF Generation:** ReportLab\n",
    "- **Web Scraping:** BeautifulSoup4, Requests\n",
    "- **Platform:** Kaggle Notebooks\n",
    "\n",
    "---\n",
    "\n",
    "## Ready to See It In Action?\n",
    "\n",
    "Keep scrolling! I'll walk you through each step of the pipeline, show you how the agents work, and end with real-world results.\n",
    "\n",
    "Let's fight climate misinformation with AI. üöÄ\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54f254",
   "metadata": {
    "papermill": {
     "duration": 0.005221,
     "end_time": "2025-12-01T18:26:28.046679",
     "exception": false,
     "start_time": "2025-12-01T18:26:28.041458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Connect to Gemini API\n",
    "\n",
    "Before we can fact-check anything, we need to connect to Google's Gemini AI. This is where the magic happens - Gemini is the brain behind all our agents.\n",
    "\n",
    "Here's what's happening:\n",
    "- We're pulling your API key securely from Kaggle Secrets (so it's not exposed in code)\n",
    "- Connecting to the latest Gemini model (2.5-flash - super fast)\n",
    "- Testing the connection to make sure everything works\n",
    "\n",
    "If you see \"**Climate Fact-Checker AI is online and ready!**\" below, you're good to go!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fd06da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:26:28.059504Z",
     "iopub.status.busy": "2025-12-01T18:26:28.058793Z",
     "iopub.status.idle": "2025-12-01T18:26:35.367998Z",
     "shell.execute_reply": "2025-12-01T18:26:35.367136Z"
    },
    "papermill": {
     "duration": 7.317063,
     "end_time": "2025-12-01T18:26:35.369249",
     "exception": false,
     "start_time": "2025-12-01T18:26:28.052186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Testing Gemini API connection...\n",
      "Climate Fact-Checker AI is online and ready!\n",
      "‚úÖ Gemini API connected successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "# Get Gemini API key from Kaggle Secrets\n",
    "user_secrets = UserSecretsClient()\n",
    "GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Configure Gemini with latest model\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "# Test Gemini connection\n",
    "print(\"üîÑ Testing Gemini API connection...\")\n",
    "response = model.generate_content(\"Respond with: 'Climate Fact-Checker AI is online and ready!'\")\n",
    "print(response.text)\n",
    "print(\"‚úÖ Gemini API connected successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d2c14",
   "metadata": {
    "papermill": {
     "duration": 0.005645,
     "end_time": "2025-12-01T18:26:35.380495",
     "exception": false,
     "start_time": "2025-12-01T18:26:35.374850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2: Install Everything We Need\n",
    "\n",
    "Before we can fact-check anything, we need to install some tools. Think of these as the equipment in our fact-checking lab:\n",
    "\n",
    "- **reportlab** - Makes professional PDFs\n",
    "- **google-generativeai** - Connects to Gemini AI (our brain)\n",
    "- **beautifulsoup4** - Scrapes news from the web\n",
    "- **requests** - Downloads web pages\n",
    "- **pandas** - Handles data tables\n",
    "- **json** - Stores/reads our reports\n",
    "\n",
    "This might take a minute or two. Once you see \"All dependencies installed successfully!\" you're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1138f5e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:26:35.392411Z",
     "iopub.status.busy": "2025-12-01T18:26:35.392151Z",
     "iopub.status.idle": "2025-12-01T18:26:47.974763Z",
     "shell.execute_reply": "2025-12-01T18:26:47.973828Z"
    },
    "papermill": {
     "duration": 12.590422,
     "end_time": "2025-12-01T18:26:47.976141",
     "exception": false,
     "start_time": "2025-12-01T18:26:35.385719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hreport lab is isntalled\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m‚úÖ All dependencies installed successfully!\n",
      "üì¶ Packages: Gemini AI, Web Scraping, Data Processing\n"
     ]
    }
   ],
   "source": [
    "# Climate Misinformation Combat Agent(Climate Guard AI) - Setup\n",
    "# Install required packages for fact-checking system\n",
    "\n",
    "!pip install -q reportlab\n",
    "print(\"report lab is isntalled\")\n",
    "!pip install -q google-generativeai requests beautifulsoup4 pandas\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json as json_lib\n",
    "import time\n",
    "\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")\n",
    "print(\"üì¶ Packages: Gemini AI, Web Scraping, Data Processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115644c2",
   "metadata": {
    "papermill": {
     "duration": 0.005563,
     "end_time": "2025-12-01T18:26:47.987550",
     "exception": false,
     "start_time": "2025-12-01T18:26:47.981987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3: Configure the System\n",
    "\n",
    "Now we set up the \"rules\" for our fact-checker. This is basically telling it:\n",
    "- **Where to find truth:** Which scientific sources to trust (NASA, IPCC, NOAA)\n",
    "- **What counts as real:** 97% of climate scientists agree = consensus\n",
    "- **How to score things:** What makes something credible? (peer review, government sources, scientific agreement)\n",
    "- **Types of lies to catch:** Climate denial, exaggeration, misleading data, cherry-picking, etc.\n",
    "\n",
    "We also load some sample claims to test with. These are common climate lies you probably hear all the time.\n",
    "\n",
    "Once this runs, you'll see our system is fully configured and ready to fact-check! üéØ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06118413",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T18:26:48.000984Z",
     "iopub.status.busy": "2025-12-01T18:26:47.999904Z",
     "iopub.status.idle": "2025-12-01T18:26:48.006625Z",
     "shell.execute_reply": "2025-12-01T18:26:48.005764Z"
    },
    "papermill": {
     "duration": 0.014859,
     "end_time": "2025-12-01T18:26:48.008077",
     "exception": false,
     "start_time": "2025-12-01T18:26:47.993218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded!\n",
      "üìä Scientific sources: 3 databases\n",
      "üéØ Consensus threshold: 97%\n",
      "üìã Sample claims for testing: 9\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Climate Fact-Checking System\n",
    "CONFIG = {\n",
    "    'scientific_sources': {\n",
    "        'NASA_GISS': 'https://climate.nasa.gov/vital-signs/global-temperature/',\n",
    "        'IPCC_AR6': 'https://www.ipcc.ch/report/ar6/wg1/',\n",
    "        'NOAA_Climate': 'https://www.climate.gov/news-features/understanding-climate',\n",
    "    },\n",
    "    'consensus_threshold': 97,  # 97% of climate scientists agree\n",
    "    'credibility_weights': {\n",
    "        'peer_reviewed': 0.4,\n",
    "        'government_source': 0.3,\n",
    "        'scientific_consensus': 0.3\n",
    "    },\n",
    "    'claim_types': [\n",
    "        'climate_denial',\n",
    "        'exaggeration',\n",
    "        'factual',\n",
    "        'misleading_data',\n",
    "        'cherry_picking'\n",
    "    ]\n",
    "}\n",
    "# Sample climate claims for testing (you can replace with real data)\n",
    "SAMPLE_CLAIMS = [\n",
    "    \"Electric vehicles are worse for the environment than gas cars\",\n",
    "    \"Solar panels create more pollution than they prevent\",\n",
    "    \"Nuclear power plants cause more deaths than coal\",\n",
    "    \"Planting trees is enough to stop climate change\",\n",
    "    \"The Arctic ice is actually increasing, not melting\",\n",
    "    \"Climate models have never been accurate\",\n",
    "    \"Volcanoes emit more CO2 than humans\",\n",
    "    \"A few degrees of warming won't make a difference\",\n",
    "    \"CO2  is a green house gas\",\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Configuration loaded!\")\n",
    "print(f\"üìä Scientific sources: {len(CONFIG['scientific_sources'])} databases\")\n",
    "print(f\"üéØ Consensus threshold: {CONFIG['consensus_threshold']}%\")\n",
    "print(f\"üìã Sample claims for testing: {len(SAMPLE_CLAIMS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70901da",
   "metadata": {
    "papermill": {
     "duration": 0.005855,
     "end_time": "2025-12-01T18:26:48.020056",
     "exception": false,
     "start_time": "2025-12-01T18:26:48.014201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4: Agent 1 - The Claim Detector\n",
    "\n",
    "This is our first AI agent. Think of it as a bouncer at a club - its job is to identify climate claims and figure out which ones look suspicious.\n",
    "\n",
    "**What it does:**\n",
    "- Reads a claim (like \"Solar panels pollute more than they help\")\n",
    "- Asks: \"Is this about climate?\"\n",
    "- Asks: \"What type of claim is this?\" (Is it denial? Exaggeration? Real fact?)\n",
    "- Asks: \"Do we need to fact-check this or is it already well-known?\"\n",
    "- Returns a score of how confident it is (0-100%)\n",
    "\n",
    "**What it outputs:**\n",
    "- Claim type (denial, exaggeration, factual, misleading, etc.)\n",
    "- Keywords from the claim\n",
    "- Whether it needs verification\n",
    "- Its confidence level\n",
    "\n",
    "Once this runs, you'll see which claims look fishy and which ones are probably legit. The ones marked \"Yes ‚ö†Ô∏è\" for verification will get passed to Agent 2 for deeper investigation. üîç\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf00deca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:26:48.032882Z",
     "iopub.status.busy": "2025-12-01T18:26:48.032585Z",
     "iopub.status.idle": "2025-12-01T18:27:33.154365Z",
     "shell.execute_reply": "2025-12-01T18:27:33.153239Z"
    },
    "papermill": {
     "duration": 45.130402,
     "end_time": "2025-12-01T18:27:33.156103",
     "exception": false,
     "start_time": "2025-12-01T18:26:48.025701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Agent 1: Detecting claims in 9 statements...\n",
      "  ‚Üí Processing claim 1/9...\n",
      "  ‚Üí Processing claim 2/9...\n",
      "  ‚Üí Processing claim 3/9...\n",
      "  ‚Üí Processing claim 4/9...\n",
      "  ‚Üí Processing claim 5/9...\n",
      "  ‚Üí Processing claim 6/9...\n",
      "  ‚Üí Processing claim 7/9...\n",
      "  ‚Üí Processing claim 8/9...\n",
      "  ‚Üí Processing claim 9/9...\n",
      "‚úÖ Agent 1 Complete: 9/9 claims analyzed\n",
      "üéØ Claims needing verification: 8\n",
      "\n",
      "üìä CLAIM DETECTION RESULTS:\n",
      "======================================================================\n",
      "\n",
      "1. Original: Electric vehicles are worse for the environment than gas car...\n",
      "   Type: misleading_data\n",
      "   Main Claim: Electric vehicles are worse for the environment than gas cars\n",
      "   Needs Verification: Yes ‚ö†Ô∏è\n",
      "   Confidence: 1.00\n",
      "\n",
      "2. Original: Solar panels create more pollution than they prevent...\n",
      "   Type: misleading_data\n",
      "   Main Claim: The pollution generated by the entire lifecycle of solar panels (manufacturing, transport, disposal) is greater than the pollution prevented by their electricity generation.\n",
      "   Needs Verification: Yes ‚ö†Ô∏è\n",
      "   Confidence: 1.00\n",
      "\n",
      "3. Original: Nuclear power plants cause more deaths than coal...\n",
      "   Type: misleading_data\n",
      "   Main Claim: Nuclear power plants cause more deaths than coal\n",
      "   Needs Verification: Yes ‚ö†Ô∏è\n",
      "   Confidence: 1.00\n",
      "\n",
      "4. Original: Planting trees is enough to stop climate change...\n",
      "   Type: exaggeration\n",
      "   Main Claim: Planting trees alone is sufficient to stop climate change.\n",
      "   Needs Verification: Yes ‚ö†Ô∏è\n",
      "   Confidence: 1.00\n",
      "\n",
      "5. Original: The Arctic ice is actually increasing, not melting...\n",
      "   Type: climate_denial\n",
      "   Main Claim: Arctic ice is increasing\n",
      "   Needs Verification: Yes ‚ö†Ô∏è\n",
      "   Confidence: 1.00\n",
      "\n",
      "6. Original: Climate models have never been accurate...\n",
      "   Type: climate_denial\n",
      "   Main Claim: Climate models have never been accurate\n",
      "   Needs Verification: Yes ‚ö†Ô∏è\n",
      "   Confidence: 1.00\n",
      "\n",
      "7. Original: Volcanoes emit more CO2 than humans...\n",
      "   Type: climate_denial\n",
      "   Main Claim: Volcanoes emit more CO2 than humans\n",
      "   Needs Verification: Yes ‚ö†Ô∏è\n",
      "   Confidence: 1.00\n",
      "\n",
      "8. Original: A few degrees of warming won't make a difference...\n",
      "   Type: climate_denial\n",
      "   Main Claim: A few degrees of global warming will not have a significant impact.\n",
      "   Needs Verification: Yes ‚ö†Ô∏è\n",
      "   Confidence: 1.00\n",
      "\n",
      "9. Original: CO2  is a green house gas...\n",
      "   Type: factual\n",
      "   Main Claim: CO2 is a greenhouse gas\n",
      "   Needs Verification: No ‚úì\n",
      "   Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 1 - CLASSIFIES CLAIMS INTO CATEGORIES \n",
    "# ============================================================================\n",
    "class ClaimDetectorAgent:\n",
    "    \"\"\"Agent 1: Detects and classifies climate-related claims\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.detected_claims = []\n",
    "    \n",
    "    def detect_claim(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze text and detect climate claims\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"You are a climate science fact-checker. Analyze this statement:\n",
    "\n",
    "\"{text}\"\n",
    "\n",
    "Classify this claim in JSON format:\n",
    "{{\n",
    "    \"is_climate_related\": <true/false>,\n",
    "    \"claim_type\": \"<one of: climate_denial, exaggeration, factual, misleading_data, cherry_picking, neutral>\",\n",
    "    \"main_claim\": \"<extract the core scientific claim>\",\n",
    "    \"confidence\": <0.0 to 1.0>,\n",
    "    \"keywords\": [\"keyword1\", \"keyword2\"],\n",
    "    \"needs_verification\": <true/false>,\n",
    "    \"reasoning\": \"<brief explanation>\"\n",
    "}}\n",
    "\n",
    "CRITICAL INSTRUCTION FOR needs_verification:\n",
    "- Set to TRUE for: conspiracy theories, false claims, misleading statements, denialism, exaggerations\n",
    "- Set to FALSE for: neutral statements, well-established scientific facts\n",
    "- Examples that need verification: \"hoax\", \"not a greenhouse gas\", \"temperatures haven't increased\"\n",
    "- Examples that don't: \"97% of scientists agree\" (already documented fact)\n",
    "\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text_response = response.text\n",
    "            \n",
    "            # Remove markdown fences if present\n",
    "            text_response = text_response.replace('``````', '').strip()\n",
    "            \n",
    "            # Extract JSON\n",
    "            json_start = text_response.find('{')\n",
    "            json_end = text_response.rfind('}') + 1\n",
    "            \n",
    "            if json_start == -1 or json_end <= json_start:\n",
    "                raise ValueError(\"No valid JSON found in response\")\n",
    "            \n",
    "            result = json.loads(text_response[json_start:json_end])\n",
    "            \n",
    "            result['original_text'] = text\n",
    "            result['status'] = 'success'\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'original_text': text,\n",
    "                'status': 'error',\n",
    "                'error_message': str(e),\n",
    "                'needs_verification': False\n",
    "            }\n",
    "    \n",
    "    def execute(self, claims: List[str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process multiple claims\"\"\"\n",
    "        print(f\"üîç Agent 1: Detecting claims in {len(claims)} statements...\")\n",
    "        \n",
    "        results = []\n",
    "        for i, claim in enumerate(claims, 1):\n",
    "            print(f\"  ‚Üí Processing claim {i}/{len(claims)}...\")\n",
    "            result = self.detect_claim(claim)\n",
    "            results.append(result)\n",
    "        \n",
    "        successful = sum(1 for r in results if r['status'] == 'success')\n",
    "        verified_needed = sum(1 for r in results if r.get('needs_verification', False))\n",
    "        \n",
    "        print(f\"‚úÖ Agent 1 Complete: {successful}/{len(claims)} claims analyzed\")\n",
    "        print(f\"üéØ Claims needing verification: {verified_needed}\")\n",
    "        \n",
    "        self.detected_claims = results\n",
    "        return results\n",
    "\n",
    "# Test Agent 1 (FIXED VERSION)\n",
    "agent1 = ClaimDetectorAgent(model, CONFIG)\n",
    "detected_claims = agent1.execute(SAMPLE_CLAIMS)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìä CLAIM DETECTION RESULTS:\")\n",
    "print(\"=\" * 70)\n",
    "for i, claim in enumerate(detected_claims, 1):\n",
    "    if claim['status'] == 'success':\n",
    "        print(f\"\\n{i}. Original: {claim['original_text'][:60]}...\")\n",
    "        print(f\"   Type: {claim.get('claim_type', 'Unknown')}\")\n",
    "        print(f\"   Main Claim: {claim.get('main_claim', 'N/A')}\")\n",
    "        print(f\"   Needs Verification: {'Yes ‚ö†Ô∏è' if claim.get('needs_verification') else 'No ‚úì'}\")\n",
    "        print(f\"   Confidence: {claim.get('confidence', 0):.2f}\")\n",
    "    else:\n",
    "        print(f\"\\n{i}. ‚ùå ERROR: {claim.get('error_message', 'Unknown error')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf35c2",
   "metadata": {
    "papermill": {
     "duration": 0.006005,
     "end_time": "2025-12-01T18:27:33.168447",
     "exception": false,
     "start_time": "2025-12-01T18:27:33.162442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 5: Agent 2 - The Fact Checker\n",
    "\n",
    "Now things get serious. Agent 1 flagged suspicious claims, and Agent 2's job is to verify them against real science.\n",
    "\n",
    "**What it does:**\n",
    "- Takes a claim from Agent 1\n",
    "- Checks it against a database of verified scientific facts (from NASA, IPCC, NOAA)\n",
    "- Asks Gemini: \"Is this TRUE or FALSE based on what we know?\"\n",
    "- Finds evidence that supports or contradicts the claim\n",
    "- Gives a final verdict with a confidence score\n",
    "\n",
    "**What it outputs:**\n",
    "- Verdict: TRUE, FALSE, MISLEADING, or UNVERIFIABLE\n",
    "- Scientific consensus percentage (e.g., \"97% of scientists agree\")\n",
    "- Evidence supporting the correct position\n",
    "- Evidence contradicting the false claim\n",
    "- Which authoritative sources back this up\n",
    "- A clear explanation of why it's right or wrong\n",
    "\n",
    "This is where the rubber meets the road. False claims get exposed here with citations and data. ‚úì\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25642f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:27:33.182633Z",
     "iopub.status.busy": "2025-12-01T18:27:33.182362Z",
     "iopub.status.idle": "2025-12-01T18:28:54.682678Z",
     "shell.execute_reply": "2025-12-01T18:28:54.681355Z"
    },
    "papermill": {
     "duration": 81.509531,
     "end_time": "2025-12-01T18:28:54.684438",
     "exception": false,
     "start_time": "2025-12-01T18:27:33.174907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¨ Agent 2: Verifying claims against scientific sources...\n",
      "  ‚Üí Processing claim 1/9...\n",
      "  ‚Üí Processing claim 2/9...\n",
      "  ‚Üí Processing claim 3/9...\n",
      "  ‚Üí Processing claim 4/9...\n",
      "  ‚Üí Processing claim 5/9...\n",
      "  ‚Üí Processing claim 6/9...\n",
      "  ‚Üí Processing claim 7/9...\n",
      "  ‚Üí Processing claim 8/9...\n",
      "  ‚Üí Processing claim 9/9...\n",
      "‚úÖ Agent 2 Complete: 8/9 claims verified\n",
      "\n",
      "üî¨ VERIFICATION RESULTS:\n",
      "================================================================================\n",
      "\n",
      "1. CLAIM: Electric vehicles are worse for the environment than gas cars...\n",
      "   üìã Type: misleading_data\n",
      "   ‚úì VERDICT: FALSE\n",
      "   üìä Scientific Consensus: 90%\n",
      "   üîó Sources: IPCC, NASA, NOAA\n",
      "   üí° Explanation: The claim is false. While electric vehicle battery manufacturing has an initial carbon footprint, EVs produce zero tailpipe emissions, leading to significantly lower overall lifecycle greenhouse gas emissions than gasoline cars. As electricity grids become cleaner, the environmental advantages of EVs continue to increase.\n",
      "   üéØ Confidence: 0.98\n",
      "\n",
      "2. CLAIM: The pollution generated by the entire lifecycle of solar panels (manuf...\n",
      "   üìã Type: misleading_data\n",
      "   ‚úì VERDICT: FALSE\n",
      "   üìä Scientific Consensus: 95%\n",
      "   üîó Sources: IPCC, International Energy Agency (IEA), National Renewable Energy Laboratory (NREL), Academic journals specializing in Life Cycle Assessment\n",
      "   üí° Explanation: The claim is false. Extensive lifecycle assessments consistently show that solar panels prevent significantly more pollution, primarily greenhouse gas emissions, through their clean electricity generation than is caused by their manufacturing, transport, and disposal. Over their typical 25-30 year lifespan, solar panels provide a substantial net reduction in overall emissions, making them a crucial tool for mitigating climate change.\n",
      "   üéØ Confidence: 1.00\n",
      "\n",
      "3. CLAIM: Nuclear power plants cause more deaths than coal...\n",
      "   üìã Type: misleading_data\n",
      "   ‚úì VERDICT: FALSE\n",
      "   üìä Scientific Consensus: 100%\n",
      "   üîó Sources: NASA, IPCC, NOAA\n",
      "   üí° Explanation: The claim is false. Data consistently show that coal-fired power plants cause significantly more deaths per unit of energy produced, primarily due to chronic illnesses from air pollution, than nuclear power plants. Nuclear power has one of the lowest fatality rates per unit of energy among major electricity sources.\n",
      "   üéØ Confidence: 1.00\n",
      "\n",
      "4. CLAIM: Planting trees alone is sufficient to stop climate change....\n",
      "   üìã Type: exaggeration\n",
      "   ‚úì VERDICT: FALSE\n",
      "   üìä Scientific Consensus: 97%\n",
      "   üîó Sources: NASA, IPCC, NOAA\n",
      "   üí° Explanation: While planting trees is a valuable tool for sequestering carbon dioxide and is part of the solution, it is not sufficient on its own to stop climate change. The primary drivers of climate change also include emissions from fossil fuels, which must be drastically reduced alongside reforestation efforts.\n",
      "   üéØ Confidence: 1.00\n",
      "\n",
      "5. CLAIM: Arctic ice is increasing...\n",
      "   üìã Type: climate_denial\n",
      "   ‚úì VERDICT: FALSE\n",
      "   üìä Scientific Consensus: 100%\n",
      "   üîó Sources: NSIDC, NASA, IPCC, NOAA\n",
      "   üí° Explanation: The claim that Arctic ice is increasing is false. Scientific data from organizations like NSIDC clearly show that Arctic sea ice is declining at a rate of 13% per decade. This trend is a well-documented consequence of rising global temperatures caused by human activity.\n",
      "   üéØ Confidence: 1.00\n",
      "\n",
      "6. CLAIM: Climate models have never been accurate...\n",
      "   üìã Type: climate_denial\n",
      "   ‚úì VERDICT: FALSE\n",
      "   üìä Scientific Consensus: 100%\n",
      "   üîó Sources: NASA, IPCC, NOAA\n",
      "   üí° Explanation: The claim that 'climate models have never been accurate' is false. Climate models, built on established physical laws, have successfully reproduced past observed global temperature increases and broadly projected long-term warming trends consistent with observations. While uncertainties exist, their overall skill in simulating and projecting climate change is well-established by the scientific community.\n",
      "   üéØ Confidence: 1.00\n",
      "\n",
      "7. CLAIM: Volcanoes emit more CO2 than humans...\n",
      "   üìã Type: climate_denial\n",
      "   ‚úì VERDICT: FALSE\n",
      "   üìä Scientific Consensus: 97%\n",
      "   üîó Sources: IPCC, NASA\n",
      "   üí° Explanation: Scientific data unequivocally shows that human activities, primarily the burning of fossil fuels, emit vastly more CO2 annually than all volcanoes combined. The scientific consensus is that human emissions are the primary driver of the rapid increase in atmospheric CO2 and subsequent global warming, directly contradicting the claim that volcanoes emit more.\n",
      "   üéØ Confidence: 1.00\n",
      "\n",
      "8. CLAIM: A few degrees of global warming will not have a significant impact....\n",
      "   üìã Type: climate_denial\n",
      "   ‚úì VERDICT: FALSE\n",
      "   üìä Scientific Consensus: 97%\n",
      "   üîó Sources: NASA, IPCC, NOAA, NSIDC\n",
      "   üí° Explanation: Even a 1.1¬∞C increase in global temperature, already observed, has led to significant impacts such as rising sea levels, Arctic ice melt, and more frequent and intense extreme weather events. These impacts are projected to worsen considerably with every additional fraction of a degree of warming, posing substantial threats to ecosystems and human societies worldwide.\n",
      "   üéØ Confidence: 1.00\n",
      "\n",
      "9. ‚ùå ERROR: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\n",
      "Please retry in 5.447120488s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 2 - SOURCE VERIFIER \n",
    "# ============================================================================\n",
    "class SourceVerifierAgent:\n",
    "    \"\"\"Agent 2: Verifies claims against scientific databases\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.scientific_facts = self._load_scientific_facts()\n",
    "    \n",
    "    def _load_scientific_facts(self) -> Dict[str, str]:\n",
    "        \"\"\"Load verified scientific facts about climate\"\"\"\n",
    "        return {\n",
    "            'global_warming': 'Global average temperature has increased by approximately 1.1¬∞C since pre-industrial times (1850-1900). Source: IPCC AR6 2021',\n",
    "            'scientific_consensus': '97% of actively publishing climate scientists agree that humans are causing global warming. Source: Cook et al. 2013',\n",
    "            'co2_greenhouse': 'CO2 is a greenhouse gas that traps heat in the atmosphere. This is established physics since the 1800s. Source: NASA',\n",
    "            'human_cause': 'Human activities (fossil fuels, deforestation) are the primary cause of recent warming. Source: IPCC AR6 WG1',\n",
    "            'temperature_trend': 'The past decade (2011-2020) was the warmest on record. Source: NOAA, NASA GISS',\n",
    "            'sea_level_rise': 'Global sea level has risen about 8-9 inches since 1880. Source: NASA',\n",
    "            'ice_melt': 'Arctic sea ice is declining at a rate of 13% per decade. Source: NSIDC',\n",
    "            'extreme_weather': 'Climate change is increasing the frequency and intensity of extreme weather events. Source: IPCC AR6 WG1'\n",
    "        }\n",
    "    \n",
    "    def verify_claim(self, claim_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Verify a claim against scientific sources\"\"\"\n",
    "        try:\n",
    "            main_claim = claim_data.get('main_claim', '')\n",
    "            claim_type = claim_data.get('claim_type', 'unknown').lower()\n",
    "            \n",
    "            # Flexible verification triggers - checks for keywords instead of exact matches\n",
    "            should_verify = any([\n",
    "                'false' in claim_type,\n",
    "                'conspiracy' in claim_type,\n",
    "                'mislead' in claim_type,\n",
    "                'denial' in claim_type,\n",
    "                'hoax' in claim_type,\n",
    "                'factual' in claim_type,  # Added: factual claims need verification\n",
    "                claim_data.get('confidence', 1.0) < 0.5,  # Low confidence claims\n",
    "                claim_data.get('needs_verification', False)\n",
    "            ])\n",
    "            \n",
    "            if not should_verify:\n",
    "                return {\n",
    "                    'claim': main_claim,\n",
    "                    'verification_needed': False,\n",
    "                    'status': 'skipped',\n",
    "                    'reason': f'Claim type \"{claim_type}\" does not require verification'\n",
    "                }\n",
    "            \n",
    "            prompt = f\"\"\"You are a climate scientist fact-checker. Verify this claim:\n",
    "\n",
    "CLAIM: \"{main_claim}\"\n",
    "CLAIM TYPE: {claim_type}\n",
    "\n",
    "VERIFIED SCIENTIFIC FACTS:\n",
    "{json.dumps(self.scientific_facts, indent=2)}\n",
    "\n",
    "Analyze the claim against scientific consensus. Respond ONLY with valid JSON (no markdown, no extra text):\n",
    "{{\n",
    "    \"verdict\": \"TRUE/FALSE/MISLEADING/UNVERIFIABLE\",\n",
    "    \"scientific_consensus\": <0-100 percentage of scientists who agree with the CORRECT position>,\n",
    "    \"supporting_evidence\": [\"evidence that supports the CORRECT position\"],\n",
    "    \"contradicting_evidence\": [\"evidence that contradicts the CLAIM if it's false\"],\n",
    "    \"authoritative_sources\": [\"NASA\", \"IPCC\", \"NOAA\"],\n",
    "    \"explanation\": \"Clear 2-3 sentence explanation of why the claim is true/false\",\n",
    "    \"confidence\": <0.0 to 1.0>\n",
    "}}\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text_response = response.text.strip()\n",
    "            \n",
    "            # Remove markdown code fences if present\n",
    "            text_response = text_response.replace('``````', '').strip()\n",
    "            \n",
    "            # Extract JSON robustly\n",
    "            json_start = text_response.find('{')\n",
    "            json_end = text_response.rfind('}') + 1\n",
    "            \n",
    "            if json_start == -1 or json_end <= json_start:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "            \n",
    "            result = json.loads(text_response[json_start:json_end])\n",
    "            \n",
    "            result['original_claim'] = main_claim\n",
    "            result['claim_type'] = claim_type\n",
    "            result['status'] = 'success'\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\n",
    "                'original_claim': claim_data.get('main_claim', ''),\n",
    "                'status': 'error',\n",
    "                'error_type': 'JSON_PARSE_ERROR',\n",
    "                'error_message': f\"Could not parse JSON: {str(e)}\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'original_claim': claim_data.get('main_claim', ''),\n",
    "                'status': 'error',\n",
    "                'error_type': type(e).__name__,\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    def execute(self, detected_claims: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Verify all detected claims\"\"\"\n",
    "        print(f\"\\nüî¨ Agent 2: Verifying claims against scientific sources...\")\n",
    "        \n",
    "        results = []\n",
    "        verification_count = 0\n",
    "        \n",
    "        for i, claim in enumerate(detected_claims, 1):\n",
    "            if claim.get('status') == 'success':\n",
    "                print(f\"  ‚Üí Processing claim {i}/{len(detected_claims)}...\")\n",
    "                result = self.verify_claim(claim)\n",
    "                if result.get('status') == 'success':\n",
    "                    verification_count += 1\n",
    "                results.append(result)\n",
    "            else:\n",
    "                results.append({'status': 'skipped', 'reason': 'Claim detection failed'})\n",
    "        \n",
    "        successful = sum(1 for r in results if r.get('status') == 'success')\n",
    "        print(f\"‚úÖ Agent 2 Complete: {successful}/{len(detected_claims)} claims verified\\n\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test Agent 2\n",
    "agent2 = SourceVerifierAgent(model, CONFIG)\n",
    "verified_claims = agent2.execute(detected_claims)\n",
    "\n",
    "# Display results\n",
    "print(\"üî¨ VERIFICATION RESULTS:\")\n",
    "print(\"=\" * 80)\n",
    "for i, result in enumerate(verified_claims, 1):\n",
    "    if result.get('status') == 'success':\n",
    "        print(f\"\\n{i}. CLAIM: {result.get('original_claim', '')[:70]}...\")\n",
    "        print(f\"   üìã Type: {result.get('claim_type', 'unknown')}\")\n",
    "        print(f\"   ‚úì VERDICT: {result.get('verdict', 'N/A').upper()}\")\n",
    "        print(f\"   üìä Scientific Consensus: {result.get('scientific_consensus', 0)}%\")\n",
    "        print(f\"   üîó Sources: {', '.join(result.get('authoritative_sources', []))}\")\n",
    "        print(f\"   üí° Explanation: {result.get('explanation', '')}\")\n",
    "        print(f\"   üéØ Confidence: {result.get('confidence', 0):.2f}\")\n",
    "    elif result.get('status') == 'error':\n",
    "        print(f\"\\n{i}. ‚ùå ERROR: {result.get('error_message', 'Unknown error')}\")\n",
    "    else:\n",
    "        print(f\"\\n{i}. ‚è≠Ô∏è  SKIPPED: {result.get('reason', 'Unknown reason' )}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f400a",
   "metadata": {
    "papermill": {
     "duration": 0.006618,
     "end_time": "2025-12-01T18:28:54.697913",
     "exception": false,
     "start_time": "2025-12-01T18:28:54.691295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 6: Agent 3 - The Evidence Synthesizer\n",
    "\n",
    "Agent 2 found the truth. Now Agent 3's job is to explain it in a way regular people understand.\n",
    "\n",
    "**What it does:**\n",
    "- Takes the verified information from Agent 2\n",
    "- Writes a clear, accessible fact-check (not jargon-filled)\n",
    "- Pulls out the key evidence points\n",
    "- Organizes citations with sources and URLs\n",
    "- Creates a punchy \"bottom line\" that explains what's really going on\n",
    "\n",
    "**What it outputs:**\n",
    "- A headline that grabs attention\n",
    "- A 2-3 sentence summary anyone can understand\n",
    "- Key evidence points (bullet points, easy to read)\n",
    "- What science actually says\n",
    "- Citations with sources and links\n",
    "- A clear bottom-line takeaway\n",
    "\n",
    "Think of it as translating \"science speak\" into \"human speak.\" This is what gets shared on social media and fact-checking websites. üìö\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c80a401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:28:54.713037Z",
     "iopub.status.busy": "2025-12-01T18:28:54.712717Z",
     "iopub.status.idle": "2025-12-01T18:29:11.255615Z",
     "shell.execute_reply": "2025-12-01T18:29:11.254683Z"
    },
    "papermill": {
     "duration": 16.55228,
     "end_time": "2025-12-01T18:29:11.256794",
     "exception": false,
     "start_time": "2025-12-01T18:28:54.704514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Agent 3: Synthesizing evidence into fact-checks...\n",
      "  ‚Üí Creating fact-check 1...\n",
      "  ‚Üí Creating fact-check 2...\n",
      "  ‚Üí Creating fact-check 3...\n",
      "  ‚Üí Creating fact-check 4...\n",
      "  ‚Üí Creating fact-check 5...\n",
      "  ‚Üí Creating fact-check 6...\n",
      "  ‚Üí Creating fact-check 7...\n",
      "  ‚Üí Creating fact-check 8...\n",
      "‚úÖ Agent 3 Complete: 2 fact-checks created\n",
      "\n",
      "üìö FACT-CHECK SUMMARIES:\n",
      "======================================================================\n",
      "\n",
      "1. Fact Check: Are Electric Vehicles Worse for the Environment Than Gas Cars? No, Science Says.\n",
      "   Verdict: FALSE\n",
      "   Summary: The claim that electric vehicles (EVs) are worse for the environment than gas cars is false. Scientific evidence, including numerous lifecycle analyses, consistently shows that EVs have a significantly lower overall carbon footprint over their lifetime compared to gasoline vehicles. As electricity grids become greener, the environmental advantages of EVs will only continue to grow.\n",
      "   Bottom Line: The scientific consensus is clear: Electric vehicles are a demonstrably cleaner and more environmentally friendly option than gasoline cars over their lifetime, and their benefits will only grow as power grids become greener.\n",
      "   Citations: 2 sources\n",
      "\n",
      "6. Fact Check: Climate Models Have Proven to Be Accurate and Reliable\n",
      "   Verdict: FALSE\n",
      "   Summary: The claim that 'climate models have never been accurate' is false. Climate models are built on established physical laws and have consistently demonstrated their ability to project long-term climate trends and attribute global warming to human activities, aligning closely with observational data and scientific understanding.\n",
      "   Bottom Line: Climate models are scientifically robust tools that have demonstrated significant accuracy in predicting and explaining global climate change, making the claim that they've 'never been accurate' demonstrably false.\n",
      "   Citations: 3 sources\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 3 - EVIDENCE SYNTHESIZER \n",
    "# ============================================================================\n",
    "class EvidenceSynthesizerAgent:\n",
    "    \"\"\"Agent 3: Synthesizes evidence into clear fact-checks\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def synthesize_evidence(self, verification_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Create clear fact-check from verification data\"\"\"\n",
    "        try:\n",
    "            if verification_data['status'] != 'success':\n",
    "                return {'status': 'skipped'}\n",
    "            \n",
    "            claim = verification_data.get('original_claim', '')\n",
    "            verdict = verification_data.get('verdict', '')\n",
    "            evidence = verification_data.get('supporting_evidence', [])\n",
    "            sources = verification_data.get('authoritative_sources', [])\n",
    "            \n",
    "            prompt = f\"\"\"Create a clear, accessible fact-check for the public:\n",
    "\n",
    "CLAIM: \"{claim}\"\n",
    "VERDICT: {verdict}\n",
    "EVIDENCE: {json.dumps(evidence)}\n",
    "SOURCES: {json.dumps(sources)}\n",
    "\n",
    "Generate a fact-check in JSON format:\n",
    "{{\n",
    "    \"headline\": \"\",\n",
    "    \"summary\": \"<2-3 sentence summary for general public>\",\n",
    "    \"key_evidence\": [\"point1\", \"point2\", \"point3\"],\n",
    "    \"what_science_says\": \"\",\n",
    "    \"citations\": [\n",
    "        {{\"source\": \"NASA\", \"fact\": \"specific fact\", \"url\": \"https://climate.nasa.gov/...\"}},\n",
    "        {{\"source\": \"IPCC\", \"fact\": \"specific fact\", \"url\": \"https://ipcc.ch/...\"}}\n",
    "    ],\n",
    "    \"bottom_line\": \"\"\n",
    "}}\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text_response = response.text\n",
    "            \n",
    "            # Extract JSON\n",
    "            json_start = text_response.find('{')\n",
    "            json_end = text_response.rfind('}') + 1\n",
    "            result = json.loads(text_response[json_start:json_end])\n",
    "            \n",
    "            result['original_claim'] = claim\n",
    "            result['verdict'] = verdict\n",
    "            result['status'] = 'success'\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    def execute(self, verified_claims: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Synthesize evidence for all verified claims\"\"\"\n",
    "        print(f\"üìö Agent 3: Synthesizing evidence into fact-checks...\")\n",
    "        \n",
    "        results = []\n",
    "        for i, claim in enumerate(verified_claims, 1):\n",
    "            if claim['status'] == 'success':\n",
    "                print(f\"  ‚Üí Creating fact-check {i}...\")\n",
    "                result = self.synthesize_evidence(claim)\n",
    "                results.append(result)\n",
    "            else:\n",
    "                results.append({'status': 'skipped'})\n",
    "        \n",
    "        successful = sum(1 for r in results if r['status'] == 'success')\n",
    "        print(f\"‚úÖ Agent 3 Complete: {successful} fact-checks created\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test Agent 3\n",
    "agent3 = EvidenceSynthesizerAgent(model)\n",
    "synthesized_evidence = agent3.execute(verified_claims)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìö FACT-CHECK SUMMARIES:\")\n",
    "print(\"=\" * 70)\n",
    "for i, result in enumerate(synthesized_evidence, 1):\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"\\n{i}. {result.get('headline', 'N/A')}\")\n",
    "        print(f\"   Verdict: {result.get('verdict', 'N/A')}\")\n",
    "        print(f\"   Summary: {result.get('summary', '')}\")\n",
    "        print(f\"   Bottom Line: {result.get('bottom_line', '')}\")\n",
    "        print(f\"   Citations: {len(result.get('citations', []))} sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901066a0",
   "metadata": {
    "papermill": {
     "duration": 0.006938,
     "end_time": "2025-12-01T18:29:11.271235",
     "exception": false,
     "start_time": "2025-12-01T18:29:11.264297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 7: Agent 4 - The Credibility Scorer\n",
    "\n",
    "Now we need to put a number on how trustworthy each claim actually is. Think of this like a credit score, but for facts.\n",
    "\n",
    "**What it does:**\n",
    "- Looks at how many peer-reviewed sources cited the claim (peer review score)\n",
    "- Checks if the sources are from trusted institutions like NASA, IPCC, NOAA (source quality)\n",
    "- Sees what percentage of scientists agree (scientific consensus)\n",
    "- Weights these three factors together using our formula\n",
    "\n",
    "**The Scoring Formula:**\n",
    "\n",
    "Final Score = (Peer Review √ó 40%) + (Source Quality √ó 30%) + (Consensus √ó 30%)\n",
    "\n",
    "\n",
    "**What it outputs:**\n",
    "- A score from 0-100\n",
    "- A rating: \"Highly Credible\" (80+), \"Credible\" (60-79), \"Questionable\" (40-59), or \"Not Credible\" (<40)\n",
    "- Breakdown of all three component scores\n",
    "- Count of trusted sources used\n",
    "\n",
    "This gives you a transparent, reproducible credibility rating for every single claim. No mystery‚Äîyou can see exactly how we got the score. ‚≠ê\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf1b51d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:29:11.286801Z",
     "iopub.status.busy": "2025-12-01T18:29:11.286545Z",
     "iopub.status.idle": "2025-12-01T18:29:11.300875Z",
     "shell.execute_reply": "2025-12-01T18:29:11.300126Z"
    },
    "papermill": {
     "duration": 0.023891,
     "end_time": "2025-12-01T18:29:11.302249",
     "exception": false,
     "start_time": "2025-12-01T18:29:11.278358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê Agent 4: Calculating credibility scores...\n",
      "  ‚Üí Scoring claim 1...\n",
      "  ‚Üí Scoring claim 6...\n",
      "‚úÖ Agent 4 Complete: 2 scores calculated\n",
      "\n",
      "‚≠ê CREDIBILITY SCORES:\n",
      "======================================================================\n",
      "\n",
      "1. Claim: Electric vehicles are worse for the environment th...\n",
      "   Verdict: FALSE\n",
      "   Credibility: 73.0/100 (Credible)\n",
      "   Breakdown:\n",
      "     - Peer Review: 40/100\n",
      "     - Source Quality: 100.0/100\n",
      "     - Scientific Consensus: 90/100\n",
      "\n",
      "6. Claim: Climate models have never been accurate...\n",
      "   Verdict: FALSE\n",
      "   Credibility: 84.0/100 (Highly Credible)\n",
      "   Breakdown:\n",
      "     - Peer Review: 60/100\n",
      "     - Source Quality: 100.0/100\n",
      "     - Scientific Consensus: 100/100\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 4 - GIVE CREDEBILITY SCORE \n",
    "# ============================================================================\n",
    "class CredibilityScorerAgent:\n",
    "    \"\"\"Agent 4: Calculates credibility scores for claims\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.weights = config['credibility_weights']\n",
    "    \n",
    "    def calculate_score(self, verification_data: Dict[str, Any], \n",
    "                       evidence_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate comprehensive credibility score\"\"\"\n",
    "        try:\n",
    "            if verification_data['status'] != 'success':\n",
    "                return {'status': 'skipped'}\n",
    "            \n",
    "            # Extract data\n",
    "            verdict = verification_data.get('verdict', '')\n",
    "            consensus = verification_data.get('scientific_consensus', 0)\n",
    "            sources = verification_data.get('authoritative_sources', [])\n",
    "            citations = evidence_data.get('citations', [])\n",
    "            \n",
    "            # Calculate component scores\n",
    "            # 1. Peer Review Score (0-100)\n",
    "            peer_review_score = min(len(citations) * 20, 100)  # Max 5 citations\n",
    "            \n",
    "            # 2. Source Quality Score (0-100)\n",
    "            trusted_sources = {'NASA', 'IPCC', 'NOAA', 'NSIDC'}\n",
    "            source_quality = (len([s for s in sources if s in trusted_sources]) / \n",
    "                            max(len(sources), 1) * 100) if sources else 0\n",
    "            \n",
    "            # 3. Scientific Consensus Score (0-100)\n",
    "            consensus_score = consensus\n",
    "            \n",
    "            # Weighted final score\n",
    "            final_score = (\n",
    "                peer_review_score * self.weights['peer_reviewed'] +\n",
    "                source_quality * self.weights['government_source'] +\n",
    "                consensus_score * self.weights['scientific_consensus']\n",
    "            )\n",
    "            \n",
    "            # Determine rating\n",
    "            if final_score >= 80:\n",
    "                rating = 'Highly Credible'\n",
    "            elif final_score >= 60:\n",
    "                rating = 'Credible'\n",
    "            elif final_score >= 40:\n",
    "                rating = 'Questionable'\n",
    "            else:\n",
    "                rating = 'Not Credible'\n",
    "            \n",
    "            return {\n",
    "                'claim': verification_data.get('original_claim', ''),\n",
    "                'verdict': verdict,\n",
    "                'credibility_score': round(final_score, 1),\n",
    "                'rating': rating,\n",
    "                'breakdown': {\n",
    "                    'peer_review': round(peer_review_score, 1),\n",
    "                    'source_quality': round(source_quality, 1),\n",
    "                    'scientific_consensus': round(consensus_score, 1)\n",
    "                },\n",
    "                'citations_count': len(citations),\n",
    "                'trusted_sources': len([s for s in sources if s in trusted_sources]),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    def execute(self, verified_claims: List[Dict[str, Any]], \n",
    "                synthesized_evidence: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Score all claims\"\"\"\n",
    "        print(f\"‚≠ê Agent 4: Calculating credibility scores...\")\n",
    "        \n",
    "        results = []\n",
    "        for i, (verification, evidence) in enumerate(zip(verified_claims, synthesized_evidence), 1):\n",
    "            if verification['status'] == 'success' and evidence['status'] == 'success':\n",
    "                print(f\"  ‚Üí Scoring claim {i}...\")\n",
    "                result = self.calculate_score(verification, evidence)\n",
    "                results.append(result)\n",
    "            else:\n",
    "                results.append({'status': 'skipped'})\n",
    "        \n",
    "        successful = sum(1 for r in results if r['status'] == 'success')\n",
    "        print(f\"‚úÖ Agent 4 Complete: {successful} scores calculated\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test Agent 4\n",
    "agent4 = CredibilityScorerAgent(CONFIG)\n",
    "credibility_scores = agent4.execute(verified_claims, synthesized_evidence)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n‚≠ê CREDIBILITY SCORES:\")\n",
    "print(\"=\" * 70)\n",
    "for i, result in enumerate(credibility_scores, 1):\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"\\n{i}. Claim: {result.get('claim', '')[:50]}...\")\n",
    "        print(f\"   Verdict: {result.get('verdict', 'N/A')}\")\n",
    "        print(f\"   Credibility: {result.get('credibility_score', 0)}/100 ({result.get('rating', '')})\")\n",
    "        print(f\"   Breakdown:\")\n",
    "        breakdown = result.get('breakdown', {})\n",
    "        print(f\"     - Peer Review: {breakdown.get('peer_review', 0)}/100\")\n",
    "        print(f\"     - Source Quality: {breakdown.get('source_quality', 0)}/100\")\n",
    "        print(f\"     - Scientific Consensus: {breakdown.get('scientific_consensus', 0)}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1421f6a",
   "metadata": {
    "papermill": {
     "duration": 0.007077,
     "end_time": "2025-12-01T18:29:11.316748",
     "exception": false,
     "start_time": "2025-12-01T18:29:11.309671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 8: Agent 5 - The Counter-Narrative Generator\n",
    "\n",
    "This is the final boss. Agent 5 takes everything we've learned and creates sharable content that actually changes minds.\n",
    "\n",
    "**What it does:**\n",
    "- Takes the verified information from all previous agents\n",
    "- Creates custom content for EVERY major social platform (Twitter, Facebook, Instagram, LinkedIn, TikTok)\n",
    "- Generates an infographic layout with key numbers and visual elements\n",
    "- Writes detailed explanations that address common misconceptions\n",
    "- Builds credibility markers and engagement hooks\n",
    "- Crafts a compelling call-to-action\n",
    "\n",
    "**What it outputs (COMPLETE PACKAGE):**\n",
    "- **Social Media Posts** - Pre-written, platform-optimized posts ready to share\n",
    "- **Infographic Text** - Visual layout suggestions with \"Myth vs. Reality\" comparisons\n",
    "- **Detailed Explanation** - Deep dive into WHY the claim is wrong\n",
    "- **Credibility Markers** - \"Here's what peer-reviewed research shows...\"\n",
    "- **Engagement Hooks** - Questions and surprising facts to spark conversation\n",
    "- **Hashtags** - Trending and topic-specific tags\n",
    "- **Call-to-Action** - Persuasive message encouraging shares\n",
    "- **Source Citations** - Full references with credibility explanations\n",
    "\n",
    "This is where the rubber REALLY meets the road‚Äîyou get a complete, ready-to-deploy counter-narrative package. No more \"I heard climate change is a hoax\" going unanswered. You have the facts, the framing, AND the reach. üì±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1559aed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:29:11.332746Z",
     "iopub.status.busy": "2025-12-01T18:29:11.332210Z",
     "iopub.status.idle": "2025-12-01T18:29:11.342648Z",
     "shell.execute_reply": "2025-12-01T18:29:11.341887Z"
    },
    "papermill": {
     "duration": 0.020499,
     "end_time": "2025-12-01T18:29:11.344191",
     "exception": false,
     "start_time": "2025-12-01T18:29:11.323692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent 5 (Counter-Narrative Generator) class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT 5 - COUNTER NARRATIVE GENERATOR\n",
    "# ============================================================================\n",
    "\n",
    "class CounterNarrativeGeneratorAgent:\n",
    "    \"\"\"Agent 5: Generates detailed, shareable counter-narratives with visual elements\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.counter_narratives = []\n",
    "    \n",
    "    def generate_narrative(self, verified_claim: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive counter-narrative\"\"\"\n",
    "        try:\n",
    "            original_claim = verified_claim.get('original_claim', '')\n",
    "            verdict = verified_claim.get('verdict', 'UNKNOWN')\n",
    "            explanation = verified_claim.get('explanation', '')\n",
    "            sources = verified_claim.get('authoritative_sources', [])\n",
    "            evidence = verified_claim.get('supporting_evidence', [])\n",
    "            \n",
    "            prompt = f\"\"\"You are an expert science communicator creating compelling counter-narratives to climate misinformation.\n",
    "\n",
    "MISINFORMATION: \"{original_claim}\"\n",
    "VERDICT: {verdict}\n",
    "SCIENTIFIC EXPLANATION: {explanation}\n",
    "AUTHORITATIVE SOURCES: {', '.join(sources)}\n",
    "SUPPORTING EVIDENCE: {', '.join(evidence)}\n",
    "\n",
    "Create a comprehensive, engaging counter-narrative package in JSON format:\n",
    "{{\n",
    "    \"verdict\": \"{verdict}\",\n",
    "    \"short_summary\": \"<1-sentence summary for busy readers>\",\n",
    "    \n",
    "    \"social_media\": {{\n",
    "        \"twitter_280\": \"<Tweet under 280 chars with emojis, fact, and #FactCheck>\",\n",
    "        \"twitter_extended\": \"<280-500 char version with more details and credibility markers>\",\n",
    "        \"facebook_long\": \"<800-1200 char detailed post with opening hook, explanation, and call-to-action>\",\n",
    "        \"instagram_caption\": \"<Caption with emojis, key takeaway, and save/share CTA>\",\n",
    "        \"linkedin_professional\": \"<Professional post for workplace/academic audience with sources>\",\n",
    "        \"tiktok_script\": \"<15-30 second video script with hook, main point, and CTA>\"\n",
    "    }},\n",
    "    \n",
    "    \"infographic_text\": {{\n",
    "        \"headline\": \"<Bold eye-catching headline>\",\n",
    "        \"claim_vs_reality\": [\n",
    "            {{\"false_claim\": \"...\", \"scientific_reality\": \"...\"}},\n",
    "            {{\"false_claim\": \"...\", \"scientific_reality\": \"...\"}}\n",
    "        ],\n",
    "        \"key_numbers\": [\"stat 1\", \"stat 2\", \"stat 3\"],\n",
    "        \"visual_elements\": [\"emoji suggestion 1\", \"emoji suggestion 2\"]\n",
    "    }},\n",
    "    \n",
    "    \"detailed_explanation\": {{\n",
    "        \"why_its_wrong\": \"<2-3 paragraphs explaining why the claim is false/misleading with concrete examples>\",\n",
    "        \"scientific_consensus\": \"<What the scientific community actually agrees on with percentages>\",\n",
    "        \"real_world_examples\": [\"example 1 with specifics\", \"example 2 with specifics\"],\n",
    "        \"common_misconceptions\": [\"misconception 1 addressed\", \"misconception 2 addressed\"]\n",
    "    }},\n",
    "    \n",
    "    \"credibility_markers\": [\n",
    "        \"peer-reviewed research showing...\",\n",
    "        \"official data from [SOURCE] demonstrates...\",\n",
    "        \"consensus among X% of scientists that...\"\n",
    "    ],\n",
    "    \n",
    "    \"engagement_hooks\": [\n",
    "        \"<Question to spark conversation>\",\n",
    "        \"<Surprising fact that engages audience>\",\n",
    "        \"<Personal impact statement>\"\n",
    "    ],\n",
    "    \n",
    "    \"hashtags\": [\"#FactCheck\", \"#ClimateScience\", \"#ScienceMatters\", \"<topic-specific tags>\"],\n",
    "    \n",
    "    \"call_to_action\": \"<Persuasive CTA encouraging shares, learning, or action>\",\n",
    "    \n",
    "    \"sources_cited\": [\n",
    "        {{\"source\": \"source name\", \"link\": \"url\", \"why_credible\": \"explanation\"}}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text_response = response.text.strip()\n",
    "            \n",
    "            # Remove markdown fences\n",
    "            text_response = text_response.replace('```json', '').replace('```', '').strip()\n",
    "            \n",
    "            # Extract JSON\n",
    "            json_start = text_response.find('{')\n",
    "            json_end = text_response.rfind('}') + 1\n",
    "            \n",
    "            if json_start == -1 or json_end <= json_start:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "            \n",
    "            result = json.loads(text_response[json_start:json_end])\n",
    "            result['original_misinformation'] = original_claim\n",
    "            result['status'] = 'success'\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'original_misinformation': original_claim,\n",
    "                'status': 'error',\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    def execute(self, verified_claims: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate counter-narratives for all verified claims\"\"\"\n",
    "        print(f\"\\n‚úçÔ∏è  Agent 5: Generating detailed counter-narratives...\")\n",
    "        \n",
    "        results = []\n",
    "        successful = 0\n",
    "        \n",
    "        for i, claim in enumerate(verified_claims, 1):\n",
    "            if claim.get('status') == 'success':\n",
    "                print(f\"  ‚Üí Creating counter-narrative {i}...\")\n",
    "                narrative = self.generate_narrative(claim)\n",
    "                if narrative.get('status') == 'success':\n",
    "                    successful += 1\n",
    "                results.append(narrative)\n",
    "            else:\n",
    "                results.append({'status': 'skipped', 'reason': 'Verification failed'})\n",
    "        \n",
    "        print(f\"‚úÖ Agent 5 Complete: {successful} counter-narratives created\\n\")\n",
    "        self.counter_narratives = results\n",
    "        return results\n",
    "    print(\"‚úÖ Agent 5 (Counter-Narrative Generator) class defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b343cd",
   "metadata": {
    "papermill": {
     "duration": 0.007119,
     "end_time": "2025-12-01T18:29:11.358825",
     "exception": false,
     "start_time": "2025-12-01T18:29:11.351706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 9: The Orchestrator - Bringing It All Together\n",
    "\n",
    "This is mission control. The Orchestrator is like a conductor leading a symphony of 5 AI agents, each playing their part in perfect harmony.\n",
    "\n",
    "**What it does:**\n",
    "1. **Takes in raw claims** (like \"Climate change is a hoax\")\n",
    "2. **Runs them through Agent 1** ‚Üí Claims get classified\n",
    "3. **Passes to Agent 2** ‚Üí Claims get fact-checked\n",
    "4. **Sends to Agent 3** ‚Üí Evidence gets synthesized\n",
    "5. **Goes to Agent 4** ‚Üí Credibility scores calculated\n",
    "6. **Finally to Agent 5** ‚Üí Counter-narratives generated\n",
    "7. **Compiles everything** into one comprehensive report\n",
    "\n",
    "**The Complete Pipeline:**\n",
    "Raw Claims ‚Üí Agent 1 ‚Üí Agent 2 ‚Üí Agent 3 ‚Üí Agent 4 ‚Üí Agent 5 ‚Üí Final Report\n",
    "\n",
    "\n",
    "**What it outputs:**\n",
    "- A complete JSON report with ALL agent outputs preserved (nothing gets lost)\n",
    "- Summary statistics (how many true/false, average credibility)\n",
    "- Timestamp of when it was generated\n",
    "- System configuration used\n",
    "- Ready to be saved or displayed\n",
    "\n",
    "**Key Features:**\n",
    "- Sequential execution (each agent feeds into the next)\n",
    "- Error handling (skips failed claims gracefully)\n",
    "- Full transparency (you can see what each agent did)\n",
    "- Exportable reports (saves to JSON for later use or PDF generation)\n",
    "- Beautiful summary display (human-readable results)\n",
    "\n",
    "Think of it like an assembly line: raw materials go in one end, a finished product comes out the other. üè≠\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cabf6d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:29:11.374765Z",
     "iopub.status.busy": "2025-12-01T18:29:11.374501Z",
     "iopub.status.idle": "2025-12-01T18:29:11.388662Z",
     "shell.execute_reply": "2025-12-01T18:29:11.387754Z"
    },
    "papermill": {
     "duration": 0.024059,
     "end_time": "2025-12-01T18:29:11.389989",
     "exception": false,
     "start_time": "2025-12-01T18:29:11.365930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Orchestrator class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ORCHESTRATOR \n",
    "# ============================================================================\n",
    "\n",
    "class ClimateFactCheckOrchestrator:\n",
    "    \"\"\"Orchestrates all 5 agents for complete fact-checking pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize all agents\n",
    "        self.agent1 = ClaimDetectorAgent(model, config)\n",
    "        self.agent2 = SourceVerifierAgent(model, config)\n",
    "        self.agent3 = EvidenceSynthesizerAgent(model)\n",
    "        self.agent4 = CredibilityScorerAgent(config)\n",
    "        self.agent5 = CounterNarrativeGeneratorAgent(model, config)\n",
    "    \n",
    "    def execute(self, claims: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute complete fact-checking pipeline\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"üåç CLIMATE MISINFORMATION COMBAT AGENT - FULL PIPELINE\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Processing {len(claims)} claims...\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "        \n",
    "        # Sequential agent execution\n",
    "        detected = self.agent1.execute(claims)\n",
    "        print()\n",
    "        \n",
    "        verified = self.agent2.execute(detected)\n",
    "        print()\n",
    "        \n",
    "        synthesized = self.agent3.execute(verified)\n",
    "        print()\n",
    "        \n",
    "        scored = self.agent4.execute(verified, synthesized)\n",
    "        print()\n",
    "        \n",
    "        # CORRECT usage of Agent 5: only pass verified claims\n",
    "        counter_narratives = self.agent5.execute(verified)\n",
    "        print()\n",
    "        \n",
    "        # Compile final report preserving detailed outputs\n",
    "        report = self._compile_report(claims, detected, verified, synthesized, scored, counter_narratives)\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"‚úÖ FACT-CHECKING PIPELINE COMPLETE!\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _compile_report(self, claims, detected, verified, synthesized, scored, counter_narratives) -> Dict[str, Any]:\n",
    "        \"\"\"Compile comprehensive report preserving full agent outputs\"\"\"\n",
    "        fact_checks = []\n",
    "        \n",
    "        for i in range(len(claims)):\n",
    "            if (detected[i]['status'] == 'success' and \n",
    "                verified[i]['status'] == 'success' and\n",
    "                synthesized[i]['status'] == 'success' and\n",
    "                scored[i]['status'] == 'success' and\n",
    "                counter_narratives[i]['status'] == 'success'):\n",
    "                \n",
    "                fact_checks.append({\n",
    "                    'original_claim': claims[i],\n",
    "                    'agent1_detection': detected[i],        # Full agent 1 output\n",
    "                    'agent2_verification': verified[i],    # Full agent 2 output\n",
    "                    'agent3_synthesis': synthesized[i],    # Full agent 3 output\n",
    "                    'agent4_credibility': scored[i],       # Full agent 4 output\n",
    "                    'agent5_counter_narrative': counter_narratives[i]  # Full agent 5 output\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'report_timestamp': datetime.now().isoformat(),\n",
    "            'total_claims_analyzed': len(claims),\n",
    "            'successful_fact_checks': len(fact_checks),\n",
    "            'system_config': {\n",
    "                'consensus_threshold': self.config['consensus_threshold'],\n",
    "                'scientific_sources': list(self.config['scientific_sources'].keys())\n",
    "            },\n",
    "            'fact_checks': fact_checks,\n",
    "            'summary': {\n",
    "                'false_claims': sum(1 for fc in fact_checks if 'FALSE' in fc['agent2_verification']['verdict']),\n",
    "                'true_claims': sum(1 for fc in fact_checks if 'TRUE' in fc['agent2_verification']['verdict']),\n",
    "                'avg_credibility': sum(fc['agent4_credibility']['credibility_score'] for fc in fact_checks) / len(fact_checks) if fact_checks else 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def save_report(self, report: Dict[str, Any], filename='climate_fact_check_report.json'):\n",
    "        \"\"\"Save report to JSON file\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        print(f\"üíæ Report saved to {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    def display_summary(self, report: Dict[str, Any]):\n",
    "        \"\"\"Display human-readable summary\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìä FACT-CHECK SUMMARY REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"\\nüìÖ Report Date: {report['report_timestamp']}\")\n",
    "        print(f\"üìã Claims Analyzed: {report['total_claims_analyzed']}\")\n",
    "        print(f\"‚úÖ Successful Fact-Checks: {report['successful_fact_checks']}\")\n",
    "        \n",
    "        summary = report['summary']\n",
    "        print(f\"\\nüìä RESULTS BREAKDOWN:\")\n",
    "        print(f\"  ‚ùå False Claims: {summary['false_claims']}\")\n",
    "        print(f\"  ‚úÖ True Claims: {summary['true_claims']}\")\n",
    "        print(f\"  üìà Avg Credibility Score: {summary['avg_credibility']:.1f}/100\")\n",
    "        \n",
    "        print(f\"\\nüî¨ DETAILED FACT-CHECKS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, fc in enumerate(report['fact_checks'], 1):\n",
    "            print(f\"\\n{i}. CLAIM: {fc['original_claim']}\")\n",
    "            print(f\"   üìå Detection: {fc['agent1_detection']}\")\n",
    "            print(f\"   üîç Verification: {fc['agent2_verification']}\")\n",
    "            print(f\"   üìù Synthesis: {fc['agent3_synthesis']}\")\n",
    "            print(f\"   ‚≠ê Credibility: {fc['agent4_credibility']}\")\n",
    "            print(f\"   üì± Counter-Narrative: {fc['agent5_counter_narrative']}\")\n",
    "            \n",
    "print(\"‚úÖ Orchestrator class defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d43c5",
   "metadata": {
    "papermill": {
     "duration": 0.007091,
     "end_time": "2025-12-01T18:29:11.404505",
     "exception": false,
     "start_time": "2025-12-01T18:29:11.397414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 10: The Web Scraper - Finding Real Claims\n",
    "\n",
    "Now we're getting real data from the actual internet. This scraper finds actual climate-related claims from news sources so we can fact-check what people are actually saying right now.\n",
    "\n",
    "**What it does:**\n",
    "- Connects to Google News RSS feed\n",
    "- Searches for climate-related articles and headlines\n",
    "- Extracts the actual claim text from real news sources\n",
    "- Handles errors gracefully (if scraping fails, falls back to sample claims)\n",
    "- Respects rate limits and uses proper HTTP headers\n",
    "\n",
    "**Why it matters:**\n",
    "- Instead of fake sample data, we're now processing REAL headlines\n",
    "- These are actual claims people are reading and sharing\n",
    "- You get immediate, current fact-checks\n",
    "- Perfect for understanding what misinformation is spreading RIGHT NOW\n",
    "\n",
    "**Fallback Logic:**\n",
    "- If live scraping works ‚Üí Use real news claims ‚úÖ\n",
    "- If scraping fails ‚Üí Use sample claims as backup ‚ö†Ô∏è\n",
    "- Either way, you get claims to fact-check\n",
    "\n",
    "**Important Note:**\n",
    "The scraper is polite:\n",
    "- Respects robots.txt\n",
    "- Uses proper User-Agent headers\n",
    "- Includes reasonable timeouts\n",
    "- Doesn't hammer servers with requests\n",
    "\n",
    "This is where we go from \"theoretical exercise\" to \"fighting real misinformation in the wild\" üåê\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa12590c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:29:11.420110Z",
     "iopub.status.busy": "2025-12-01T18:29:11.419814Z",
     "iopub.status.idle": "2025-12-01T18:29:13.011879Z",
     "shell.execute_reply": "2025-12-01T18:29:13.010768Z"
    },
    "papermill": {
     "duration": 1.601413,
     "end_time": "2025-12-01T18:29:13.013088",
     "exception": false,
     "start_time": "2025-12-01T18:29:11.411675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FETCHING LIVE CLIMATE CLAIMS...\n",
      "================================================================================\n",
      "üåê LIVE WEB SCRAPING INITIATED\n",
      "================================================================================\n",
      "\n",
      "üì∞ Scraping climate news for 'climate change'...\n",
      "‚úÖ Found 5 news articles\n",
      "\n",
      "‚úÖ Total claims collected: 5\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Using LIVE CLAIMS from Google News!\n",
      "üìä Total: 5 real-time headlines\n",
      "\n",
      "üìã CLAIMS TO BE FACT-CHECKED:\n",
      "================================================================================\n",
      "1. Europe could get 42 more days of summer by the year 2100 due to climate change -...\n",
      "2. Once-in-a-century floods set to become annual events in northeastern US in the n...\n",
      "3. Will Glacier Melt Lead to Increased Seismic Activity in Mountain Regions? - Colu...\n",
      "4. Flooding Kills 1,000+ Across South Asia as Climate Crisis Fuels More Extreme Rai...\n",
      "5. Many Fighting Climate Change Worry They Are Losing the Information War - The New...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# WEB SCRAPPER\n",
    "# ============================================================================\n",
    "class LiveClaimScraper:\n",
    "    \"\"\"Scrapes climate-related claims from various sources with fallbacks\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "    \n",
    "    def scrape_climate_news_rss(self, query='climate change', num_results=5):\n",
    "        \"\"\"Scrape climate news from Google News RSS\"\"\"\n",
    "        print(f\"\\nüì∞ Scraping climate news for '{query}'...\")\n",
    "        \n",
    "        try:\n",
    "            url = f\"https://news.google.com/rss/search?q={query.replace(' ', '+')}&hl=en-US&gl=US&ceid=US:en\"\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ö†Ô∏è  News request failed: {response.status_code}\")\n",
    "                return []\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'xml')\n",
    "            items = soup.find_all('item')[:num_results]\n",
    "            \n",
    "            claims = []\n",
    "            for item in items:\n",
    "                title = item.find('title')\n",
    "                link = item.find('link')\n",
    "                \n",
    "                if title:\n",
    "                    claims.append({\n",
    "                        'text': title.text.strip(),\n",
    "                        'source': 'Google News',\n",
    "                        'url': link.text if link else ''\n",
    "                    })\n",
    "            \n",
    "            print(f\"‚úÖ Found {len(claims)} news articles\")\n",
    "            return claims\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  News scraping error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def execute(self, sources=['news'], claims_per_source=5):\n",
    "        \"\"\"Scrape claims from sources\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"üåê LIVE WEB SCRAPING INITIATED\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        all_claims: List[str] = []\n",
    "        \n",
    "        if 'news' in sources:\n",
    "            news_claims = self.scrape_climate_news_rss(num_results=claims_per_source)\n",
    "            if news_claims:\n",
    "                all_claims.extend([c['text'] for c in news_claims])\n",
    "            time.sleep(1)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Total claims collected: {len(all_claims)}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return all_claims\n",
    "\n",
    "# Initialize scraper and fetch live claims\n",
    "print(\"\\nüéØ FETCHING LIVE CLIMATE CLAIMS...\")\n",
    "scraper = LiveClaimScraper({'model': None})\n",
    "live_claims = scraper.execute(sources=['news'], claims_per_source=5)\n",
    "\n",
    "# Decide which claims to use\n",
    "if live_claims and len(live_claims) > 0:\n",
    "    CLAIMS_TO_ANALYZE = live_claims\n",
    "    print(\"\\n‚úÖ Using LIVE CLAIMS from Google News!\")\n",
    "    print(f\"üìä Total: {len(CLAIMS_TO_ANALYZE)} real-time headlines\")\n",
    "else:\n",
    "    CLAIMS_TO_ANALYZE = SAMPLE_CLAIMS\n",
    "    print(\"\\n‚ö†Ô∏è  Using SAMPLE_CLAIMS as fallback\")\n",
    "    print(f\"üìä Total: {len(CLAIMS_TO_ANALYZE)} sample claims\")\n",
    "\n",
    "# Display claims (for quick confirmation)\n",
    "print(\"\\nüìã CLAIMS TO BE FACT-CHECKED:\")\n",
    "print(\"=\" * 80)\n",
    "for i, claim in enumerate(CLAIMS_TO_ANALYZE, 1):\n",
    "    preview = claim[:80] + \"...\" if len(claim) > 80 else claim\n",
    "    print(f\"{i}. {preview}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a9f56",
   "metadata": {
    "papermill": {
     "duration": 0.007577,
     "end_time": "2025-12-01T18:29:13.028248",
     "exception": false,
     "start_time": "2025-12-01T18:29:13.020671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 11: Execute the Full Pipeline - It All Comes Together\n",
    "\n",
    "This is the moment of truth. We're about to run all 5 agents on real (or sample) climate claims and generate a comprehensive fact-checking report.\n",
    "\n",
    "**What happens here:**\n",
    "1. **Orchestrator takes the claims** (real news or samples)\n",
    "2. **Agent 1 classifies them** - Is it a climate claim? What type?\n",
    "3. **Agent 2 verifies them** - True or false? What's the consensus?\n",
    "4. **Agent 3 synthesizes** - Clear, accessible explanation\n",
    "5. **Agent 4 scores** - Credibility rating with breakdown\n",
    "6. **Agent 5 generates** - Ready-to-share social media content\n",
    "7. **Report is compiled** - Complete JSON with all outputs\n",
    "8. **Results are saved** - climate_fact_check_report.json\n",
    "9. **Summary is displayed** - Human-readable overview\n",
    "\n",
    "**Output you'll see:**\n",
    "- Progress indicators for each agent ‚úì\n",
    "- Summary statistics (true vs false claims)\n",
    "- Average credibility score\n",
    "- Full breakdown of every fact-check\n",
    "- File saved confirmation\n",
    "\n",
    "**What gets saved:**\n",
    "- Complete JSON report with ALL agent outputs\n",
    "- Timestamp of generation\n",
    "- System configuration used\n",
    "- Success/failure metrics\n",
    "- Ready for PDF generation or social media sharing\n",
    "\n",
    "This is production-grade fact-checking infrastructure. In a few seconds, you'll have transparent, verifiable, detailed fact-checks ready to share. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ef48e0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:29:13.044751Z",
     "iopub.status.busy": "2025-12-01T18:29:13.044045Z",
     "iopub.status.idle": "2025-12-01T18:29:37.617782Z",
     "shell.execute_reply": "2025-12-01T18:29:37.616822Z"
    },
    "papermill": {
     "duration": 24.583909,
     "end_time": "2025-12-01T18:29:37.619510",
     "exception": false,
     "start_time": "2025-12-01T18:29:13.035601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ RUNNING FACT-CHECKING PIPELINE\n",
      "================================================================================\n",
      "Processing 5 claims through 5-agent system...\n",
      "================================================================================\n",
      "================================================================================\n",
      "üåç CLIMATE MISINFORMATION COMBAT AGENT - FULL PIPELINE\n",
      "================================================================================\n",
      "Processing 5 claims...\n",
      "================================================================================\n",
      "\n",
      "üîç Agent 1: Detecting claims in 5 statements...\n",
      "  ‚Üí Processing claim 1/5...\n",
      "  ‚Üí Processing claim 2/5...\n",
      "  ‚Üí Processing claim 3/5...\n",
      "  ‚Üí Processing claim 4/5...\n",
      "  ‚Üí Processing claim 5/5...\n",
      "‚úÖ Agent 1 Complete: 3/5 claims analyzed\n",
      "üéØ Claims needing verification: 0\n",
      "\n",
      "\n",
      "üî¨ Agent 2: Verifying claims against scientific sources...\n",
      "  ‚Üí Processing claim 3/5...\n",
      "  ‚Üí Processing claim 4/5...\n",
      "  ‚Üí Processing claim 5/5...\n",
      "‚úÖ Agent 2 Complete: 0/5 claims verified\n",
      "\n",
      "\n",
      "üìö Agent 3: Synthesizing evidence into fact-checks...\n",
      "‚úÖ Agent 3 Complete: 0 fact-checks created\n",
      "\n",
      "‚≠ê Agent 4: Calculating credibility scores...\n",
      "‚úÖ Agent 4 Complete: 0 scores calculated\n",
      "\n",
      "\n",
      "‚úçÔ∏è  Agent 5: Generating detailed counter-narratives...\n",
      "‚úÖ Agent 5 Complete: 0 counter-narratives created\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ FACT-CHECKING PIPELINE COMPLETE!\n",
      "================================================================================\n",
      "üíæ Report saved to climate_fact_check_report.json\n",
      "\n",
      "================================================================================\n",
      "üìä FACT-CHECK SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "üìÖ Report Date: 2025-12-01T18:29:37.614178\n",
      "üìã Claims Analyzed: 5\n",
      "‚úÖ Successful Fact-Checks: 0\n",
      "\n",
      "üìä RESULTS BREAKDOWN:\n",
      "  ‚ùå False Claims: 0\n",
      "  ‚úÖ True Claims: 0\n",
      "  üìà Avg Credibility Score: 0.0/100\n",
      "\n",
      "üî¨ DETAILED FACT-CHECKS:\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚úÖ COMPLETE! Check climate_fact_check_report.json for full results\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FINAL PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ RUNNING FACT-CHECKING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Processing {len(CLAIMS_TO_ANALYZE)} claims through 5-agent system...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create orchestrator and run pipeline\n",
    "orchestrator = ClimateFactCheckOrchestrator(model, CONFIG)\n",
    "final_report = orchestrator.execute(CLAIMS_TO_ANALYZE)\n",
    "\n",
    "# Save and display results\n",
    "orchestrator.save_report(final_report)\n",
    "orchestrator.display_summary(final_report)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ COMPLETE! Check climate_fact_check_report.json for full results\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518bf49",
   "metadata": {
    "papermill": {
     "duration": 0.007788,
     "end_time": "2025-12-01T18:29:37.635556",
     "exception": false,
     "start_time": "2025-12-01T18:29:37.627768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 12: Generate Professional PDF Reports\n",
    "\n",
    "The final piece of the puzzle. Your JSON data transforms into a polished, professional PDF report that you can share with stakeholders, publish, or submit.\n",
    "\n",
    "**What it does:**\n",
    "- Loads the JSON report from the orchestrator\n",
    "- Creates a beautifully formatted PDF with:\n",
    "  - **Title Page** - Report name, date, summary statistics\n",
    "  - **Executive Summary** - High-level overview of findings\n",
    "  - **Detailed Fact-Checks** - One complete page per claim showing ALL 5 agent outputs\n",
    "  - **Professional Styling** - Colors, fonts, spacing optimized for readability\n",
    "  - **Page Breaks** - Clean separation between sections\n",
    "  - **Full Transparency** - Every agent's work visible and cited\n",
    "\n",
    "**PDF Contents (per claim):**\n",
    "1. üîç Agent 1: Claim Detection (type, confidence, keywords)\n",
    "2. ‚úì Agent 2: Source Verification (verdict, consensus, evidence)\n",
    "3. üìö Agent 3: Evidence Synthesis (headline, summary, citations)\n",
    "4. ‚≠ê Agent 4: Credibility Score (rating, breakdown, justification)\n",
    "5. üì± Agent 5: Counter-Narrative (Twitter, Facebook, Instagram, LinkedIn, TikTok, hashtags, CTA)\n",
    "\n",
    "**Quality Features:**\n",
    "- Clean HTML-escaped text (no rendering errors)\n",
    "- Smart formatting of lists and dictionaries\n",
    "- Proper citation formatting with sources and URLs\n",
    "- Color-coded headers for visual hierarchy\n",
    "- Professional color scheme (navy blues, clean whites)\n",
    "- Responsive layout that works in any PDF viewer\n",
    "\n",
    "**Output Files:**\n",
    "- `climate_fact_check_report.json` - Raw data, machine-readable\n",
    "- `Climate_FactCheck_Report_COMPLETE.pdf` - Presentation-ready, human-readable\n",
    "\n",
    "This is publication-quality output suitable for:\n",
    "- Academic papers\n",
    "- Policy briefs\n",
    "- News organizations\n",
    "- Educational materials\n",
    "- Social media campaigns\n",
    "- Government reports\n",
    "\n",
    "Your entire 5-agent system culminates in this single, professional deliverable. üìÑ‚ú®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed1566d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:29:37.653308Z",
     "iopub.status.busy": "2025-12-01T18:29:37.653018Z",
     "iopub.status.idle": "2025-12-01T18:29:37.765922Z",
     "shell.execute_reply": "2025-12-01T18:29:37.764877Z"
    },
    "papermill": {
     "duration": 0.123712,
     "end_time": "2025-12-01T18:29:37.767377",
     "exception": false,
     "start_time": "2025-12-01T18:29:37.643665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìÑ GENERATING PRODUCTION-GRADE PDF (ALL CLAIMS, FULL DETAIL)\n",
      "================================================================================\n",
      "‚úÖ Production PDF generated: Climate_FactCheck_Report_COMPLETE.pdf\n",
      "üìÑ Total claims: 0\n",
      "üìä Estimated pages: 2\n",
      "\n",
      "‚úÖ PRODUCTION PDF COMPLETE!\n",
      "üìÑ File: Climate_FactCheck_Report_COMPLETE.pdf\n",
      "üìä All 0 claims included with full agent outputs\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, PageTemplate, Frame\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib.enums import TA_JUSTIFY, TA_LEFT, TA_CENTER\n",
    "from reportlab.pdfgen import canvas\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class ProductionPDFGenerator:\n",
    "    \"\"\"Production-grade PDF generator with complete outputs and polish\"\"\"\n",
    "    \n",
    "    def __init__(self, filename='Climate_FactCheck_Report_COMPLETE.pdf'):\n",
    "        self.filename = filename\n",
    "        self.styles = getSampleStyleSheet()\n",
    "        self.setup_custom_styles()\n",
    "    \n",
    "    def setup_custom_styles(self):\n",
    "        \"\"\"Setup custom styles\"\"\"\n",
    "        if 'ReportTitle' not in self.styles:\n",
    "            self.styles.add(ParagraphStyle(\n",
    "                name='ReportTitle',\n",
    "                parent=self.styles['Heading1'],\n",
    "                fontSize=26,\n",
    "                textColor=colors.HexColor('#1F4788'),\n",
    "                spaceAfter=20,\n",
    "                alignment=TA_CENTER,\n",
    "                bold=True\n",
    "            ))\n",
    "        \n",
    "        if 'ClaimHeader' not in self.styles:\n",
    "            self.styles.add(ParagraphStyle(\n",
    "                name='ClaimHeader',\n",
    "                parent=self.styles['Heading2'],\n",
    "                fontSize=15,\n",
    "                textColor=colors.HexColor('#2A5CAE'),\n",
    "                spaceAfter=12,\n",
    "                spaceBefore=15,\n",
    "                bold=True,\n",
    "                borderWidth=1,\n",
    "                borderColor=colors.HexColor('#2A5CAE'),\n",
    "                borderPadding=5\n",
    "            ))\n",
    "        \n",
    "        if 'AgentHeader' not in self.styles:\n",
    "            self.styles.add(ParagraphStyle(\n",
    "                name='AgentHeader',\n",
    "                parent=self.styles['Heading3'],\n",
    "                fontSize=12,\n",
    "                textColor=colors.HexColor('#3D5A80'),\n",
    "                spaceAfter=6,\n",
    "                spaceBefore=8,\n",
    "                bold=True,\n",
    "                backColor=colors.HexColor('#F0F4F8')\n",
    "            ))\n",
    "        \n",
    "        if 'BodyText' not in self.styles:\n",
    "            self.styles.add(ParagraphStyle(\n",
    "                name='BodyText',\n",
    "                parent=self.styles['BodyText'],\n",
    "                fontSize=9,\n",
    "                alignment=TA_LEFT,\n",
    "                leading=12,\n",
    "                spaceBefore=3,\n",
    "                spaceAfter=3\n",
    "            ))\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and escape text for PDF\"\"\"\n",
    "        if text is None:\n",
    "            return \"Not available\"\n",
    "        \n",
    "        text_str = str(text)\n",
    "        \n",
    "        # Handle dict/list formatting\n",
    "        if isinstance(text, dict):\n",
    "            return self.format_dict(text)\n",
    "        if isinstance(text, list):\n",
    "            return self.format_list(text)\n",
    "        \n",
    "        # Escape HTML\n",
    "        text_str = text_str.replace('&', '&amp;')\n",
    "        text_str = text_str.replace('<', '&lt;')\n",
    "        text_str = text_str.replace('>', '&gt;')\n",
    "        \n",
    "        return text_str\n",
    "    \n",
    "    def format_dict(self, d):\n",
    "        \"\"\"Format dictionary cleanly\"\"\"\n",
    "        parts = []\n",
    "        for key, value in d.items():\n",
    "            parts.append(f\"{key}: {self.clean_text(value)}\")\n",
    "        return \"<br/>\".join(parts)\n",
    "    \n",
    "    def format_list(self, lst):\n",
    "        \"\"\"Format list cleanly\"\"\"\n",
    "        if not lst:\n",
    "            return \"None\"\n",
    "        return \"<br/>\".join([f\"‚Ä¢ {self.clean_text(item)}\" for item in lst])\n",
    "    \n",
    "    def generate_pdf(self, report_data):\n",
    "        \"\"\"Generate complete PDF\"\"\"\n",
    "        doc = SimpleDocTemplate(\n",
    "            self.filename,\n",
    "            pagesize=letter,\n",
    "            topMargin=0.75*inch,\n",
    "            bottomMargin=0.75*inch,\n",
    "            leftMargin=0.75*inch,\n",
    "            rightMargin=0.75*inch\n",
    "        )\n",
    "        \n",
    "        story = []\n",
    "        \n",
    "        # Title Page\n",
    "        story.extend(self._create_title_page(report_data))\n",
    "        story.append(PageBreak())\n",
    "        \n",
    "        # Executive Summary\n",
    "        story.extend(self._create_executive_summary(report_data))\n",
    "        story.append(PageBreak())\n",
    "        \n",
    "        # Process ALL claims\n",
    "        for i, fact_check in enumerate(report_data['fact_checks'], 1):\n",
    "            story.extend(self._create_complete_claim_section(fact_check, i))\n",
    "            story.append(PageBreak())\n",
    "        \n",
    "        # Build PDF\n",
    "        doc.build(story)\n",
    "        print(f\"‚úÖ Production PDF generated: {self.filename}\")\n",
    "        print(f\"üìÑ Total claims: {len(report_data['fact_checks'])}\")\n",
    "        print(f\"üìä Estimated pages: {len(report_data['fact_checks']) * 4 + 2}\")\n",
    "    \n",
    "    def _create_title_page(self, report_data):\n",
    "        \"\"\"Title page\"\"\"\n",
    "        story = []\n",
    "        \n",
    "        title = Paragraph(\"üåç CLIMATE MISINFORMATION<br/>FACT-CHECK REPORT\", self.styles['ReportTitle'])\n",
    "        story.append(title)\n",
    "        story.append(Spacer(1, 0.3*inch))\n",
    "        \n",
    "        timestamp = datetime.fromisoformat(report_data['report_timestamp'])\n",
    "        date_str = timestamp.strftime(\"%B %d, %Y at %H:%M UTC\")\n",
    "        \n",
    "        info_text = f\"\"\"\n",
    "        <b>Generated:</b> {date_str}<br/>\n",
    "        <b>Total Claims:</b> {report_data['total_claims_analyzed']}<br/>\n",
    "        <b>Successfully Analyzed:</b> {report_data['successful_fact_checks']}<br/><br/>\n",
    "        \n",
    "        <b>üìä Summary Statistics:</b><br/>\n",
    "        ‚Ä¢ True Claims: {report_data['summary']['true_claims']}<br/>\n",
    "        ‚Ä¢ False Claims: {report_data['summary']['false_claims']}<br/>\n",
    "        ‚Ä¢ Average Credibility: {report_data['summary']['avg_credibility']:.1f}/100<br/><br/>\n",
    "        \n",
    "        <b>üî¨ Sources:</b> {', '.join(report_data['system_config']['scientific_sources'])}\n",
    "        \"\"\"\n",
    "        \n",
    "        story.append(Paragraph(info_text, self.styles['BodyText']))\n",
    "        return story\n",
    "    \n",
    "    def _create_executive_summary(self, report_data):\n",
    "        \"\"\"Executive summary\"\"\"\n",
    "        story = []\n",
    "        \n",
    "        title = Paragraph(\"üìã EXECUTIVE SUMMARY\", self.styles['ClaimHeader'])\n",
    "        story.append(title)\n",
    "        story.append(Spacer(1, 0.15*inch))\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "        This report examined {report_data['total_claims_analyzed']} climate-related claims using a \n",
    "        5-agent AI system. Each claim was processed through: Detection, Verification, Synthesis, \n",
    "        Credibility Scoring, and Counter-Narrative Generation.<br/><br/>\n",
    "        \n",
    "        <b>System Configuration:</b><br/>\n",
    "        ‚Ä¢ Authoritative Sources: {', '.join(report_data['system_config']['scientific_sources'])}<br/>\n",
    "        ‚Ä¢ Consensus Threshold: {report_data['system_config']['consensus_threshold']}%<br/>\n",
    "        ‚Ä¢ Success Rate: {report_data['successful_fact_checks']}/{report_data['total_claims_analyzed']} \n",
    "        ({100*report_data['successful_fact_checks']/report_data['total_claims_analyzed']:.1f}%)\n",
    "        \"\"\"\n",
    "        \n",
    "        story.append(Paragraph(summary, self.styles['BodyText']))\n",
    "        return story\n",
    "    \n",
    "    def _create_complete_claim_section(self, fact_check, num):\n",
    "        \"\"\"Complete claim section - NO TRUNCATION\"\"\"\n",
    "        story = []\n",
    "        \n",
    "        # Claim title\n",
    "        title = Paragraph(f\"<b>CLAIM #{num}</b>\", self.styles['ClaimHeader'])\n",
    "        story.append(title)\n",
    "        story.append(Spacer(1, 0.1*inch))\n",
    "        \n",
    "        # Original claim\n",
    "        claim_text = Paragraph(\n",
    "            f\"<b>Original Claim:</b><br/>{self.clean_text(fact_check['original_claim'])}\",\n",
    "            self.styles['BodyText']\n",
    "        )\n",
    "        story.append(claim_text)\n",
    "        story.append(Spacer(1, 0.15*inch))\n",
    "        \n",
    "        # AGENT 1\n",
    "        agent1 = fact_check.get('agent1_detection', {})\n",
    "        story.append(Paragraph(\"üîç AGENT 1: CLAIM DETECTION\", self.styles['AgentHeader']))\n",
    "        \n",
    "        a1_text = f\"\"\"\n",
    "        <b>Type:</b> {self.clean_text(agent1.get('claim_type'))}<br/>\n",
    "        <b>Confidence:</b> {agent1.get('confidence', 0):.2f}<br/>\n",
    "        <b>Climate Related:</b> {self.clean_text(agent1.get('is_climate_related'))}<br/>\n",
    "        <b>Needs Verification:</b> {self.clean_text(agent1.get('needs_verification'))}<br/>\n",
    "        <b>Keywords:</b> {', '.join(agent1.get('keywords', []))}<br/>\n",
    "        <b>Reasoning:</b><br/>{self.clean_text(agent1.get('reasoning'))}\n",
    "        \"\"\"\n",
    "        story.append(Paragraph(a1_text, self.styles['BodyText']))\n",
    "        story.append(Spacer(1, 0.1*inch))\n",
    "        \n",
    "        # AGENT 2\n",
    "        agent2 = fact_check.get('agent2_verification', {})\n",
    "        story.append(Paragraph(\"‚úì AGENT 2: SOURCE VERIFICATION\", self.styles['AgentHeader']))\n",
    "        \n",
    "        a2_text = f\"\"\"\n",
    "        <b>Verdict:</b> {self.clean_text(agent2.get('verdict'))}<br/>\n",
    "        <b>Scientific Consensus:</b> {agent2.get('scientific_consensus', 0)}%<br/>\n",
    "        <b>Confidence:</b> {agent2.get('confidence', 0):.2f}<br/>\n",
    "        <b>Sources:</b> {', '.join(agent2.get('authoritative_sources', []))}<br/><br/>\n",
    "        \n",
    "        <b>Explanation:</b><br/>{self.clean_text(agent2.get('explanation'))}<br/><br/>\n",
    "        \n",
    "        <b>Supporting Evidence:</b><br/>\n",
    "        {self.format_list(agent2.get('supporting_evidence', []))}<br/><br/>\n",
    "        \n",
    "        <b>Contradicting Evidence:</b><br/>\n",
    "        {self.format_list(agent2.get('contradicting_evidence', []))}\n",
    "        \"\"\"\n",
    "        story.append(Paragraph(a2_text, self.styles['BodyText']))\n",
    "        story.append(Spacer(1, 0.1*inch))\n",
    "        \n",
    "        # AGENT 3\n",
    "        agent3 = fact_check.get('agent3_synthesis', {})\n",
    "        story.append(Paragraph(\"üìö AGENT 3: EVIDENCE SYNTHESIS\", self.styles['AgentHeader']))\n",
    "        \n",
    "        # Format citations properly\n",
    "        citations_list = agent3.get('citations', [])\n",
    "        citations_formatted = []\n",
    "        for idx, citation in enumerate(citations_list, 1):\n",
    "            if isinstance(citation, dict):\n",
    "                source = citation.get('source', 'Unknown')\n",
    "                fact = citation.get('fact', '')\n",
    "                url = citation.get('url', '')\n",
    "                citations_formatted.append(f\"{idx}. <b>{source}:</b> {self.clean_text(fact)}<br/><i>{url}</i>\")\n",
    "            else:\n",
    "                citations_formatted.append(f\"{idx}. {self.clean_text(citation)}\")\n",
    "        \n",
    "        a3_text = f\"\"\"\n",
    "        <b>Headline:</b><br/>{self.clean_text(agent3.get('headline'))}<br/><br/>\n",
    "        \n",
    "        <b>Summary:</b><br/>{self.clean_text(agent3.get('summary'))}<br/><br/>\n",
    "        \n",
    "        <b>Bottom Line:</b><br/>{self.clean_text(agent3.get('bottom_line'))}<br/><br/>\n",
    "        \n",
    "        <b>Citations:</b><br/>\n",
    "        {'<br/>'.join(citations_formatted)}\n",
    "        \"\"\"\n",
    "        story.append(Paragraph(a3_text, self.styles['BodyText']))\n",
    "        story.append(Spacer(1, 0.1*inch))\n",
    "        \n",
    "        # AGENT 4\n",
    "        agent4 = fact_check.get('agent4_credibility', {})\n",
    "        story.append(Paragraph(\"‚≠ê AGENT 4: CREDIBILITY ASSESSMENT\", self.styles['AgentHeader']))\n",
    "        \n",
    "        a4_text = f\"\"\"\n",
    "        <b>Score:</b> {agent4.get('credibility_score', 0)}/100<br/>\n",
    "        <b>Rating:</b> {self.clean_text(agent4.get('rating'))}<br/><br/>\n",
    "        \n",
    "        <b>Breakdown:</b><br/>\n",
    "        {self.format_dict(agent4.get('breakdown', {}))}<br/><br/>\n",
    "        \n",
    "        <b>Justification:</b><br/>\n",
    "        {self.clean_text(agent4.get('justification'))}\n",
    "        \"\"\"\n",
    "        story.append(Paragraph(a4_text, self.styles['BodyText']))\n",
    "        story.append(Spacer(1, 0.1*inch))\n",
    "        \n",
    "        # AGENT 5 - COMPLETE SOCIAL MEDIA\n",
    "        agent5 = fact_check.get('agent5_counter_narrative', {})\n",
    "        story.append(Paragraph(\"üì± AGENT 5: COUNTER-NARRATIVE\", self.styles['AgentHeader']))\n",
    "        \n",
    "        social = agent5.get('social_media', {})\n",
    "        \n",
    "        a5_text = f\"\"\"\n",
    "        <b>Summary:</b><br/>{self.clean_text(agent5.get('short_summary'))}<br/><br/>\n",
    "        \n",
    "        <b>Twitter (280):</b><br/>{self.clean_text(social.get('twitter_280'))}<br/><br/>\n",
    "        \n",
    "        <b>Twitter Extended:</b><br/>{self.clean_text(social.get('twitter_extended'))}<br/><br/>\n",
    "        \n",
    "        <b>Facebook:</b><br/>{self.clean_text(social.get('facebook_long'))}<br/><br/>\n",
    "        \n",
    "        <b>Instagram:</b><br/>{self.clean_text(social.get('instagram_caption'))}<br/><br/>\n",
    "        \n",
    "        <b>LinkedIn:</b><br/>{self.clean_text(social.get('linkedin_professional'))}<br/><br/>\n",
    "        \n",
    "        <b>TikTok:</b><br/>{self.clean_text(social.get('tiktok_script'))}<br/><br/>\n",
    "        \n",
    "        <b>Hashtags:</b> {' '.join(agent5.get('hashtags', []))}<br/><br/>\n",
    "        \n",
    "        <b>CTA:</b> {self.clean_text(agent5.get('call_to_action'))}\n",
    "        \"\"\"\n",
    "        story.append(Paragraph(a5_text, self.styles['BodyText']))\n",
    "        \n",
    "        return story\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTE PRODUCTION PDF GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìÑ GENERATING PRODUCTION-GRADE PDF (ALL CLAIMS, FULL DETAIL)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load report\n",
    "with open('climate_fact_check_report.json', 'r') as f:\n",
    "    report_data = json.load(f)\n",
    "\n",
    "# Generate\n",
    "pdf_gen = ProductionPDFGenerator('Climate_FactCheck_Report_COMPLETE.pdf')\n",
    "pdf_gen.generate_pdf(report_data)\n",
    "\n",
    "print(\"\\n‚úÖ PRODUCTION PDF COMPLETE!\")\n",
    "print(\"üìÑ File: Climate_FactCheck_Report_COMPLETE.pdf\")\n",
    "print(f\"üìä All {len(report_data['fact_checks'])} claims included with full agent outputs\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6381cae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T18:29:37.784793Z",
     "iopub.status.busy": "2025-12-01T18:29:37.784526Z",
     "iopub.status.idle": "2025-12-01T18:29:37.806165Z",
     "shell.execute_reply": "2025-12-01T18:29:37.805007Z"
    },
    "papermill": {
     "duration": 0.032323,
     "end_time": "2025-12-01T18:29:37.807743",
     "exception": false,
     "start_time": "2025-12-01T18:29:37.775420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üì¶ CREATING SUBMISSION OUTPUT FILES\n",
      "================================================================================\n",
      "‚úÖ JSON Report saved: climate_fact_check_report.json (0.4 KB)\n",
      "‚úÖ Production PDF generated: Climate_FactCheck_Report_COMPLETE.pdf\n",
      "üìÑ Total claims: 0\n",
      "üìä Estimated pages: 2\n",
      "‚úÖ PDF Report generated: Climate_FactCheck_Report_COMPLETE.pdf (2.9 KB)\n",
      "‚úÖ Summary CSV saved: climate_fact_check_summary.csv (0.1 KB)\n",
      "‚úÖ Text Summary saved: climate_fact_check_summary.txt (0.3 KB)\n",
      "\n",
      "================================================================================\n",
      "üì¶ SUBMISSION FILES READY:\n",
      "   ‚úÖ climate_fact_check_report.json (375 bytes)\n",
      "   ‚úÖ Climate_FactCheck_Report_COMPLETE.pdf (2,966 bytes)\n",
      "   ‚úÖ climate_fact_check_summary.csv (69 bytes)\n",
      "   ‚úÖ climate_fact_check_summary.txt (336 bytes)\n",
      "\n",
      "üéØ Total Output Files: 4/4\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE SUBMISSION OUTPUT FILES\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üì¶ CREATING SUBMISSION OUTPUT FILES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verify final_report exists\n",
    "if 'final_report' not in globals():\n",
    "    print(\"‚ùå ERROR: final_report not found! Run all prior cells first.\")\n",
    "else:\n",
    "    try:\n",
    "        # 1. Save JSON Report\n",
    "        report_json_path = 'climate_fact_check_report.json'\n",
    "        with open(report_json_path, 'w') as f:\n",
    "            json.dump(final_report, f, indent=2)\n",
    "        \n",
    "        if os.path.exists(report_json_path):\n",
    "            size_kb = os.path.getsize(report_json_path) / 1024\n",
    "            print(f\"‚úÖ JSON Report saved: {report_json_path} ({size_kb:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå JSON save failed!\")\n",
    "        \n",
    "        # 2. Generate PDF\n",
    "        pdf_path = 'Climate_FactCheck_Report_COMPLETE.pdf'\n",
    "        pdf_gen = ProductionPDFGenerator(pdf_path)\n",
    "        pdf_gen.generate_pdf(final_report)\n",
    "        \n",
    "        if os.path.exists(pdf_path):\n",
    "            size_kb = os.path.getsize(pdf_path) / 1024\n",
    "            print(f\"‚úÖ PDF Report generated: {pdf_path} ({size_kb:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå PDF save failed!\")\n",
    "        \n",
    "        # 3. Create Summary CSV\n",
    "        csv_path = 'climate_fact_check_summary.csv'\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Claim_Number', 'Claim', 'Type', 'Verdict', 'Credibility_Score', 'Rating', 'Confidence']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            writer.writeheader()\n",
    "            for idx, fc in enumerate(final_report['fact_checks'], 1):\n",
    "                try:\n",
    "                    writer.writerow({\n",
    "                        'Claim_Number': idx,\n",
    "                        'Claim': fc['original_claim'][:100],\n",
    "                        'Type': fc['agent1_detection'].get('claim_type', 'N/A'),\n",
    "                        'Verdict': fc['agent2_verification'].get('verdict', 'N/A'),\n",
    "                        'Credibility_Score': round(fc['agent4_credibility'].get('credibility_score', 0), 1),\n",
    "                        'Rating': fc['agent4_credibility'].get('rating', 'N/A'),\n",
    "                        'Confidence': round(fc['agent2_verification'].get('confidence', 0), 2)\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è  Skipped row {idx}: {str(e)}\")\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            size_kb = os.path.getsize(csv_path) / 1024\n",
    "            print(f\"‚úÖ Summary CSV saved: {csv_path} ({size_kb:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå CSV save failed!\")\n",
    "        \n",
    "        # 4. Create Text Summary Report\n",
    "        txt_path = 'climate_fact_check_summary.txt'\n",
    "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(\"üåç CLIMATE FACT-CHECK REPORT SUMMARY\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Total Claims: {final_report['total_claims_analyzed']}\\n\")\n",
    "            f.write(f\"Successfully Processed: {final_report['successful_fact_checks']}\\n\")\n",
    "            f.write(f\"True Claims: {final_report['summary']['true_claims']}\\n\")\n",
    "            f.write(f\"False Claims: {final_report['summary']['false_claims']}\\n\")\n",
    "            f.write(f\"Average Credibility: {final_report['summary']['avg_credibility']:.1f}/100\\n\\n\")\n",
    "            \n",
    "            for idx, fc in enumerate(final_report['fact_checks'], 1):\n",
    "                f.write(f\"\\nCLAIM {idx}:\\n\")\n",
    "                f.write(f\"  Original: {fc['original_claim'][:150]}\\n\")\n",
    "                f.write(f\"  Verdict: {fc['agent2_verification'].get('verdict', 'N/A')}\\n\")\n",
    "                f.write(f\"  Credibility: {fc['agent4_credibility'].get('credibility_score', 'N/A')}/100\\n\")\n",
    "                f.write(f\"  Rating: {fc['agent4_credibility'].get('rating', 'N/A')}\\n\")\n",
    "        \n",
    "        if os.path.exists(txt_path):\n",
    "            size_kb = os.path.getsize(txt_path) / 1024\n",
    "            print(f\"‚úÖ Text Summary saved: {txt_path} ({size_kb:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Text save failed!\")\n",
    "        \n",
    "        # Final confirmation\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üì¶ SUBMISSION FILES READY:\")\n",
    "        output_files = []\n",
    "        for fname in [report_json_path, pdf_path, csv_path, txt_path]:\n",
    "            if os.path.exists(fname):\n",
    "                size = os.path.getsize(fname)\n",
    "                output_files.append(f\"   ‚úÖ {fname} ({size:,} bytes)\")\n",
    "        \n",
    "        print(\"\\n\".join(output_files))\n",
    "        print(f\"\\nüéØ Total Output Files: {len(output_files)}/4\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR during file creation: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14484960,
     "sourceId": 121144,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 198.854264,
   "end_time": "2025-12-01T18:29:41.155279",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T18:26:22.301015",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
